{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"YAPFM Documentation","text":"<p>Welcome to the comprehensive documentation for YAPFM (Yet Another Python File Manager). This documentation covers all aspects of the library, from basic usage to advanced features.</p>"},{"location":"#documentation-structure","title":"\ud83d\udcda Documentation Structure","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation Guide - How to install and set up YAPFM</li> <li>Quick Start - Get up and running in minutes</li> <li>User Guide - Comprehensive step-by-step guide</li> </ul>"},{"location":"#api-reference","title":"API Reference","text":"<ul> <li>API Reference - Complete API documentation with examples</li> <li>Core Classes - YAPFileManager, FileManagerProxy</li> <li>Strategies - File format handlers</li> <li>Mixins - Modular functionality components</li> </ul>"},{"location":"#examples-and-patterns","title":"Examples and Patterns","text":"<ul> <li>Examples - Code examples and common patterns</li> <li>Configuration Management - Real-world config examples</li> <li>Multi-Environment Setup - Managing different environments</li> <li>Advanced Patterns - Complex usage scenarios</li> </ul>"},{"location":"#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Performance Features - Caching, lazy loading, and streaming capabilities</li> <li>Advanced Features - Proxy, mixins, and strategies</li> <li>Custom Strategies - Creating your own file format handlers</li> <li>Performance Optimization - Tips for better performance</li> <li>Thread Safety - Using YAPFM in multi-threaded environments</li> </ul>"},{"location":"#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Troubleshooting - Common issues and solutions</li> <li>FAQ - Frequently asked questions</li> <li>Error Reference - Complete error reference</li> </ul>"},{"location":"#development-future","title":"Development &amp; Future","text":"<ul> <li>Roadmap - Future enhancements and planned features</li> <li>Contributing - How to contribute to YAPFM</li> </ul>"},{"location":"#quick-navigation","title":"\ud83d\ude80 Quick Navigation","text":""},{"location":"#by-use-case","title":"By Use Case","text":"<ul> <li>Configuration Files: Start with User Guide \u2192 Configuration Management</li> <li>Performance &amp; Caching: Performance Features \u2192 Caching &amp; Streaming Examples</li> <li>Multi-Format Support: API Reference \u2192 Custom Strategies</li> <li>Logging &amp; Monitoring: Advanced Features \u2192 Examples</li> <li>Performance Optimization: Performance Features \u2192 Troubleshooting</li> </ul>"},{"location":"#by-experience-level","title":"By Experience Level","text":"<ul> <li>Beginner: Installation \u2192 Quick Start \u2192 User Guide</li> <li>Intermediate: Examples \u2192 API Reference \u2192 Advanced Features</li> <li>Advanced: Custom Strategies \u2192 Performance \u2192 Troubleshooting</li> </ul>"},{"location":"#key-concepts","title":"\ud83d\udca1 Key Concepts","text":""},{"location":"#file-manager","title":"File Manager","text":"<p>The core class that combines all functionality through mixins. Handles file operations, data access, and persistence.</p>"},{"location":"#strategies","title":"Strategies","text":"<p>Format-specific handlers that know how to read and write different file types (JSON, TOML, YAML).</p>"},{"location":"#mixins","title":"Mixins","text":"<p>Modular components that provide specific functionality: - FileOperationsMixin: Basic file operations (load, save, exists) - KeyOperationsMixin: Key-based data access with dot notation - SectionOperationsMixin: Section-based data management - ContextMixin: Context manager support - CacheMixin: Intelligent caching with TTL, LRU eviction, and statistics - LazySectionsMixin: Lazy loading for memory-efficient section access - StreamingMixin: Streaming functionality for large files</p>"},{"location":"#proxy-pattern","title":"Proxy Pattern","text":"<p>Wrapper that adds logging, metrics, and auditing to file operations without modifying the core functionality.</p>"},{"location":"#external-resources","title":"\ud83d\udd17 External Resources","text":"<ul> <li>GitHub Repository - Source code and issue tracking</li> <li>PyPI Package - Package installation</li> <li>Changelog - Version history and changes</li> </ul>"},{"location":"#contributing-to-documentation","title":"\ud83d\udcdd Contributing to Documentation","text":"<p>Found an error or want to improve the documentation? Please:</p> <ol> <li>Check the Contributing Guide</li> <li>Open an issue or pull request</li> <li>Follow the documentation style guide</li> </ol> <p>This documentation is automatically generated and updated with each release.</p>"},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#v050-2025-09-26","title":"v0.5.0 (2025-09-26)","text":""},{"location":"CHANGELOG/#refactor","title":"Refactor","text":"<ul> <li>Update import statement from regify to regman in registry.py</li> </ul>"},{"location":"CHANGELOG/#v040-2025-09-23","title":"v0.4.0 (2025-09-23)","text":""},{"location":"CHANGELOG/#feat","title":"Feat","text":"<ul> <li>Introduce new mixins for enhanced functionality in YAPFileManager</li> <li>Add method to infer file format from extension</li> <li>Add new data transformation and traversal utilities</li> <li>Add MultiFileMixin for enhanced multi-file operations in YAPFileManager</li> <li>Implement multi-file operations module with loading and merging capabilities</li> <li>Introduce merge strategies for file management</li> <li>Add batch operations to YAPFileManager for enhanced key management</li> <li>Enhance YAPFileManager and CacheMixin with simplified API and improved key management</li> </ul>"},{"location":"CHANGELOG/#fix","title":"Fix","text":"<ul> <li>Improve immutability in ReplaceMergeStrategy by using deepcopy</li> </ul>"},{"location":"CHANGELOG/#refactor_1","title":"Refactor","text":"<ul> <li>Revise CacheMixin tests for improved clarity and functionality</li> <li>Update CacheMixin methods to include additional parameters for improved key management</li> </ul>"},{"location":"CHANGELOG/#v030-2025-09-22","title":"v0.3.0 (2025-09-22)","text":""},{"location":"CHANGELOG/#major-features-caching-performance","title":"\ud83d\ude80 Major Features: Caching &amp; Performance","text":""},{"location":"CHANGELOG/#intelligent-caching-system-cachemixin","title":"Intelligent Caching System (CacheMixin)","text":"<ul> <li>Smart Caching: Automatic caching of individual key values with TTL support</li> <li>LRU Eviction: Least Recently Used eviction when cache is full</li> <li>Memory Management: Size-based eviction to prevent memory issues</li> <li>Statistics Tracking: Comprehensive hit/miss ratios and performance metrics</li> <li>Pattern Invalidation: Invalidate cache entries using wildcard patterns</li> <li>Thread Safety: Safe for use in multi-threaded environments</li> <li>Unified Architecture: Centralized cache management in YAPFileManager</li> </ul>"},{"location":"CHANGELOG/#lazy-loading-system-lazysectionsmixin","title":"Lazy Loading System (LazySectionsMixin)","text":"<ul> <li>Memory Efficiency: Sections are loaded only when accessed</li> <li>Cache Integration: Works seamlessly with the unified cache system</li> <li>Automatic Invalidation: Cache invalidation when sections are modified</li> <li>Statistics Tracking: Monitor lazy loading performance and efficiency</li> <li>Configurable: Enable/disable lazy loading per manager instance</li> </ul>"},{"location":"CHANGELOG/#streaming-support-streamingmixin","title":"Streaming Support (StreamingMixin)","text":"<ul> <li>Large File Support: Process files larger than available RAM</li> <li>Chunked Reading: Process files in configurable chunks</li> <li>Memory Efficient: Constant memory usage regardless of file size</li> <li>Multiple Formats: Support for different file encodings</li> <li>Progress Tracking: Monitor processing progress with callbacks</li> <li>Search Capabilities: Search within large files with context</li> <li>Section Extraction: Extract specific sections from large files</li> <li>Thread Safety: Safe for concurrent access</li> </ul>"},{"location":"CHANGELOG/#enhanced-features","title":"\ud83d\udd27 Enhanced Features","text":""},{"location":"CHANGELOG/#unified-architecture","title":"Unified Architecture","text":"<ul> <li>Centralized Cache Management: Single cache instance for all operations</li> <li>Key Generation Optimization: Cached key generation for better performance</li> <li>Comprehensive Statistics: Unified statistics across all caching mechanisms</li> <li>Memory Management: Centralized memory management and cleanup</li> </ul>"},{"location":"CHANGELOG/#performance-improvements","title":"Performance Improvements","text":"<ul> <li>Key Caching: Cache generated keys to avoid redundant computations</li> <li>Import Optimization: Optimized imports in mixins to reduce overhead</li> <li>Parameter Validation: Enhanced parameter validation for better error handling</li> <li>Statistics Collection: Comprehensive statistics for performance monitoring</li> </ul>"},{"location":"CHANGELOG/#documentation-updates","title":"\ud83d\udcda Documentation Updates","text":""},{"location":"CHANGELOG/#new-documentation","title":"New Documentation","text":"<ul> <li>Caching &amp; Performance Guide: Comprehensive guide to intelligent caching, lazy loading, and streaming</li> <li>Caching &amp; Streaming Examples: Practical examples and real-world usage patterns</li> <li>API Reference Updates: Complete documentation for all new mixins and methods</li> <li>Performance Monitoring: Guidelines for monitoring and optimizing performance</li> </ul>"},{"location":"CHANGELOG/#enhanced-documentation","title":"Enhanced Documentation","text":"<ul> <li>Mixins Documentation: Updated with all new mixins and their capabilities</li> <li>Examples Section: New examples showcasing the latest features</li> <li>Advanced Features: Updated with new functionality and best practices</li> </ul>"},{"location":"CHANGELOG/#testing","title":"\ud83e\uddea Testing","text":""},{"location":"CHANGELOG/#comprehensive-test-coverage","title":"Comprehensive Test Coverage","text":"<ul> <li>CacheMixin Tests: 21 tests covering all caching functionality</li> <li>LazySectionsMixin Tests: 23 tests covering lazy loading scenarios</li> <li>StreamingMixin Tests: 33 tests covering streaming functionality</li> <li>Integration Tests: Tests for unified architecture and cross-mixin functionality</li> <li>Performance Tests: Benchmarking and performance monitoring tests</li> </ul>"},{"location":"CHANGELOG/#test-improvements","title":"Test Improvements","text":"<ul> <li>Mock Implementations: Comprehensive mock implementations for testing</li> <li>Real File Testing: Integration tests with actual file operations</li> <li>Error Handling Tests: Comprehensive error handling and edge case testing</li> <li>Thread Safety Tests: Multi-threaded testing for all new features</li> </ul>"},{"location":"CHANGELOG/#api-changes","title":"\ud83d\udd04 API Changes","text":""},{"location":"CHANGELOG/#new-methods","title":"New Methods","text":"<ul> <li><code>get_value()</code>: Intelligent caching for individual keys</li> <li><code>get_section()</code>: Lazy loading for entire sections</li> <li><code>stream_file()</code>: Streaming file processing</li> <li><code>stream_lines()</code>: Line-by-line file processing</li> <li><code>stream_sections()</code>: Section extraction from large files</li> <li><code>process_large_file()</code>: Custom processing with progress tracking</li> <li><code>search_in_file()</code>: Pattern search in large files</li> <li><code>get_cache_stats()</code>: Comprehensive cache statistics</li> <li><code>get_lazy_stats()</code>: Lazy loading statistics</li> <li><code>clear_key_cache()</code>: Key generation cache management</li> </ul>"},{"location":"CHANGELOG/#enhanced-methods","title":"Enhanced Methods","text":"<ul> <li><code>YAPFileManager.__init__()</code>: New parameters for enabling features</li> <li><code>_generate_cache_key()</code>: Unified key generation with caching</li> <li><code>get_cache()</code>: Access to unified cache system</li> </ul>"},{"location":"CHANGELOG/#use-cases","title":"\ud83c\udfaf Use Cases","text":""},{"location":"CHANGELOG/#configuration-management","title":"Configuration Management","text":"<ul> <li>High-performance configuration access with intelligent caching</li> <li>Memory-efficient loading of large configuration files</li> <li>Real-time configuration updates with cache invalidation</li> </ul>"},{"location":"CHANGELOG/#large-file-processing","title":"Large File Processing","text":"<ul> <li>Process log files larger than available RAM</li> <li>Extract specific sections from large configuration files</li> <li>Search and analyze large datasets efficiently</li> </ul>"},{"location":"CHANGELOG/#memory-efficient-applications","title":"Memory-Efficient Applications","text":"<ul> <li>Lazy loading for applications with large configuration files</li> <li>Streaming for data processing applications</li> <li>Optimized memory usage for long-running applications</li> </ul>"},{"location":"CHANGELOG/#breaking-changes","title":"\ud83d\udea8 Breaking Changes","text":""},{"location":"CHANGELOG/#none","title":"None","text":"<ul> <li>All new features are opt-in and backward compatible</li> <li>Existing code continues to work without changes</li> <li>New features can be enabled gradually</li> </ul>"},{"location":"CHANGELOG/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":""},{"location":"CHANGELOG/#planned-features","title":"Planned Features","text":"<ul> <li>Distributed Caching: Support for Redis and other distributed caches</li> <li>Compression: Automatic compression of cached data</li> <li>Encryption: Encrypted caching for sensitive data</li> <li>Metrics: More detailed performance metrics</li> <li>Profiling: Built-in profiling tools</li> <li>Visualization: Cache performance visualization tools</li> </ul>"},{"location":"CHANGELOG/#v020-2025-09-10","title":"v0.2.0 (2025-09-10)","text":""},{"location":"CHANGELOG/#feat_1","title":"Feat","text":"<ul> <li>Introduce open_file helper function for simplified file management</li> <li>Enhance YAPFileManager with key and section operations mixins</li> <li>Introduce ContextMixin for enhanced context management in YAPFileManager</li> <li>Enhance YAPFM with mixins and file operations</li> <li>Implement FileManagerProxy for enhanced file management</li> <li>Add validation utilities for file strategies</li> <li>Introduce file management strategies and error handling</li> <li>Implement file management and strategy registry system - Introduce YAPFileManager class for managing file paths and strategies - Add FileStrategyRegistry for thread-safe strategy registration and usage tracking - Define BaseFileStrategy protocol for file handling strategies - Create initial structure for various file strategies</li> </ul>"},{"location":"CHANGELOG/#fix_1","title":"Fix","text":"<ul> <li>Correct JSON loading function in JsonStrategy</li> </ul>"},{"location":"CHANGELOG/#refactor_2","title":"Refactor","text":"<ul> <li>Update import paths and enhance TOML merging logic</li> <li>Replace Lock with RLock for thread safety in FileStrategyRegistry</li> </ul>"},{"location":"CONTRIBUTING/","title":"Contributing to YAPFM","text":"<p>Thank you for your interest in contributing to YAPFM! This document provides guidelines and information for contributors.</p>"},{"location":"CONTRIBUTING/#table-of-contents","title":"\ud83d\udccb Table of Contents","text":"<ul> <li>Code of Conduct</li> <li>Getting Started</li> <li>Development Setup</li> <li>Contributing Process</li> <li>Code Style and Standards</li> <li>Testing</li> <li>Documentation</li> <li>Release Process</li> <li>Types of Contributions</li> </ul>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"\ud83e\udd1d Code of Conduct","text":"<p>This project adheres to a code of conduct that we expect all contributors to follow. Please be respectful, inclusive, and constructive in all interactions.</p>"},{"location":"CONTRIBUTING/#getting-started","title":"\ud83d\ude80 Getting Started","text":""},{"location":"CONTRIBUTING/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or higher</li> <li>Poetry (for dependency management)</li> <li>Git</li> </ul>"},{"location":"CONTRIBUTING/#fork-and-clone","title":"Fork and Clone","text":"<ol> <li>Fork the repository on GitHub</li> <li>Clone your fork locally:    <pre><code>git clone https://github.com/your-username/yapfm.git\ncd yapfm\n</code></pre></li> <li>Add the upstream repository:    <pre><code>git remote add upstream https://github.com/mawuva/yapfm.git\n</code></pre></li> </ol>"},{"location":"CONTRIBUTING/#development-setup","title":"\ud83d\udee0\ufe0f Development Setup","text":""},{"location":"CONTRIBUTING/#1-install-dependencies","title":"1. Install Dependencies","text":"<pre><code># Install Poetry if you haven't already\ncurl -sSL https://install.python-poetry.org | python3 -\n\n# Install project dependencies\npoetry install\n\n# Activate the virtual environment\npoetry shell\n</code></pre>"},{"location":"CONTRIBUTING/#2-install-pre-commit-hooks","title":"2. Install Pre-commit Hooks","text":"<pre><code># Install pre-commit hooks\npoetry run pre-commit install\n</code></pre>"},{"location":"CONTRIBUTING/#3-verify-installation","title":"3. Verify Installation","text":"<pre><code># Run tests to ensure everything is working\npoetry run pytest\n\n# Run linting\npoetry run ruff check .\n\n# Run type checking\npoetry run mypy src/\n</code></pre>"},{"location":"CONTRIBUTING/#contributing-process","title":"\ud83d\udcdd Contributing Process","text":""},{"location":"CONTRIBUTING/#1-create-a-branch","title":"1. Create a Branch","text":"<pre><code># Create a new branch for your feature/fix\ngit checkout -b feature/your-feature-name\n# or\ngit checkout -b fix/your-bug-fix\n</code></pre>"},{"location":"CONTRIBUTING/#2-make-your-changes","title":"2. Make Your Changes","text":"<ul> <li>Write clean, readable code</li> <li>Follow the existing code style</li> <li>Add tests for new functionality</li> <li>Update documentation as needed</li> </ul>"},{"location":"CONTRIBUTING/#3-test-your-changes","title":"3. Test Your Changes","text":"<pre><code># Run all tests\npoetry run pytest\n\n# Run tests with coverage\npoetry run pytest --cov=src/yapfm\n\n# Run specific test files\npoetry run pytest tests/strategies/test_json_strategy.py\n</code></pre>"},{"location":"CONTRIBUTING/#4-commit-your-changes","title":"4. Commit Your Changes","text":"<p>We use Conventional Commits for commit messages:</p> <pre><code># Examples of good commit messages:\ngit commit -m \"feat: add support for XML file format\"\ngit commit -m \"fix: resolve memory leak in proxy pattern\"\ngit commit -m \"docs: update API reference for new methods\"\ngit commit -m \"test: add unit tests for context manager\"\ngit commit -m \"refactor: simplify strategy registration logic\"\n</code></pre>"},{"location":"CONTRIBUTING/#5-push-and-create-pull-request","title":"5. Push and Create Pull Request","text":"<pre><code># Push your branch\ngit push origin feature/your-feature-name\n\n# Create a pull request on GitHub\n</code></pre>"},{"location":"CONTRIBUTING/#code-style-and-standards","title":"\ud83c\udfa8 Code Style and Standards","text":""},{"location":"CONTRIBUTING/#python-code-style","title":"Python Code Style","text":"<p>We use several tools to maintain code quality:</p> <ul> <li>Black: Code formatting</li> <li>isort: Import sorting</li> <li>Ruff: Linting and additional formatting</li> <li>MyPy: Type checking</li> </ul>"},{"location":"CONTRIBUTING/#running-code-quality-tools","title":"Running Code Quality Tools","text":"<pre><code># Format code\npoetry run black src/ tests/\npoetry run isort src/ tests/\n\n# Lint code\npoetry run ruff check src/ tests/\n\n# Fix auto-fixable issues\npoetry run ruff check --fix src/ tests/\n\n# Type checking\npoetry run mypy src/\n</code></pre>"},{"location":"CONTRIBUTING/#code-style-guidelines","title":"Code Style Guidelines","text":"<ol> <li>Type Hints: All functions and methods should have type hints</li> <li>Docstrings: Use Google-style docstrings for all public functions/classes</li> <li>Line Length: Maximum 88 characters (Black default)</li> <li>Imports: Use absolute imports, sort with isort</li> <li>Naming: Follow PEP 8 conventions</li> </ol>"},{"location":"CONTRIBUTING/#example-code-style","title":"Example Code Style","text":"<pre><code>from typing import Any, Dict, Optional\n\nfrom yapfm.exceptions import FileManagerError\n\n\nclass ExampleClass:\n    \"\"\"Example class demonstrating code style.\n\n    This class shows the expected code style for YAPFM contributions.\n    \"\"\"\n\n    def __init__(self, name: str, config: Optional[Dict[str, Any]] = None) -&gt; None:\n        \"\"\"Initialize the example class.\n\n        Args:\n            name: The name of the instance\n            config: Optional configuration dictionary\n        \"\"\"\n        self.name = name\n        self.config = config or {}\n\n    def process_data(self, data: Dict[str, Any]) -&gt; bool:\n        \"\"\"Process the given data.\n\n        Args:\n            data: The data to process\n\n        Returns:\n            True if processing was successful\n\n        Raises:\n            FileManagerError: If processing fails\n        \"\"\"\n        if not data:\n            raise FileManagerError(\"Data cannot be empty\")\n\n        # Process the data\n        return True\n</code></pre>"},{"location":"CONTRIBUTING/#testing","title":"\ud83e\uddea Testing","text":""},{"location":"CONTRIBUTING/#test-structure","title":"Test Structure","text":"<p>Tests are organized in the <code>tests/</code> directory mirroring the source structure:</p> <pre><code>tests/\n\u251c\u2500\u2500 helpers/\n\u2502   \u251c\u2500\u2500 test_dict_utils.py\n\u2502   \u251c\u2500\u2500 test_io.py\n\u2502   \u2514\u2500\u2500 test_validation.py\n\u251c\u2500\u2500 mixins/\n\u2502   \u251c\u2500\u2500 test_context_mixin.py\n\u2502   \u251c\u2500\u2500 test_file_operations_mixin.py\n\u2502   \u2514\u2500\u2500 test_key_operations_mixin.py\n\u251c\u2500\u2500 strategies/\n\u2502   \u251c\u2500\u2500 test_base.py\n\u2502   \u251c\u2500\u2500 test_json_strategy.py\n\u2502   \u2514\u2500\u2500 test_toml_strategy.py\n\u2514\u2500\u2500 test_proxy.py\n</code></pre>"},{"location":"CONTRIBUTING/#writing-tests","title":"Writing Tests","text":"<ol> <li>Test Coverage: Aim for high test coverage (90%+)</li> <li>Test Naming: Use descriptive test names that explain what is being tested</li> <li>Test Structure: Follow Arrange-Act-Assert pattern</li> <li>Fixtures: Use pytest fixtures for common setup</li> </ol>"},{"location":"CONTRIBUTING/#example-test","title":"Example Test","text":"<pre><code>import pytest\nfrom yapfm import YAPFileManager\nfrom yapfm.exceptions import FileManagerError\n\n\nclass TestYAPFileManager:\n    \"\"\"Test cases for YAPFileManager class.\"\"\"\n\n    def test_set_key_creates_nested_structure(self) -&gt; None:\n        \"\"\"Test that set_key creates nested dictionary structure.\"\"\"\n        # Arrange\n        fm = YAPFileManager(\"test.json\")\n        fm.load()\n\n        # Act\n        fm.set_key(\"localhost\", dot_key=\"database.host\")\n\n        # Assert\n        assert fm.get_key(dot_key=\"database.host\") == \"localhost\"\n        assert fm.get_key(dot_key=\"database\") == {\"host\": \"localhost\"}\n\n    def test_set_key_raises_error_for_invalid_key(self) -&gt; None:\n        \"\"\"Test that set_key raises error for invalid key format.\"\"\"\n        # Arrange\n        fm = YAPFileManager(\"test.json\")\n        fm.load()\n\n        # Act &amp; Assert\n        with pytest.raises(FileManagerError, match=\"Invalid key format\"):\n            fm.set_key(\"value\", dot_key=\"\")\n</code></pre>"},{"location":"CONTRIBUTING/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npoetry run pytest\n\n# Run with coverage\npoetry run pytest --cov=src/yapfm --cov-report=html\n\n# Run specific test file\npoetry run pytest tests/strategies/test_json_strategy.py\n\n# Run tests with verbose output\npoetry run pytest -v\n\n# Run tests matching a pattern\npoetry run pytest -k \"test_set_key\"\n</code></pre>"},{"location":"CONTRIBUTING/#documentation","title":"\ud83d\udcda Documentation","text":""},{"location":"CONTRIBUTING/#documentation-structure","title":"Documentation Structure","text":"<p>Documentation is located in the <code>docs/</code> directory:</p> <ul> <li><code>README.md</code> - Project overview and quick start</li> <li><code>installation.md</code> - Installation instructions</li> <li><code>quick_start.md</code> - Getting started guide</li> <li><code>user_guide.md</code> - Comprehensive usage guide</li> <li><code>api_reference.md</code> - Complete API documentation</li> <li><code>examples.md</code> - Code examples and patterns</li> <li><code>advanced_features.md</code> - Advanced features and patterns</li> <li><code>troubleshooting.md</code> - Common issues and solutions</li> <li><code>roadmap.md</code> - Future plans and features</li> </ul>"},{"location":"CONTRIBUTING/#writing-documentation","title":"Writing Documentation","text":"<ol> <li>Markdown: Use standard Markdown with GitHub-flavored extensions</li> <li>Code Examples: Include working code examples</li> <li>Cross-references: Link between related documentation sections</li> <li>Updates: Update documentation when adding new features</li> </ol>"},{"location":"CONTRIBUTING/#building-documentation","title":"Building Documentation","text":"<pre><code># Build documentation locally\npoetry run mkdocs serve\n\n# Build static documentation\npoetry run mkdocs build\n</code></pre>"},{"location":"CONTRIBUTING/#release-process","title":"\ud83d\ude80 Release Process","text":""},{"location":"CONTRIBUTING/#version-management","title":"Version Management","text":"<p>We use Commitizen for version management:</p> <pre><code># Bump version (patch, minor, or major)\npoetry run cz bump\n\n# Check current version\npoetry run cz version\n</code></pre>"},{"location":"CONTRIBUTING/#release-checklist","title":"Release Checklist","text":"<ol> <li>\u2705 All tests pass</li> <li>\u2705 Documentation is updated</li> <li>\u2705 CHANGELOG.md is updated</li> <li>\u2705 Version is bumped</li> <li>\u2705 Pull request is approved and merged</li> <li>\u2705 GitHub release is created</li> <li>\u2705 Package is published to PyPI</li> </ol>"},{"location":"CONTRIBUTING/#types-of-contributions","title":"\ud83c\udfaf Types of Contributions","text":""},{"location":"CONTRIBUTING/#bug-fixes","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fix existing functionality that's not working correctly</li> <li>Include tests that reproduce the bug</li> <li>Ensure the fix doesn't break existing functionality</li> </ul>"},{"location":"CONTRIBUTING/#new-features","title":"\u2728 New Features","text":"<ul> <li>Add new functionality to the library</li> <li>Follow the existing architecture patterns</li> <li>Include comprehensive tests</li> <li>Update documentation</li> </ul>"},{"location":"CONTRIBUTING/#documentation_1","title":"\ud83d\udcda Documentation","text":"<ul> <li>Improve existing documentation</li> <li>Add missing documentation</li> <li>Fix typos or unclear explanations</li> <li>Add examples and tutorials</li> </ul>"},{"location":"CONTRIBUTING/#tests","title":"\ud83e\uddea Tests","text":"<ul> <li>Add missing test coverage</li> <li>Improve existing tests</li> <li>Add integration tests</li> <li>Add performance tests</li> </ul>"},{"location":"CONTRIBUTING/#refactoring","title":"\ud83d\udd27 Refactoring","text":"<ul> <li>Improve code structure without changing functionality</li> <li>Optimize performance</li> <li>Improve type hints</li> <li>Simplify complex code</li> </ul>"},{"location":"CONTRIBUTING/#code-quality","title":"\ud83c\udfa8 Code Quality","text":"<ul> <li>Fix linting issues</li> <li>Improve code style</li> <li>Add type hints</li> <li>Optimize imports</li> </ul>"},{"location":"CONTRIBUTING/#getting-help","title":"\ud83d\udcde Getting Help","text":"<p>If you need help or have questions:</p> <ol> <li>Check the documentation in the <code>docs/</code> directory</li> <li>Search existing issues on GitHub</li> <li>Create a new issue if your question isn't answered</li> <li>Join discussions in GitHub Discussions</li> </ol>"},{"location":"CONTRIBUTING/#recognition","title":"\ud83d\ude4f Recognition","text":"<p>Contributors will be recognized in: - The project's README.md - Release notes - GitHub contributors list</p> <p>Thank you for contributing to YAPFM! \ud83c\udf89</p>"},{"location":"PERFORMANCE_FEATURES/","title":"Performance Features","text":"<p>YAPFM provides powerful performance features designed to optimize speed, memory usage, and efficiency for various use cases.</p>"},{"location":"PERFORMANCE_FEATURES/#overview","title":"\ud83d\ude80 Overview","text":"<p>YAPFM's performance features are built around three core concepts:</p> <ul> <li>Intelligent Caching: Smart caching system with TTL, LRU eviction, and comprehensive statistics</li> <li>Lazy Loading: Memory-efficient loading of large sections and data</li> <li>Streaming: Process files larger than available RAM with constant memory usage</li> </ul>"},{"location":"PERFORMANCE_FEATURES/#intelligent-caching","title":"\ud83e\udde0 Intelligent Caching","text":""},{"location":"PERFORMANCE_FEATURES/#what-is-intelligent-caching","title":"What is Intelligent Caching?","text":"<p>Intelligent caching automatically caches frequently accessed values to dramatically improve performance. The system includes:</p> <ul> <li>TTL Support: Time-to-live for cached entries</li> <li>LRU Eviction: Least Recently Used eviction when cache is full</li> <li>Memory Management: Size-based eviction to prevent memory issues</li> <li>Statistics Tracking: Hit/miss ratios and performance metrics</li> <li>Pattern Invalidation: Invalidate cache entries using wildcard patterns</li> </ul>"},{"location":"PERFORMANCE_FEATURES/#when-to-use-caching","title":"When to Use Caching","text":"<ul> <li>Frequently Accessed Data: Configuration values accessed multiple times</li> <li>Expensive Operations: Data that takes time to load or compute</li> <li>Read-Heavy Workloads: Applications that read more than they write</li> <li>Performance Critical: Applications where speed is important</li> </ul>"},{"location":"PERFORMANCE_FEATURES/#example","title":"Example","text":"<pre><code>from yapfm import YAPFileManager\n\n# Enable caching\nfm = YAPFileManager(\n    \"config.json\",\n    enable_cache=True,\n    cache_size=1000,      # Maximum 1000 cached entries\n    cache_ttl=3600        # 1 hour TTL\n)\n\n# First access loads from file and caches\nhost = fm.get_value(\"database.host\")\n\n# Subsequent accesses return from cache (much faster)\nhost_cached = fm.get_value(\"database.host\")  # Returns from cache\n</code></pre>"},{"location":"PERFORMANCE_FEATURES/#lazy-loading","title":"\ud83c\udfaf Lazy Loading","text":""},{"location":"PERFORMANCE_FEATURES/#what-is-lazy-loading","title":"What is Lazy Loading?","text":"<p>Lazy loading loads data only when it's actually needed, reducing memory usage and startup time. Features include:</p> <ul> <li>Memory Efficiency: Sections are loaded only when accessed</li> <li>Cache Integration: Works seamlessly with the unified cache system</li> <li>Automatic Invalidation: Cache invalidation when sections are modified</li> <li>Statistics Tracking: Monitor lazy loading performance</li> </ul>"},{"location":"PERFORMANCE_FEATURES/#when-to-use-lazy-loading","title":"When to Use Lazy Loading","text":"<ul> <li>Large Configuration Files: Files with many sections, but only some are used</li> <li>Memory Constrained: Applications with limited memory</li> <li>Selective Access: When only specific parts of data are needed</li> <li>Startup Performance: When fast startup is important</li> </ul>"},{"location":"PERFORMANCE_FEATURES/#example_1","title":"Example","text":"<pre><code>from yapfm import YAPFileManager\n\n# Enable lazy loading\nfm = YAPFileManager(\n    \"large_config.json\",\n    enable_lazy_loading=True\n)\n\n# Section is not loaded until accessed\ndb_section = fm.get_section(\"database\")  # Loads only when accessed\nprint(f\"Database host: {db_section['host']}\")\n\n# Subsequent accesses return from lazy cache\ndb_section_again = fm.get_section(\"database\")  # Returns from cache\n</code></pre>"},{"location":"PERFORMANCE_FEATURES/#streaming","title":"\ud83c\udf0a Streaming","text":""},{"location":"PERFORMANCE_FEATURES/#what-is-streaming","title":"What is Streaming?","text":"<p>Streaming allows processing files larger than available RAM by reading them in chunks. Features include:</p> <ul> <li>Large File Support: Process files larger than available RAM</li> <li>Chunked Reading: Process files in configurable chunks</li> <li>Memory Efficient: Constant memory usage regardless of file size</li> <li>Progress Tracking: Monitor processing progress</li> <li>Search Capabilities: Search within large files</li> </ul>"},{"location":"PERFORMANCE_FEATURES/#when-to-use-streaming","title":"When to Use Streaming","text":"<ul> <li>Large Files: Files larger than available RAM</li> <li>Log Processing: Analyzing large log files</li> <li>Data Processing: Processing large datasets</li> <li>Memory Constrained: When memory usage must be controlled</li> </ul>"},{"location":"PERFORMANCE_FEATURES/#example_2","title":"Example","text":"<pre><code>from yapfm import YAPFileManager\n\n# Enable streaming\nfm = YAPFileManager(\n    \"large_file.txt\",\n    enable_streaming=True\n)\n\n# Stream file in chunks\nfor chunk in fm.stream_file(chunk_size=1024*1024):  # 1MB chunks\n    process_chunk(chunk)\n\n# Stream line by line\nfor line in fm.stream_lines():\n    if \"ERROR\" in line:\n        print(f\"Error found: {line}\")\n</code></pre>"},{"location":"PERFORMANCE_FEATURES/#configuration-examples","title":"\ud83d\udd27 Configuration Examples","text":""},{"location":"PERFORMANCE_FEATURES/#high-performance-configuration","title":"High-Performance Configuration","text":"<pre><code># For high-performance applications\nfm = YAPFileManager(\n    \"config.json\",\n    enable_cache=True,\n    cache_size=10000,     # Large cache\n    cache_ttl=7200,       # 2 hours TTL\n    enable_lazy_loading=True,\n    enable_streaming=True\n)\n</code></pre>"},{"location":"PERFORMANCE_FEATURES/#memory-conscious-configuration","title":"Memory-Conscious Configuration","text":"<pre><code># For memory-constrained environments\nfm = YAPFileManager(\n    \"config.json\",\n    enable_cache=True,\n    cache_size=100,       # Small cache\n    cache_ttl=300,        # 5 minutes TTL\n    enable_lazy_loading=True,\n    enable_streaming=True\n)\n</code></pre>"},{"location":"PERFORMANCE_FEATURES/#development-configuration","title":"Development Configuration","text":"<pre><code># For development with frequent changes\nfm = YAPFileManager(\n    \"config.json\",\n    enable_cache=True,\n    cache_size=1000,\n    cache_ttl=60,         # Short TTL for development\n    enable_lazy_loading=False,  # Disable for easier debugging\n    enable_streaming=True\n)\n</code></pre>"},{"location":"PERFORMANCE_FEATURES/#performance-monitoring","title":"\ud83d\udcca Performance Monitoring","text":""},{"location":"PERFORMANCE_FEATURES/#cache-performance","title":"Cache Performance","text":"<pre><code># Monitor cache performance\nstats = fm.get_cache_stats()\nhit_rate = stats['unified_cache']['hit_rate']\n\nif hit_rate &lt; 0.8:  # Less than 80% hit rate\n    print(\"Warning: Low cache hit rate, consider increasing cache size\")\n    fm.clear_cache()  # Clear cache and start fresh\n</code></pre>"},{"location":"PERFORMANCE_FEATURES/#memory-usage","title":"Memory Usage","text":"<pre><code># Monitor memory usage\nstats = fm.get_cache_stats()\nmemory_usage = stats['unified_cache']['memory_usage_mb']\n\nif memory_usage &gt; 50:  # More than 50MB\n    print(\"Warning: High memory usage, consider reducing cache size\")\n    fm.clear_cache()\n</code></pre>"},{"location":"PERFORMANCE_FEATURES/#lazy-loading-efficiency","title":"Lazy Loading Efficiency","text":"<pre><code># Monitor lazy loading efficiency\nstats = fm.get_lazy_stats()\nloaded_ratio = stats['loaded_sections'] / stats['total_sections']\n\nif loaded_ratio &gt; 0.5:  # More than 50% of sections loaded\n    print(\"Warning: High lazy loading ratio, consider disabling lazy loading\")\n</code></pre>"},{"location":"PERFORMANCE_FEATURES/#use-cases","title":"\ud83c\udfaf Use Cases","text":""},{"location":"PERFORMANCE_FEATURES/#configuration-management","title":"Configuration Management","text":"<pre><code># High-performance configuration management\nfm = YAPFileManager(\n    \"app_config.json\",\n    enable_cache=True,\n    cache_size=1000,\n    cache_ttl=3600,\n    enable_lazy_loading=True\n)\n\n# Fast access to frequently used values\ndb_host = fm.get_value(\"database.host\")\napi_key = fm.get_value(\"api.key\")\n</code></pre>"},{"location":"PERFORMANCE_FEATURES/#large-file-processing","title":"Large File Processing","text":"<pre><code># Process large log files\nfm = YAPFileManager(\"access.log\", enable_streaming=True)\n\n# Search for errors\nfor match in fm.search_in_file(\"ERROR\", case_sensitive=False):\n    print(f\"Error at line {match['line_number']}: {match['match']}\")\n</code></pre>"},{"location":"PERFORMANCE_FEATURES/#memory-efficient-data-access","title":"Memory-Efficient Data Access","text":"<pre><code># Process large configuration files\nfm = YAPFileManager(\n    \"large_config.json\",\n    enable_lazy_loading=True,\n    enable_cache=True\n)\n\n# Only load sections when needed\nif user_needs_database_config:\n    db_config = fm.get_section(\"database\")\n    process_database_config(db_config)\n</code></pre>"},{"location":"PERFORMANCE_FEATURES/#best-practices","title":"\ud83d\udea8 Best Practices","text":""},{"location":"PERFORMANCE_FEATURES/#caching-best-practices","title":"Caching Best Practices","text":"<ol> <li>Choose Appropriate Cache Size: Balance memory usage with performance</li> <li>Set Reasonable TTL: Don't cache data that changes frequently</li> <li>Monitor Hit Rates: Aim for 80%+ hit rate</li> <li>Use Pattern Invalidation: Invalidate related cache entries together</li> <li>Clear Cache When Needed: Clear cache when data changes significantly</li> </ol>"},{"location":"PERFORMANCE_FEATURES/#lazy-loading-best-practices","title":"Lazy Loading Best Practices","text":"<ol> <li>Use for Large Sections: Only use lazy loading for sections that are large</li> <li>Monitor Memory Usage: Keep track of loaded sections</li> <li>Invalidate When Needed: Update lazy cache when sections change</li> <li>Consider Access Patterns: Disable lazy loading if sections are accessed frequently</li> </ol>"},{"location":"PERFORMANCE_FEATURES/#streaming-best-practices","title":"Streaming Best Practices","text":"<ol> <li>Choose Appropriate Chunk Size: Balance memory usage with I/O efficiency</li> <li>Use Progress Callbacks: Monitor long-running operations</li> <li>Handle Errors Gracefully: Streaming operations can fail on large files</li> <li>Consider File Size: Use streaming for files larger than available RAM</li> <li>Test with Different Chunk Sizes: Find the optimal chunk size for your use case</li> </ol>"},{"location":"PERFORMANCE_FEATURES/#troubleshooting","title":"\ud83d\udd0d Troubleshooting","text":""},{"location":"PERFORMANCE_FEATURES/#common-issues","title":"Common Issues","text":""},{"location":"PERFORMANCE_FEATURES/#low-cache-hit-rate","title":"Low Cache Hit Rate","text":"<ul> <li>Problem: Cache hit rate below 80%</li> <li>Solution: Increase cache size or check access patterns</li> </ul>"},{"location":"PERFORMANCE_FEATURES/#high-memory-usage","title":"High Memory Usage","text":"<ul> <li>Problem: Memory usage too high</li> <li>Solution: Reduce cache size or enable lazy loading</li> </ul>"},{"location":"PERFORMANCE_FEATURES/#slow-streaming","title":"Slow Streaming","text":"<ul> <li>Problem: Streaming operations are slow</li> <li>Solution: Adjust chunk size or check disk I/O performance</li> </ul>"},{"location":"PERFORMANCE_FEATURES/#performance-tips","title":"Performance Tips","text":"<ol> <li>Profile Your Application: Use profiling tools to identify bottlenecks</li> <li>Monitor Statistics: Regularly check cache and lazy loading statistics</li> <li>Test Different Configurations: Find the optimal settings for your use case</li> <li>Consider Your Data: Different data patterns require different optimizations</li> </ol>"},{"location":"PERFORMANCE_FEATURES/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<p>Planned enhancements include:</p> <ul> <li>Distributed Caching: Support for Redis and other distributed caches</li> <li>Compression: Automatic compression of cached data</li> <li>Encryption: Encrypted caching for sensitive data</li> <li>Metrics: More detailed performance metrics</li> <li>Profiling: Built-in profiling tools</li> <li>Visualization: Cache performance visualization tools</li> </ul> <p>For more detailed information, see the Caching &amp; Performance Guide and Examples.</p>"},{"location":"installation/","title":"Installation Guide","text":"<p>This guide covers how to install YAPFM and its dependencies on different platforms.</p>"},{"location":"installation/#requirements","title":"\ud83d\udccb Requirements","text":""},{"location":"installation/#python-version","title":"Python Version","text":"<ul> <li>Python 3.10+ (tested up to Python 3.13)</li> <li>pip or Poetry for package management</li> </ul>"},{"location":"installation/#dependencies","title":"Dependencies","text":"<ul> <li><code>tomlkit</code> (&gt;=0.13.3,&lt;0.14.0) - TOML file handling</li> <li><code>pyyaml</code> (&gt;=6.0.2,&lt;7.0.0) - YAML file handling</li> </ul> <p>Note: JSON support uses Python's built-in <code>json</code> module, so no additional dependencies are required.</p>"},{"location":"installation/#installation-methods","title":"\ud83d\ude80 Installation Methods","text":""},{"location":"installation/#method-1-pip-recommended","title":"Method 1: pip (Recommended)","text":"<pre><code># Install the latest version\npip install yapfm\n\n# Install a specific version\npip install yapfm==1.0.0\n\n# Install with development dependencies\npip install yapfm[dev]\n</code></pre>"},{"location":"installation/#method-2-poetry","title":"Method 2: Poetry","text":"<pre><code># Add to your project\npoetry add yapfm\n\n# Add development dependencies\npoetry add --group dev yapfm\n</code></pre>"},{"location":"installation/#method-3-from-source","title":"Method 3: From Source","text":"<pre><code># Clone the repository\ngit clone https://github.com/mawuva/yapfm.git\ncd yapfm\n\n# Install in development mode\npip install -e .\n\n# Or with Poetry\npoetry install\n</code></pre>"},{"location":"installation/#platform-specific-instructions","title":"\ud83d\udd27 Platform-Specific Instructions","text":""},{"location":"installation/#windows","title":"Windows","text":"<pre><code># Using PowerShell\npip install yapfm\n\n# Verify installation\npython -c \"import yapfm; print(yapfm.__version__)\"\n</code></pre>"},{"location":"installation/#macos","title":"macOS","text":"<pre><code># Using Homebrew Python\nbrew install python\npip3 install yapfm\n\n# Or using system Python\npython3 -m pip install yapfm\n</code></pre>"},{"location":"installation/#linux-ubuntudebian","title":"Linux (Ubuntu/Debian)","text":"<pre><code># Update package list\nsudo apt update\n\n# Install Python and pip if not already installed\nsudo apt install python3 python3-pip\n\n# Install YAPFM\npip3 install yapfm\n</code></pre>"},{"location":"installation/#linux-centosrhel","title":"Linux (CentOS/RHEL)","text":"<pre><code># Install Python and pip\nsudo yum install python3 python3-pip\n\n# Install YAPFM\npip3 install yapfm\n</code></pre>"},{"location":"installation/#docker-installation","title":"\ud83d\udc33 Docker Installation","text":""},{"location":"installation/#using-dockerfile","title":"Using Dockerfile","text":"<pre><code>FROM python:3.11-slim\n\n# Install YAPFM\nRUN pip install yapfm\n\n# Your application code here\nCOPY . /app\nWORKDIR /app\n</code></pre>"},{"location":"installation/#using-docker-compose","title":"Using Docker Compose","text":"<pre><code>version: '3.8'\nservices:\n  app:\n    build: .\n    environment:\n      - PYTHONPATH=/app\n    volumes:\n      - ./config:/app/config\n</code></pre>"},{"location":"installation/#verification","title":"\ud83d\udd0d Verification","text":"<p>After installation, verify that YAPFM is working correctly:</p> <pre><code># test_installation.py\nfrom yapfm import YAPFileManager, FileManagerProxy, FileStrategyRegistry\n\n# Test basic functionality\nfm = YAPFileManager(\"test.json\")\nprint(\"\u2705 YAPFileManager imported successfully\")\n\n# Test proxy\nproxy = FileManagerProxy(fm)\nprint(\"\u2705 FileManagerProxy imported successfully\")\n\n# Test registry\nstrategies = FileStrategyRegistry.get_supported_formats()\nprint(f\"\u2705 Supported formats: {strategies}\")\n\nprint(\"\ud83c\udf89 YAPFM installation verified!\")\n</code></pre> <p>Run the test:</p> <pre><code>python test_installation.py\n</code></pre>"},{"location":"installation/#development-setup","title":"\ud83d\udee0\ufe0f Development Setup","text":"<p>If you're contributing to YAPFM or want to run the tests:</p>"},{"location":"installation/#clone-and-setup","title":"Clone and Setup","text":"<pre><code># Clone the repository\ngit clone https://github.com/mawuva/yapfm.git\ncd yapfm\n\n# Install in development mode with all dependencies\npip install -e \".[dev]\"\n\n# Or with Poetry\npoetry install --with dev\n</code></pre>"},{"location":"installation/#development-dependencies","title":"Development Dependencies","text":"<p>The development dependencies include:</p> <ul> <li><code>pytest</code> - Testing framework</li> <li><code>pytest-cov</code> - Coverage reporting</li> <li><code>ruff</code> - Linting and formatting</li> <li><code>black</code> - Code formatting</li> <li><code>isort</code> - Import sorting</li> <li><code>mypy</code> - Type checking</li> <li><code>pre-commit</code> - Git hooks</li> </ul>"},{"location":"installation/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest\n\n# Run with coverage\npytest --cov=yapfm\n\n# Run specific test file\npytest tests/test_manager.py\n</code></pre>"},{"location":"installation/#code-quality","title":"Code Quality","text":"<pre><code># Format code\nblack src/ tests/\n\n# Sort imports\nisort src/ tests/\n\n# Lint code\nruff check src/ tests/\n\n# Type check\nmypy src/\n</code></pre>"},{"location":"installation/#troubleshooting","title":"\ud83d\udea8 Troubleshooting","text":""},{"location":"installation/#common-installation-issues","title":"Common Installation Issues","text":""},{"location":"installation/#1-permission-denied","title":"1. Permission Denied","text":"<pre><code># Use --user flag\npip install --user yapfm\n\n# Or use virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\npip install yapfm\n</code></pre>"},{"location":"installation/#2-toml-dependencies-issues","title":"2. TOML Dependencies Issues","text":"<pre><code># Update pip first\npip install --upgrade pip\n\n# Install with specific TOML version\npip install tomlkit==0.13.3\npip install yapfm\n</code></pre>"},{"location":"installation/#3-yaml-dependencies-issues","title":"3. YAML Dependencies Issues","text":"<pre><code># Install PyYAML separately\npip install pyyaml&gt;=6.0.2\npip install yapfm\n</code></pre>"},{"location":"installation/#4-python-version-issues","title":"4. Python Version Issues","text":"<pre><code># Check Python version\npython --version\n\n# Use specific Python version\npython3.10 -m pip install yapfm\n</code></pre>"},{"location":"installation/#platform-specific-issues","title":"Platform-Specific Issues","text":""},{"location":"installation/#windows-microsoft-visual-c-140-required","title":"Windows: Microsoft Visual C++ 14.0 Required","text":"<p>If you encounter this error, install Visual Studio Build Tools:</p> <ol> <li>Download from Microsoft's website</li> <li>Install \"C++ build tools\"</li> <li>Restart your terminal</li> <li>Try installing again</li> </ol>"},{"location":"installation/#macos-xcode-command-line-tools","title":"macOS: Xcode Command Line Tools","text":"<pre><code># Install Xcode command line tools\nxcode-select --install\n\n# Then install YAPFM\npip install yapfm\n</code></pre>"},{"location":"installation/#linux-missing-development-headers","title":"Linux: Missing Development Headers","text":"<pre><code># Ubuntu/Debian\nsudo apt install python3-dev build-essential\n\n# CentOS/RHEL\nsudo yum install python3-devel gcc\n</code></pre>"},{"location":"installation/#virtual-environments","title":"\ud83d\udce6 Virtual Environments","text":""},{"location":"installation/#using-venv","title":"Using venv","text":"<pre><code># Create virtual environment\npython -m venv yapfm-env\n\n# Activate (Linux/macOS)\nsource yapfm-env/bin/activate\n\n# Activate (Windows)\nyapfm-env\\Scripts\\activate\n\n# Install YAPFM\npip install yapfm\n\n# Deactivate when done\ndeactivate\n</code></pre>"},{"location":"installation/#using-conda","title":"Using conda","text":"<pre><code># Create conda environment\nconda create -n yapfm-env python=3.11\n\n# Activate environment\nconda activate yapfm-env\n\n# Install YAPFM\npip install yapfm\n</code></pre>"},{"location":"installation/#upgrading","title":"\ud83d\udd04 Upgrading","text":""},{"location":"installation/#upgrade-to-latest-version","title":"Upgrade to Latest Version","text":"<pre><code># Using pip\npip install --upgrade yapfm\n\n# Using Poetry\npoetry update yapfm\n</code></pre>"},{"location":"installation/#check-current-version","title":"Check Current Version","text":"<pre><code>import yapfm\nprint(yapfm.__version__)\n</code></pre>"},{"location":"installation/#next-steps","title":"\ud83d\udcdd Next Steps","text":"<p>After successful installation:</p> <ol> <li>Read the Quick Start Guide</li> <li>Follow the User Guide</li> <li>Explore Examples</li> <li>Check the API Reference</li> </ol> <p>Having trouble with installation? Check our Troubleshooting Guide or open an issue on GitHub.</p>"},{"location":"quick_start/","title":"Quick Start Guide","text":"<p>Get up and running with YAPFM in just a few minutes! This guide will walk you through the essential features and common usage patterns.</p>"},{"location":"quick_start/#installation","title":"\ud83d\ude80 Installation","text":"<p>First, install YAPFM:</p> <pre><code>pip install yapfm\n</code></pre>"},{"location":"quick_start/#basic-usage","title":"\ud83d\udcdd Basic Usage","text":""},{"location":"quick_start/#1-simple-file-operations","title":"1. Simple File Operations","text":"<pre><code>from yapfm import YAPFileManager\n\n# Create a file manager for a JSON file\nfm = YAPFileManager(\"config.json\")\n\n# Load the file (creates empty document if file doesn't exist)\nfm.load()\n\n# Set some configuration values\nfm.set_key(\"localhost\", dot_key=\"database.host\")\nfm.set_key(5432, dot_key=\"database.port\")\nfm.set_key(\"myapp\", dot_key=\"database.name\")\n\n# Save changes\nfm.save()\n\n# Read values back\nhost = fm.get_key(dot_key=\"database.host\")\nprint(f\"Database host: {host}\")  # Output: Database host: localhost\n</code></pre>"},{"location":"quick_start/#2-context-manager-recommended","title":"2. Context Manager (Recommended)","text":"<pre><code>from yapfm import YAPFileManager\n\n# Automatic loading and saving with context manager\nwith YAPFileManager(\"config.toml\", auto_create=True) as fm:\n    # Set configuration values\n    fm.set_key(\"production\", dot_key=\"environment\")\n    fm.set_key(True, dot_key=\"debug\")\n\n    # Set entire sections\n    fm.set_section({\n        \"host\": \"localhost\",\n        \"port\": 8000,\n        \"workers\": 4\n    }, dot_key=\"server\")\n\n# File is automatically saved when exiting the context\n</code></pre>"},{"location":"quick_start/#key-features","title":"\ud83c\udfaf Key Features","text":""},{"location":"quick_start/#dot-notation-access","title":"Dot Notation Access","text":"<p>YAPFM uses dot notation to access nested data:</p> <pre><code># Set nested values\nfm.set_key(\"value\", dot_key=\"section.subsection.key\")\n\n# Get nested values with defaults\nvalue = fm.get_key(dot_key=\"section.subsection.key\", default=\"default\")\n\n# Check if key exists\nexists = fm.has_key(dot_key=\"section.subsection.key\")\n\n# Delete keys\ndeleted = fm.delete_key(dot_key=\"section.subsection.key\")\n</code></pre>"},{"location":"quick_start/#section-operations","title":"Section Operations","text":"<p>Work with entire sections of configuration:</p> <pre><code># Set entire sections\nfm.set_section({\n    \"host\": \"localhost\",\n    \"port\": 5432,\n    \"ssl\": True\n}, dot_key=\"database\")\n\n# Get entire sections\ndb_config = fm.get_section(dot_key=\"database\")\n\n# Check if section exists\nhas_section = fm.has_section(dot_key=\"database\")\n</code></pre>"},{"location":"quick_start/#multiple-file-formats","title":"Multiple File Formats","text":"<p>YAPFM automatically detects file format based on extension:</p> <pre><code># JSON file\njson_fm = YAPFileManager(\"config.json\")\n\n# TOML file\ntoml_fm = YAPFileManager(\"config.toml\")\n\n# YAML file\nyaml_fm = YAPFileManager(\"config.yaml\")\n</code></pre>"},{"location":"quick_start/#using-the-open_file-helper","title":"Using the open_file Helper","text":"<p>For a more convenient way to open files:</p> <pre><code>from yapfm.helpers import open_file\n\n# Automatic format detection\nfm = open_file(\"config.json\")\n\n# Force a specific format regardless of extension\nfm = open_file(\"config.txt\", format=\"toml\")\n\n# Auto-create file if it doesn't exist\nfm = open_file(\"new_config.json\", auto_create=True)\n\n# Use the file manager\nwith fm:\n    fm.set_key(\"value\", dot_key=\"key\")\n</code></pre>"},{"location":"quick_start/#common-patterns","title":"\ud83d\udd27 Common Patterns","text":""},{"location":"quick_start/#1-configuration-management","title":"1. Configuration Management","text":"<pre><code>from yapfm import YAPFileManager\n\ndef load_app_config():\n    \"\"\"Load application configuration with defaults.\"\"\"\n    with YAPFileManager(\"app_config.json\", auto_create=True) as fm:\n        # Set defaults if not present\n        if not fm.has_key(dot_key=\"app.name\"):\n            fm.set_key(\"My App\", dot_key=\"app.name\")\n\n        if not fm.has_key(dot_key=\"app.version\"):\n            fm.set_key(\"1.0.0\", dot_key=\"app.version\")\n\n        if not fm.has_key(dot_key=\"database.host\"):\n            fm.set_key(\"localhost\", dot_key=\"database.host\")\n\n        return fm.data\n\n# Use the configuration\nconfig = load_app_config()\nprint(f\"App: {config['app']['name']} v{config['app']['version']}\")\n</code></pre>"},{"location":"quick_start/#2-environment-specific-configuration","title":"2. Environment-Specific Configuration","text":"<pre><code>import os\nfrom yapfm import YAPFileManager\n\ndef get_config_for_environment(env=\"development\"):\n    \"\"\"Load configuration for specific environment.\"\"\"\n    config_file = f\"config_{env}.json\"\n\n    with YAPFileManager(config_file, auto_create=True) as fm:\n        # Set environment-specific defaults\n        fm.set_key(env, dot_key=\"environment\")\n\n        if env == \"development\":\n            fm.set_key(True, dot_key=\"debug\")\n            fm.set_key(\"localhost\", dot_key=\"database.host\")\n        elif env == \"production\":\n            fm.set_key(False, dot_key=\"debug\")\n            fm.set_key(\"prod-db.example.com\", dot_key=\"database.host\")\n\n        return fm.data\n\n# Load configuration for current environment\nenv = os.getenv(\"ENVIRONMENT\", \"development\")\nconfig = get_config_for_environment(env)\n</code></pre>"},{"location":"quick_start/#3-configuration-validation","title":"3. Configuration Validation","text":"<pre><code>from yapfm import YAPFileManager\n\ndef validate_config(config):\n    \"\"\"Validate required configuration keys.\"\"\"\n    required_keys = [\n        \"database.host\",\n        \"database.port\",\n        \"app.name\",\n        \"app.version\"\n    ]\n\n    missing_keys = []\n    for key in required_keys:\n        if not config.has_key(dot_key=key):\n            missing_keys.append(key)\n\n    if missing_keys:\n        raise ValueError(f\"Missing required configuration keys: {missing_keys}\")\n\n    return True\n\n# Use validation\nwith YAPFileManager(\"config.json\") as fm:\n    validate_config(fm)\n    print(\"Configuration is valid!\")\n</code></pre>"},{"location":"quick_start/#advanced-usage","title":"\ud83c\udfa8 Advanced Usage","text":""},{"location":"quick_start/#proxy-with-logging","title":"Proxy with Logging","text":"<pre><code>from yapfm import YAPFileManager, FileManagerProxy\nimport logging\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\n\n# Create file manager\nfm = YAPFileManager(\"app_config.json\")\n\n# Create proxy with logging and metrics\nproxy = FileManagerProxy(\n    fm,\n    enable_logging=True,\n    enable_metrics=True,\n    enable_audit=True\n)\n\n# All operations are logged and measured\nwith proxy:\n    proxy.set_key(\"v1.0.0\", dot_key=\"app.version\")\n    proxy.set_key(\"production\", dot_key=\"app.environment\")\n</code></pre>"},{"location":"quick_start/#custom-audit-hook","title":"Custom Audit Hook","text":"<pre><code>def audit_hook(method, args, kwargs, result):\n    \"\"\"Custom audit hook for tracking changes.\"\"\"\n    print(f\"\ud83d\udd0d AUDIT: {method} called with {args}, {kwargs} =&gt; {result}\")\n\n# Use custom audit hook\nproxy = FileManagerProxy(\n    fm,\n    enable_audit=True,\n    audit_hook=audit_hook\n)\n</code></pre>"},{"location":"quick_start/#file-status-operations","title":"\ud83d\udcca File Status Operations","text":"<pre><code>from yapfm import YAPFileManager\n\nfm = YAPFileManager(\"config.json\")\n\n# Check file status\nprint(f\"File exists: {fm.exists()}\")\nprint(f\"File loaded: {fm.is_loaded()}\")\nprint(f\"File dirty: {fm.is_dirty()}\")\n\n# Manual operations\nfm.load()      # Load from disk\nfm.save()      # Save to disk\nfm.reload()    # Reload from disk (discards changes)\nfm.unload()    # Unload from memory\n</code></pre>"},{"location":"quick_start/#lazy-save-context","title":"\ud83d\udd04 Lazy Save Context","text":"<pre><code>from yapfm import YAPFileManager\n\nwith YAPFileManager(\"config.json\") as fm:\n    # Make multiple changes\n    with fm.lazy_save():\n        fm.set_key(\"value1\", dot_key=\"key1\")\n        fm.set_key(\"value2\", dot_key=\"key2\")\n        fm.set_key(\"value3\", dot_key=\"key3\")\n        # Save happens here when exiting the lazy_save context\n</code></pre>"},{"location":"quick_start/#supported-file-formats","title":"\ud83c\udfaf Supported File Formats","text":"Format Extension Example JSON <code>.json</code> <code>config.json</code> TOML <code>.toml</code> <code>config.toml</code> YAML <code>.yml</code>, <code>.yaml</code> <code>config.yaml</code>"},{"location":"quick_start/#error-handling","title":"\ud83d\udea8 Error Handling","text":"<pre><code>from yapfm import YAPFileManager\nfrom yapfm.exceptions import LoadFileError, FileWriteError\n\ntry:\n    with YAPFileManager(\"config.json\") as fm:\n        fm.set_key(\"value\", dot_key=\"key\")\n        fm.save()\nexcept LoadFileError as e:\n    print(f\"Failed to load file: {e}\")\nexcept FileWriteError as e:\n    print(f\"Failed to save file: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"quick_start/#next-steps","title":"\ud83d\udcda Next Steps","text":"<p>Now that you've got the basics down:</p> <ol> <li>Read the User Guide for comprehensive usage patterns</li> <li>Explore Examples for real-world scenarios</li> <li>Check the API Reference for complete documentation</li> <li>Learn Advanced Features for power users</li> </ol>"},{"location":"quick_start/#tips-and-best-practices","title":"\ud83d\udca1 Tips and Best Practices","text":"<ol> <li>Use context managers for automatic file handling</li> <li>Set <code>auto_create=True</code> for configuration files that might not exist</li> <li>Use dot notation for cleaner, more readable code</li> <li>Validate configuration before using it in production</li> <li>Use proxy pattern for logging and monitoring in production</li> <li>Handle exceptions gracefully for better user experience</li> </ol> <p>Ready to dive deeper? Check out the User Guide for comprehensive usage patterns and advanced features.</p>"},{"location":"advanced/","title":"Advanced Features","text":"<p>This guide covers advanced features of YAPFM, including proxy patterns, custom strategies, mixins, and performance optimization techniques.</p>"},{"location":"advanced/#table-of-contents","title":"\ud83d\udcda Table of Contents","text":"<ol> <li>Caching &amp; Performance - Intelligent caching, lazy loading, and streaming capabilities</li> <li>Proxy Pattern - Monitoring, logging, and auditing file operations</li> <li>Custom Strategies - Creating custom file format strategies</li> <li>Mixins Deep Dive - Creating and using custom mixins</li> <li>Performance Optimization - Lazy loading and memory-efficient processing</li> <li>Thread Safety - Thread-safe file manager implementations</li> <li>Memory Management - Memory-efficient file manager features</li> <li>Advanced Context Management - Nested context managers and transactions</li> <li>Plugin Architecture - Extending functionality with plugins</li> </ol>"},{"location":"advanced/#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Need caching and performance features? Check Caching &amp; Performance</li> <li>Need monitoring capabilities? Check Proxy Pattern</li> <li>Want to support new file formats? See Custom Strategies</li> <li>Looking to extend functionality? Read Mixins Deep Dive</li> <li>Performance is critical? Go to Performance Optimization</li> <li>Working with multiple threads? Browse Thread Safety</li> <li>Memory usage is a concern? See Memory Management</li> <li>Need complex context handling? Check Advanced Context Management</li> <li>Want to build extensible systems? Explore Plugin Architecture</li> </ul>"},{"location":"advanced/#additional-resources","title":"Additional Resources","text":"<ul> <li>User Guide - Basic usage and common patterns</li> <li>API Reference - Complete API documentation</li> <li>Examples - More code examples and use cases</li> <li>Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"advanced/advanced_context_management/","title":"Advanced Context Management","text":""},{"location":"advanced/advanced_context_management/#nested-context-managers","title":"Nested Context Managers","text":"<pre><code>from yapfm import YAPFileManager\nfrom contextlib import contextmanager\nfrom typing import Iterator, Dict, Any\n\nclass NestedContextManager:\n    \"\"\"Advanced context manager with nested operations.\"\"\"\n\n    def __init__(self, path: str):\n        self.path = path\n        self._fm = YAPFileManager(path, auto_create=True)\n        self._context_level = 0\n\n    @contextmanager\n    def transaction(self) -&gt; Iterator[Dict[str, Any]]:\n        \"\"\"Transaction context with rollback capability.\"\"\"\n        self._context_level += 1\n        original_data = None\n\n        try:\n            with self._fm:\n                # Save original state\n                original_data = self._fm.data.copy()\n                yield self._fm.data\n        except Exception as e:\n            # Rollback on error\n            if original_data is not None:\n                with self._fm:\n                    self._fm.data = original_data\n            raise e\n        finally:\n            self._context_level -= 1\n\n    @contextmanager\n    def batch_operations(self) -&gt; Iterator[Dict[str, Any]]:\n        \"\"\"Batch operations context.\"\"\"\n        with self._fm:\n            with self._fm.lazy_save():\n                yield self._fm.data\n\n    @contextmanager\n    def read_only(self) -&gt; Iterator[Dict[str, Any]]:\n        \"\"\"Read-only context that prevents modifications.\"\"\"\n        with self._fm:\n            # Create a read-only view\n            class ReadOnlyView:\n                def __init__(self, data):\n                    self._data = data\n\n                def __getitem__(self, key):\n                    return self._data[key]\n\n                def __setitem__(self, key, value):\n                    raise RuntimeError(\"Modifications not allowed in read-only context\")\n\n                def get(self, key, default=None):\n                    return self._data.get(key, default)\n\n                def keys(self):\n                    return self._data.keys()\n\n                def values(self):\n                    return self._data.values()\n\n                def items(self):\n                    return self._data.items()\n\n            yield ReadOnlyView(self._fm.data)\n\n# Usage\nnested_fm = NestedContextManager(\"nested_config.json\")\n\n# Transaction context\ntry:\n    with nested_fm.transaction() as data:\n        data[\"key1\"] = \"value1\"\n        data[\"key2\"] = \"value2\"\n        # If an exception occurs here, changes are rolled back\nexcept Exception as e:\n    print(f\"Transaction failed: {e}\")\n\n# Batch operations\nwith nested_fm.batch_operations() as data:\n    data[\"key3\"] = \"value3\"\n    data[\"key4\"] = \"value4\"\n    # All changes are saved when exiting the context\n\n# Read-only context\nwith nested_fm.read_only() as data:\n    value = data[\"key1\"]  # OK\n    # data[\"key5\"] = \"value5\"  # This would raise an error\n</code></pre>"},{"location":"advanced/caching_performance/","title":"Caching &amp; Performance","text":"<p>This document covers YAPFM's advanced caching and performance features, including intelligent caching, lazy loading, and streaming capabilities.</p>"},{"location":"advanced/caching_performance/#overview","title":"\ud83d\ude80 Overview","text":"<p>YAPFM provides powerful caching and performance features that significantly improve speed, memory efficiency, and usability:</p> <ul> <li>Intelligent Caching System: Smart caching with TTL, LRU eviction, and comprehensive statistics</li> <li>Lazy Loading: Memory-efficient loading of large sections</li> <li>Streaming Support: Process files larger than available RAM</li> <li>Unified Architecture: Centralized cache management and key generation</li> </ul>"},{"location":"advanced/caching_performance/#intelligent-caching-cachemixin","title":"\ud83e\udde0 Intelligent Caching (CacheMixin)","text":""},{"location":"advanced/caching_performance/#features","title":"Features","text":"<p>The new caching system provides:</p> <ul> <li>Automatic Caching: Values are automatically cached on first access</li> <li>TTL Support: Time-to-live for cached entries</li> <li>LRU Eviction: Least Recently Used eviction when cache is full</li> <li>Memory Management: Size-based eviction to prevent memory issues</li> <li>Statistics Tracking: Hit/miss ratios and performance metrics</li> <li>Pattern Invalidation: Invalidate cache entries using wildcard patterns</li> <li>Thread Safety: Safe for use in multi-threaded environments</li> </ul>"},{"location":"advanced/caching_performance/#basic-usage","title":"Basic Usage","text":"<pre><code>from yapfm import YAPFileManager\n\n# Enable caching\nfm = YAPFileManager(\n    \"config.json\",\n    enable_cache=True,\n    cache_size=1000,      # Maximum number of cached entries\n    cache_ttl=3600        # TTL in seconds (1 hour)\n)\n\n# First access loads from file and caches\nhost = fm.get_value(\"database.host\")\nprint(f\"Database host: {host}\")\n\n# Subsequent accesses return from cache (much faster)\nhost_cached = fm.get_value(\"database.host\")  # Returns from cache\n</code></pre>"},{"location":"advanced/caching_performance/#advanced-caching","title":"Advanced Caching","text":"<pre><code># Get cache statistics\nstats = fm.get_cache_stats()\nprint(f\"Cache hits: {stats['unified_cache']['hits']}\")\nprint(f\"Cache misses: {stats['unified_cache']['misses']}\")\nprint(f\"Hit rate: {stats['unified_cache']['hit_rate']:.2%}\")\n\n# Invalidate specific patterns\nfm.invalidate_cache(\"key:database.*\")  # Invalidate all database keys\n\n# Clear all cache\nfm.clear_cache()\n</code></pre>"},{"location":"advanced/caching_performance/#performance-benefits","title":"Performance Benefits","text":"<ul> <li>Speed: Cached values are returned instantly</li> <li>Memory Efficient: LRU eviction prevents memory bloat</li> <li>Configurable: Adjust cache size and TTL based on your needs</li> <li>Statistics: Monitor cache performance and optimize usage</li> </ul>"},{"location":"advanced/caching_performance/#lazy-loading-lazysectionsmixin","title":"\ud83c\udfaf Lazy Loading (LazySectionsMixin)","text":""},{"location":"advanced/caching_performance/#features_1","title":"Features","text":"<p>Lazy loading provides:</p> <ul> <li>Memory Efficiency: Sections are loaded only when accessed</li> <li>Performance: Avoid loading large sections unnecessarily</li> <li>Cache Integration: Works seamlessly with the unified cache system</li> <li>Automatic Invalidation: Cache invalidation when sections are modified</li> <li>Statistics: Monitor lazy loading performance</li> </ul>"},{"location":"advanced/caching_performance/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from yapfm import YAPFileManager\n\n# Enable lazy loading\nfm = YAPFileManager(\n    \"large_config.json\",\n    enable_lazy_loading=True\n)\n\n# Section is not loaded until accessed\ndb_section = fm.get_section(\"database\")  # Loads only when accessed\nprint(f\"Database host: {db_section['host']}\")\n\n# Subsequent accesses return from lazy cache\ndb_section_again = fm.get_section(\"database\")  # Returns from cache\n</code></pre>"},{"location":"advanced/caching_performance/#advanced-lazy-loading","title":"Advanced Lazy Loading","text":"<pre><code># Force immediate loading (bypass lazy loading)\ndb_section = fm.get_section(\"database\", lazy=False)\n\n# Update section with cache invalidation\nfm.set_section({\n    \"host\": \"newhost\",\n    \"port\": 3306\n}, dot_key=\"database\", update_lazy_cache=True)\n\n# Get lazy loading statistics\nstats = fm.get_lazy_stats()\nprint(f\"Total sections: {stats['total_sections']}\")\nprint(f\"Loaded sections: {stats['loaded_sections']}\")\n\n# Clear lazy cache\nfm.clear_lazy_cache()\n</code></pre>"},{"location":"advanced/caching_performance/#memory-benefits","title":"Memory Benefits","text":"<ul> <li>Reduced Memory Usage: Only load sections when needed</li> <li>Faster Startup: Don't load entire file at startup</li> <li>Selective Loading: Load only the sections you actually use</li> <li>Automatic Management: Cache invalidation when sections change</li> </ul>"},{"location":"advanced/caching_performance/#streaming-support-streamingmixin","title":"\ud83c\udf0a Streaming Support (StreamingMixin)","text":""},{"location":"advanced/caching_performance/#features_2","title":"Features","text":"<p>Streaming provides:</p> <ul> <li>Large File Support: Process files larger than available RAM</li> <li>Chunked Reading: Process files in configurable chunks</li> <li>Memory Efficient: Constant memory usage regardless of file size</li> <li>Multiple Formats: Support for different file encodings</li> <li>Progress Tracking: Monitor processing progress</li> <li>Search Capabilities: Search within large files</li> <li>Section Extraction: Extract specific sections from large files</li> </ul>"},{"location":"advanced/caching_performance/#basic-usage_2","title":"Basic Usage","text":"<pre><code>from yapfm import YAPFileManager\n\n# Enable streaming\nfm = YAPFileManager(\n    \"large_file.txt\",\n    enable_streaming=True\n)\n\n# Stream file in chunks\nfor chunk in fm.stream_file(chunk_size=1024*1024):  # 1MB chunks\n    process_chunk(chunk)\n\n# Stream line by line\nfor line in fm.stream_lines():\n    if \"error\" in line.lower():\n        print(f\"Error found: {line}\")\n</code></pre>"},{"location":"advanced/caching_performance/#advanced-streaming","title":"Advanced Streaming","text":"<pre><code># Stream sections with markers\nfor section in fm.stream_sections(\"[\", \"]\"):\n    print(f\"Section: {section['name']}\")\n    print(f\"Content: {section['content']}\")\n\n# Process with custom function\ndef count_lines(chunk):\n    return chunk.count('\\n')\n\ndef progress_callback(progress):\n    print(f\"Progress: {progress:.1%}\")\n\nresults = list(fm.process_large_file(count_lines, progress_callback))\ntotal_lines = sum(results)\n\n# Search in large file\nfor match in fm.search_in_file(\"error\", case_sensitive=False):\n    print(f\"Found: {match['match']}\")\n    print(f\"Context: {match['context']}\")\n\n# Get file information\nsize = fm.get_file_size()\nprogress = fm.get_file_progress()\nestimated_time = fm.estimate_processing_time(count_lines)\n</code></pre>"},{"location":"advanced/caching_performance/#performance-benefits_1","title":"Performance Benefits","text":"<ul> <li>Memory Efficient: Process files of any size</li> <li>Configurable: Adjust chunk size based on available memory</li> <li>Progress Tracking: Monitor long-running operations</li> <li>Search Capabilities: Find patterns in large files efficiently</li> </ul>"},{"location":"advanced/caching_performance/#unified-architecture","title":"\ud83c\udfd7\ufe0f Unified Architecture","text":""},{"location":"advanced/caching_performance/#centralized-cache-management","title":"Centralized Cache Management","text":"<p>The new architecture provides:</p> <ul> <li>Unified Cache: Single cache instance for all operations</li> <li>Key Generation: Centralized key generation with caching</li> <li>Statistics: Comprehensive statistics across all caching mechanisms</li> <li>Memory Management: Centralized memory management and cleanup</li> </ul>"},{"location":"advanced/caching_performance/#key-generation-optimization","title":"Key Generation Optimization","text":"<pre><code># Key generation is now cached for performance\nkey1 = fm._generate_cache_key(\"database.host\", None, None, \"key\")\nkey2 = fm._generate_cache_key(\"database.host\", None, None, \"key\")  # Returns cached key\n\n# Clear key generation cache\nfm.clear_key_cache()\n</code></pre>"},{"location":"advanced/caching_performance/#comprehensive-statistics","title":"Comprehensive Statistics","text":"<pre><code># Get unified statistics\nstats = fm.get_cache_stats()\nprint(\"Unified Cache Stats:\")\nprint(f\"  Hits: {stats['unified_cache']['hits']}\")\nprint(f\"  Misses: {stats['unified_cache']['misses']}\")\nprint(f\"  Hit Rate: {stats['unified_cache']['hit_rate']:.2%}\")\n\nprint(\"Lazy Sections Stats:\")\nprint(f\"  Total Sections: {stats['lazy_sections']['total_sections']}\")\nprint(f\"  Loaded Sections: {stats['lazy_sections']['loaded_sections']}\")\n\nprint(\"Key Cache Stats:\")\nprint(f\"  Size: {stats['key_cache']['size']}\")\n</code></pre>"},{"location":"advanced/caching_performance/#configuration-examples","title":"\ud83d\udd27 Configuration Examples","text":""},{"location":"advanced/caching_performance/#high-performance-configuration","title":"High-Performance Configuration","text":"<pre><code># For high-performance applications\nfm = YAPFileManager(\n    \"config.json\",\n    enable_cache=True,\n    cache_size=10000,     # Large cache\n    cache_ttl=7200,       # 2 hours TTL\n    enable_lazy_loading=True,\n    enable_streaming=True\n)\n</code></pre>"},{"location":"advanced/caching_performance/#memory-conscious-configuration","title":"Memory-Conscious Configuration","text":"<pre><code># For memory-constrained environments\nfm = YAPFileManager(\n    \"config.json\",\n    enable_cache=True,\n    cache_size=100,       # Small cache\n    cache_ttl=300,        # 5 minutes TTL\n    enable_lazy_loading=True,\n    enable_streaming=True\n)\n</code></pre>"},{"location":"advanced/caching_performance/#development-configuration","title":"Development Configuration","text":"<pre><code># For development with frequent changes\nfm = YAPFileManager(\n    \"config.json\",\n    enable_cache=True,\n    cache_size=1000,\n    cache_ttl=60,         # Short TTL for development\n    enable_lazy_loading=False,  # Disable for easier debugging\n    enable_streaming=True\n)\n</code></pre>"},{"location":"advanced/caching_performance/#performance-monitoring","title":"\ud83d\udcca Performance Monitoring","text":""},{"location":"advanced/caching_performance/#cache-performance","title":"Cache Performance","text":"<pre><code># Monitor cache performance\nstats = fm.get_cache_stats()\nhit_rate = stats['unified_cache']['hit_rate']\n\nif hit_rate &lt; 0.8:  # Less than 80% hit rate\n    print(\"Warning: Low cache hit rate, consider increasing cache size\")\n    fm.clear_cache()  # Clear cache and start fresh\n</code></pre>"},{"location":"advanced/caching_performance/#memory-usage","title":"Memory Usage","text":"<pre><code># Monitor memory usage\nstats = fm.get_cache_stats()\nmemory_usage = stats['unified_cache']['memory_usage_mb']\n\nif memory_usage &gt; 50:  # More than 50MB\n    print(\"Warning: High memory usage, consider reducing cache size\")\n    fm.clear_cache()\n</code></pre>"},{"location":"advanced/caching_performance/#lazy-loading-efficiency","title":"Lazy Loading Efficiency","text":"<pre><code># Monitor lazy loading efficiency\nstats = fm.get_lazy_stats()\nloaded_ratio = stats['loaded_sections'] / stats['total_sections']\n\nif loaded_ratio &gt; 0.5:  # More than 50% of sections loaded\n    print(\"Warning: High lazy loading ratio, consider disabling lazy loading\")\n</code></pre>"},{"location":"advanced/caching_performance/#best-practices","title":"\ud83d\udea8 Best Practices","text":""},{"location":"advanced/caching_performance/#caching-best-practices","title":"Caching Best Practices","text":"<ol> <li>Choose Appropriate Cache Size: Balance memory usage with performance</li> <li>Set Reasonable TTL: Don't cache data that changes frequently</li> <li>Monitor Hit Rates: Aim for 80%+ hit rate</li> <li>Use Pattern Invalidation: Invalidate related cache entries together</li> <li>Clear Cache When Needed: Clear cache when data changes significantly</li> </ol>"},{"location":"advanced/caching_performance/#lazy-loading-best-practices","title":"Lazy Loading Best Practices","text":"<ol> <li>Use for Large Sections: Only use lazy loading for sections that are large</li> <li>Monitor Memory Usage: Keep track of loaded sections</li> <li>Invalidate When Needed: Update lazy cache when sections change</li> <li>Consider Access Patterns: Disable lazy loading if sections are accessed frequently</li> </ol>"},{"location":"advanced/caching_performance/#streaming-best-practices","title":"Streaming Best Practices","text":"<ol> <li>Choose Appropriate Chunk Size: Balance memory usage with I/O efficiency</li> <li>Use Progress Callbacks: Monitor long-running operations</li> <li>Handle Errors Gracefully: Streaming operations can fail on large files</li> <li>Consider File Size: Use streaming for files larger than available RAM</li> <li>Test with Different Chunk Sizes: Find the optimal chunk size for your use case</li> </ol>"},{"location":"advanced/caching_performance/#migration-guide","title":"\ud83d\udd04 Migration Guide","text":""},{"location":"advanced/caching_performance/#from-basic-to-cached","title":"From Basic to Cached","text":"<pre><code># Old way\nhost = fm.get_key(\"database.host\")\n\n# New way with caching\nhost = fm.get_value(\"database.host\")  # Automatically cached\n</code></pre>"},{"location":"advanced/caching_performance/#from-immediate-to-lazy-loading","title":"From Immediate to Lazy Loading","text":"<pre><code># Old way\nsection = fm.get_section(\"database\")\n\n# New way with lazy loading\nsection = fm.get_section(\"database\", lazy=True)  # Lazy loaded\n</code></pre>"},{"location":"advanced/caching_performance/#adding-streaming-support","title":"Adding Streaming Support","text":"<pre><code># For large files\nfm = YAPFileManager(\"large_file.txt\", enable_streaming=True)\n\n# Process in chunks\nfor chunk in fm.stream_file():\n    process_chunk(chunk)\n</code></pre>"},{"location":"advanced/caching_performance/#use-cases","title":"\ud83c\udfaf Use Cases","text":""},{"location":"advanced/caching_performance/#configuration-management","title":"Configuration Management","text":"<pre><code># High-performance configuration management\nfm = YAPFileManager(\n    \"app_config.json\",\n    enable_cache=True,\n    cache_size=1000,\n    cache_ttl=3600,\n    enable_lazy_loading=True\n)\n\n# Fast access to frequently used values\ndb_host = fm.get_value(\"database.host\")\napi_key = fm.get_value(\"api.key\")\n</code></pre>"},{"location":"advanced/caching_performance/#large-file-processing","title":"Large File Processing","text":"<pre><code># Process large log files\nfm = YAPFileManager(\"access.log\", enable_streaming=True)\n\n# Search for errors\nfor match in fm.search_in_file(\"ERROR\", case_sensitive=False):\n    print(f\"Error at line {match['line_number']}: {match['match']}\")\n</code></pre>"},{"location":"advanced/caching_performance/#memory-efficient-data-access","title":"Memory-Efficient Data Access","text":"<pre><code># Process large configuration files\nfm = YAPFileManager(\n    \"large_config.json\",\n    enable_lazy_loading=True,\n    enable_cache=True\n)\n\n# Only load sections when needed\nif user_needs_database_config:\n    db_config = fm.get_section(\"database\")\n    process_database_config(db_config)\n</code></pre>"},{"location":"advanced/caching_performance/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":"<p>Planned enhancements include:</p> <ul> <li>Distributed Caching: Support for Redis and other distributed caches</li> <li>Compression: Automatic compression of cached data</li> <li>Encryption: Encrypted caching for sensitive data</li> <li>Metrics: More detailed performance metrics</li> <li>Profiling: Built-in profiling tools</li> <li>Visualization: Cache performance visualization tools</li> </ul> <p>For more information about these features, see the API Reference and Examples.</p>"},{"location":"advanced/custom_strategies/","title":"Custom Strategies","text":"<p>Creating custom strategies allows you to support new file formats or customize existing ones.</p>"},{"location":"advanced/custom_strategies/#basic-custom-strategy","title":"Basic Custom Strategy","text":"<pre><code>from yapfm.strategies import BaseFileStrategy\nfrom yapfm.registry import register_file_strategy\nfrom pathlib import Path\nfrom typing import Any, List, Optional, Union\nimport csv\n\n@register_file_strategy(\".csv\")\nclass CsvStrategy:\n    \"\"\"Custom strategy for CSV files.\"\"\"\n\n    def load(self, file_path: Union[Path, str]) -&gt; List[Dict[str, Any]]:\n        \"\"\"Load CSV file as list of dictionaries.\"\"\"\n        with open(file_path, 'r', newline='', encoding='utf-8') as file:\n            reader = csv.DictReader(file)\n            return list(reader)\n\n    def save(self, file_path: Union[Path, str], data: List[Dict[str, Any]]) -&gt; None:\n        \"\"\"Save list of dictionaries as CSV file.\"\"\"\n        if not data:\n            return\n\n        with open(file_path, 'w', newline='', encoding='utf-8') as file:\n            fieldnames = data[0].keys()\n            writer = csv.DictWriter(file, fieldnames=fieldnames)\n            writer.writeheader()\n            writer.writerows(data)\n\n    def navigate(self, document: List[Dict[str, Any]], path: List[str], create: bool = False) -&gt; Optional[Any]:\n        \"\"\"Navigate CSV document structure.\"\"\"\n        if not path:\n            return document\n\n        # For CSV, we can navigate by row index and column name\n        if len(path) == 1:\n            # Get all values for a column\n            column = path[0]\n            return [row.get(column) for row in document if column in row]\n        elif len(path) == 2:\n            # Get specific cell value\n            try:\n                row_index = int(path[0])\n                column = path[1]\n                if 0 &lt;= row_index &lt; len(document):\n                    return document[row_index].get(column)\n            except (ValueError, IndexError):\n                pass\n\n        return None\n\n# Usage\nfm = YAPFileManager(\"data.csv\")  # Automatically uses CsvStrategy\n</code></pre>"},{"location":"advanced/custom_strategies/#advanced-custom-strategy-with-validation","title":"Advanced Custom Strategy with Validation","text":"<pre><code>import json\nimport yaml\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Union\nfrom yapfm.strategies import BaseFileStrategy\nfrom yapfm.registry import register_file_strategy\n\n@register_file_strategy([\".json\", \".yaml\", \".yml\"])\nclass MultiFormatStrategy:\n    \"\"\"Strategy that can handle multiple formats based on file extension.\"\"\"\n\n    def load(self, file_path: Union[Path, str]) -&gt; Dict[str, Any]:\n        \"\"\"Load file based on extension.\"\"\"\n        file_path = Path(file_path)\n        extension = file_path.suffix.lower()\n\n        with open(file_path, 'r', encoding='utf-8') as file:\n            content = file.read()\n\n        if extension == '.json':\n            return json.loads(content)\n        elif extension in ['.yaml', '.yml']:\n            return yaml.safe_load(content)\n        else:\n            raise ValueError(f\"Unsupported file format: {extension}\")\n\n    def save(self, file_path: Union[Path, str], data: Dict[str, Any]) -&gt; None:\n        \"\"\"Save file based on extension.\"\"\"\n        file_path = Path(file_path)\n        extension = file_path.suffix.lower()\n\n        if extension == '.json':\n            content = json.dumps(data, indent=2, ensure_ascii=False)\n        elif extension in ['.yaml', '.yml']:\n            content = yaml.dump(data, default_flow_style=False, allow_unicode=True)\n        else:\n            raise ValueError(f\"Unsupported file format: {extension}\")\n\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(content)\n\n    def navigate(self, document: Dict[str, Any], path: List[str], create: bool = False) -&gt; Optional[Any]:\n        \"\"\"Navigate document structure.\"\"\"\n        current = document\n\n        for part in path:\n            if isinstance(current, dict):\n                if part not in current:\n                    if create:\n                        current[part] = {}\n                    else:\n                        return None\n                current = current[part]\n            else:\n                return None\n\n        return current\n\n# Usage\njson_fm = YAPFileManager(\"config.json\")  # Uses MultiFormatStrategy\nyaml_fm = YAPFileManager(\"config.yaml\")  # Uses MultiFormatStrategy\n</code></pre>"},{"location":"advanced/custom_strategies/#strategy-with-caching","title":"Strategy with Caching","text":"<pre><code>from pathlib import Path\nfrom typing import Any, Dict, List, Optional, Union\nimport time\nfrom yapfm.strategies import BaseFileStrategy\nfrom yapfm.registry import register_file_strategy\n\n@register_file_strategy(\".json\")\nclass CachedJsonStrategy:\n    \"\"\"JSON strategy with caching capabilities.\"\"\"\n\n    def __init__(self):\n        self._cache: Dict[str, tuple] = {}  # path -&gt; (data, timestamp)\n        self._cache_ttl = 300  # 5 minutes\n\n    def load(self, file_path: Union[Path, str]) -&gt; Dict[str, Any]:\n        \"\"\"Load JSON file with caching.\"\"\"\n        file_path = str(file_path)\n        current_time = time.time()\n\n        # Check cache\n        if file_path in self._cache:\n            data, timestamp = self._cache[file_path]\n            if current_time - timestamp &lt; self._cache_ttl:\n                return data\n\n        # Load from file\n        with open(file_path, 'r', encoding='utf-8') as file:\n            data = json.load(file)\n\n        # Update cache\n        self._cache[file_path] = (data, current_time)\n\n        return data\n\n    def save(self, file_path: Union[Path, str], data: Dict[str, Any]) -&gt; None:\n        \"\"\"Save JSON file and update cache.\"\"\"\n        file_path = str(file_path)\n\n        with open(file_path, 'w', encoding='utf-8') as file:\n            json.dump(data, file, indent=2, ensure_ascii=False)\n\n        # Update cache\n        self._cache[file_path] = (data, time.time())\n\n    def navigate(self, document: Dict[str, Any], path: List[str], create: bool = False) -&gt; Optional[Any]:\n        \"\"\"Navigate document structure.\"\"\"\n        current = document\n\n        for part in path:\n            if isinstance(current, dict):\n                if part not in current:\n                    if create:\n                        current[part] = {}\n                    else:\n                        return None\n                current = current[part]\n            else:\n                return None\n\n        return current\n\n    def clear_cache(self) -&gt; None:\n        \"\"\"Clear the cache.\"\"\"\n        self._cache.clear()\n\n    def get_cache_stats(self) -&gt; Dict[str, Any]:\n        \"\"\"Get cache statistics.\"\"\"\n        current_time = time.time()\n        valid_entries = 0\n        expired_entries = 0\n\n        for data, timestamp in self._cache.values():\n            if current_time - timestamp &lt; self._cache_ttl:\n                valid_entries += 1\n            else:\n                expired_entries += 1\n\n        return {\n            \"total_entries\": len(self._cache),\n            \"valid_entries\": valid_entries,\n            \"expired_entries\": expired_entries,\n            \"cache_ttl\": self._cache_ttl\n        }\n</code></pre>"},{"location":"advanced/memory_management/","title":"Memory Management","text":""},{"location":"advanced/memory_management/#memory-efficient-file-manager","title":"Memory-Efficient File Manager","text":"<pre><code>from yapfm import YAPFileManager\nfrom typing import Any, Dict, Optional\nimport weakref\nimport gc\n\nclass MemoryEfficientFileManager:\n    \"\"\"File manager with memory management features.\"\"\"\n\n    def __init__(self, path: str, max_memory_mb: int = 100):\n        self.path = path\n        self.max_memory_mb = max_memory_mb\n        self._fm = YAPFileManager(path, auto_create=True)\n        self._cache: Optional[Dict[str, Any]] = None\n        self._cache_refs = weakref.WeakValueDictionary()\n\n    def _check_memory_usage(self) -&gt; bool:\n        \"\"\"Check if memory usage is within limits.\"\"\"\n        import psutil\n        process = psutil.Process()\n        memory_mb = process.memory_info().rss / 1024 / 1024\n        return memory_mb &lt; self.max_memory_mb\n\n    def _cleanup_memory(self) -&gt; None:\n        \"\"\"Clean up memory by clearing cache and running garbage collection.\"\"\"\n        self._cache = None\n        self._cache_refs.clear()\n        gc.collect()\n\n    def get_data(self) -&gt; Dict[str, Any]:\n        \"\"\"Get data with memory management.\"\"\"\n        if not self._check_memory_usage():\n            self._cleanup_memory()\n\n        if self._cache is None:\n            with self._fm:\n                self._cache = self._fm.data.copy()\n\n        return self._cache.copy()\n\n    def get_key(self, dot_key: str, default: Any = None) -&gt; Any:\n        \"\"\"Get key with memory management.\"\"\"\n        data = self.get_data()\n\n        # Navigate through nested keys\n        keys = dot_key.split('.')\n        value = data\n\n        for key in keys:\n            if isinstance(value, dict) and key in value:\n                value = value[key]\n            else:\n                return default\n\n        return value\n\n    def set_key(self, value: Any, dot_key: str) -&gt; None:\n        \"\"\"Set key with memory management.\"\"\"\n        with self._fm:\n            self._fm.set_key(value, dot_key=dot_key)\n\n        # Invalidate cache\n        self._cache = None\n\n    def optimize_memory(self) -&gt; None:\n        \"\"\"Optimize memory usage.\"\"\"\n        self._cleanup_memory()\n\n        # Force garbage collection\n        gc.collect()\n\n        print(f\"Memory optimized. Current usage: {self._get_memory_usage():.2f} MB\")\n\n    def _get_memory_usage(self) -&gt; float:\n        \"\"\"Get current memory usage in MB.\"\"\"\n        import psutil\n        process = psutil.Process()\n        return process.memory_info().rss / 1024 / 1024\n\n# Usage\nmemory_fm = MemoryEfficientFileManager(\"memory_config.json\", max_memory_mb=50)\n\n# Use the file manager\ndata = memory_fm.get_data()\nmemory_fm.set_key(\"value\", \"key\")\n\n# Optimize memory when needed\nmemory_fm.optimize_memory()\n</code></pre>"},{"location":"advanced/mixins_deep_dive/","title":"Mixins Deep Dive","text":""},{"location":"advanced/mixins_deep_dive/#advanced-multi-file-operations","title":"Advanced Multi-File Operations","text":"<p>YAPFM provides powerful multi-file operations with various merge strategies for complex configuration management scenarios.</p>"},{"location":"advanced/mixins_deep_dive/#merge-strategies-deep-dive","title":"Merge Strategies Deep Dive","text":""},{"location":"advanced/mixins_deep_dive/#deep-merge-strategy","title":"Deep Merge Strategy","text":"<p>The most commonly used strategy for configuration layering:</p> <pre><code>from yapfm import YAPFileManager\nfrom yapfm.multi_file.strategies import MergeStrategy\n\nfm = YAPFileManager(\"config.json\")\n\n# Deep merge with custom options\ndata = fm.load_multiple_files([\n    \"base.json\",\n    \"environment.json\", \n    \"user.json\"\n], strategy=\"deep\")\n\n# Deep merge with conflict resolution\ndef resolve_conflicts(key, value1, value2):\n    \"\"\"Custom conflict resolution function.\"\"\"\n    if key == \"database.host\":\n        return value2  # Always use the newer value\n    elif key == \"logging.level\":\n        # Use the more verbose level\n        levels = {\"DEBUG\": 0, \"INFO\": 1, \"WARNING\": 2, \"ERROR\": 3}\n        return value1 if levels.get(value1, 0) &gt; levels.get(value2, 0) else value2\n    else:\n        return value2  # Default: newer value wins\n\ndata = fm.load_multiple_files(\n    [\"base.json\", \"override.json\"],\n    strategy=\"deep\",\n    conflict_resolver=resolve_conflicts\n)\n</code></pre>"},{"location":"advanced/mixins_deep_dive/#namespace-strategy-with-custom-prefixes","title":"Namespace Strategy with Custom Prefixes","text":"<p>Organize configurations by environment or component:</p> <pre><code># Environment-based namespacing\ndata = fm.load_multiple_files([\n    \"database.json\",\n    \"api.json\",\n    \"cache.json\"\n], strategy=\"namespace\", namespace_prefix=\"services\")\n\n# Result structure:\n# {\n#     \"services\": {\n#         \"database\": {...},\n#         \"api\": {...},\n#         \"cache\": {...}\n#     }\n# }\n\n# Component-based namespacing\ndata = fm.load_multiple_files([\n    \"frontend.json\",\n    \"backend.json\",\n    \"mobile.json\"\n], strategy=\"namespace\", namespace_prefix=\"components\")\n</code></pre>"},{"location":"advanced/mixins_deep_dive/#priority-strategy-with-complex-rules","title":"Priority Strategy with Complex Rules","text":"<p>Handle complex precedence scenarios:</p> <pre><code># Define priority rules\npriorities = {\n    \"user.json\": 100,      # Highest priority\n    \"environment.json\": 50, # Medium priority\n    \"base.json\": 10        # Lowest priority\n}\n\ndata = fm.load_multiple_files([\n    \"base.json\",\n    \"environment.json\",\n    \"user.json\"\n], strategy=\"priority\", priorities=priorities)\n\n# Conditional priority based on file content\ndef dynamic_priority(file_path, data):\n    \"\"\"Calculate priority based on file content.\"\"\"\n    if data.get(\"environment\") == \"production\":\n        return 100\n    elif \"override\" in str(file_path):\n        return 75\n    else:\n        return 25\n\ndata = fm.load_multiple_files(\n    [\"base.json\", \"override.json\", \"prod.json\"],\n    strategy=\"priority\",\n    priority_calculator=dynamic_priority\n)\n</code></pre>"},{"location":"advanced/mixins_deep_dive/#conditional-strategy-for-dynamic-loading","title":"Conditional Strategy for Dynamic Loading","text":"<p>Load files based on runtime conditions:</p> <pre><code>def load_environment_specific_files(environment):\n    \"\"\"Load files based on environment.\"\"\"\n    def condition(file_path, data):\n        # Load base files always\n        if \"base\" in str(file_path):\n            return True\n\n        # Load environment-specific files\n        if environment in str(file_path):\n            return True\n\n        # Load files that match current environment\n        if data.get(\"environment\") == environment:\n            return True\n\n        return False\n\n    return fm.load_multiple_files(\n        [\"base.json\", \"dev.json\", \"prod.json\", \"staging.json\"],\n        strategy=\"conditional\",\n        condition_func=condition\n    )\n\n# Load production configuration\nprod_config = load_environment_specific_files(\"production\")\n</code></pre>"},{"location":"advanced/mixins_deep_dive/#advanced-file-group-management","title":"Advanced File Group Management","text":"<p>Organize complex multi-file scenarios:</p> <pre><code># Define comprehensive file groups\nfile_groups = {\n    \"core_services\": {\n        \"files\": [\"database.json\", \"cache.json\", \"queue.json\"],\n        \"strategy\": \"namespace\",\n        \"namespace_prefix\": \"core\"\n    },\n    \"api_services\": {\n        \"files\": [\"rest.json\", \"graphql.json\", \"websocket.json\"],\n        \"strategy\": \"namespace\", \n        \"namespace_prefix\": \"api\"\n    },\n    \"environment_config\": {\n        \"files\": [\"base.json\", \"dev.json\", \"prod.json\"],\n        \"strategy\": \"priority\",\n        \"priorities\": {\"prod.json\": 100, \"dev.json\": 50, \"base.json\": 10}\n    },\n    \"user_preferences\": {\n        \"files\": [\"defaults.json\", \"user.json\"],\n        \"strategy\": \"deep\",\n        \"conditional_filter\": lambda path, data: \"user\" in str(path)\n    }\n}\n\n# Load specific groups\ncore_config = fm.load_file_group(\"core_services\", file_groups)\napi_config = fm.load_file_group(\"api_services\", file_groups)\n\n# Load all groups into a single configuration\nall_config = {}\nfor group_name in file_groups:\n    group_config = fm.load_file_group(group_name, file_groups)\n    all_config.update(group_config)\n</code></pre>"},{"location":"advanced/mixins_deep_dive/#performance-optimization-with-caching","title":"Performance Optimization with Caching","text":"<p>Optimize multi-file operations with intelligent caching:</p> <pre><code># Enable caching for multi-file operations\nfm = YAPFileManager(\"config.json\", enable_cache=True, cache_size=5000)\n\n# Load with caching enabled\ndata = fm.load_multiple_files([\n    \"base.json\",\n    \"environment.json\",\n    \"user.json\"\n], strategy=\"deep\", use_cache=True)\n\n# Cache statistics for multi-file operations\nstats = fm.get_cache_stats()\nprint(f\"Multi-file cache hits: {stats['multi_file']['hits']}\")\nprint(f\"Cache efficiency: {stats['multi_file']['hit_rate']:.2%}\")\n\n# Invalidate specific file caches\nfm.invalidate_multi_file_cache(\"environment.json\")\n</code></pre>"},{"location":"advanced/mixins_deep_dive/#error-handling-and-validation","title":"Error Handling and Validation","text":"<p>Robust error handling for multi-file operations:</p> <pre><code>def safe_load_multiple_files(fm, files, strategy=\"deep\", **kwargs):\n    \"\"\"Safely load multiple files with error handling.\"\"\"\n    try:\n        return fm.load_multiple_files(files, strategy=strategy, **kwargs)\n    except FileNotFoundError as e:\n        print(f\"File not found: {e}\")\n        # Try loading available files\n        available_files = [f for f in files if Path(f).exists()]\n        if available_files:\n            return fm.load_multiple_files(available_files, strategy=strategy, **kwargs)\n        return {}\n    except Exception as e:\n        print(f\"Error loading files: {e}\")\n        return {}\n\n# Usage with error handling\ndata = safe_load_multiple_files(\n    fm, \n    [\"base.json\", \"missing.json\", \"environment.json\"],\n    strategy=\"deep\"\n)\n</code></pre>"},{"location":"advanced/mixins_deep_dive/#unified-api-and-batch-operations","title":"Unified API and Batch Operations","text":"<p>YAPFM provides a unified API that simplifies common operations while maintaining the power of individual mixins.</p>"},{"location":"advanced/mixins_deep_dive/#unified-api-benefits","title":"Unified API Benefits","text":"<p>The unified API provides: - Simplified syntax: <code>fm.set()</code> instead of <code>fm.set_key()</code> - Dictionary-like interface: <code>fm[\"key\"]</code> for natural Python syntax - Consistent behavior: All operations work the same way across formats - Performance optimization: Batch operations for efficiency</p>"},{"location":"advanced/mixins_deep_dive/#batch-operations-deep-dive","title":"Batch Operations Deep Dive","text":""},{"location":"advanced/mixins_deep_dive/#efficient-multi-key-operations","title":"Efficient Multi-Key Operations","text":"<pre><code>from yapfm import YAPFileManager\n\nfm = YAPFileManager(\"config.json\")\n\n# Traditional approach (inefficient)\nfm.set(\"database.host\", \"localhost\")\nfm.set(\"database.port\", 5432)\nfm.set(\"database.ssl\", True)\nfm.set(\"api.version\", \"v2\")\nfm.set(\"api.timeout\", 30)\n\n# Batch approach (efficient)\nfm.set_multiple({\n    \"database.host\": \"localhost\",\n    \"database.port\": 5432,\n    \"database.ssl\": True,\n    \"api.version\": \"v2\",\n    \"api.timeout\": 30\n})\n\n# Batch operations with error handling\ntry:\n    fm.set_multiple({\n        \"valid.key\": \"value\",\n        \"invalid.key\": None  # This might fail\n    })\nexcept ValueError as e:\n    print(f\"Some keys failed to set: {e}\")\n</code></pre>"},{"location":"advanced/mixins_deep_dive/#advanced-batch-retrieval","title":"Advanced Batch Retrieval","text":"<pre><code># Get multiple values with different defaults\nvalues = fm.get_multiple([\n    \"database.host\",\n    \"database.port\", \n    \"api.timeout\",\n    \"logging.level\"\n], defaults={\n    \"database.host\": \"localhost\",\n    \"database.port\": 5432,\n    \"api.timeout\": 30,\n    \"logging.level\": \"INFO\"\n})\n\n# Check existence of multiple keys\nexists = fm.has_multiple([\n    \"database.host\",\n    \"database.port\",\n    \"missing.key\"\n])\n# Returns: {\"database.host\": True, \"database.port\": True, \"missing.key\": False}\n\n# Delete multiple keys with validation\ndeleted_count = fm.delete_multiple([\n    \"temp.key1\",\n    \"temp.key2\",\n    \"temp.key3\"\n])\nprint(f\"Deleted {deleted_count} keys\")\n</code></pre>"},{"location":"advanced/mixins_deep_dive/#performance-optimization-with-batch-operations","title":"Performance Optimization with Batch Operations","text":"<pre><code>import time\nfrom yapfm import YAPFileManager\n\nfm = YAPFileManager(\"large_config.json\", enable_cache=True)\n\n# Measure performance difference\ndef measure_performance():\n    # Individual operations\n    start = time.time()\n    for i in range(1000):\n        fm.set(f\"key{i}\", f\"value{i}\")\n    individual_time = time.time() - start\n\n    # Batch operations\n    start = time.time()\n    batch_data = {f\"batch_key{i}\": f\"value{i}\" for i in range(1000)}\n    fm.set_multiple(batch_data)\n    batch_time = time.time() - start\n\n    print(f\"Individual operations: {individual_time:.3f}s\")\n    print(f\"Batch operations: {batch_time:.3f}s\")\n    print(f\"Speedup: {individual_time/batch_time:.1f}x\")\n\nmeasure_performance()\n</code></pre>"},{"location":"advanced/mixins_deep_dive/#dictionary-like-interface","title":"Dictionary-like Interface","text":"<p>YAPFM supports full dictionary-like syntax for seamless integration:</p> <pre><code># Natural Python syntax\nfm[\"database.host\"] = \"localhost\"\nhost = fm[\"database.host\"]\n\"database.host\" in fm\ndel fm[\"database.host\"]\n\n# Iteration support\nfor key in fm:\n    print(f\"Key: {key}\")\n\nfor key, value in fm.items():\n    print(f\"{key}: {value}\")\n\n# Dictionary methods\nfm.update({\n    \"new.key1\": \"value1\",\n    \"new.key2\": \"value2\"\n})\n\n# Pop with default\nvalue = fm.pop(\"key\", \"default_value\")\n\n# Clear all data\nfm.clear()\n</code></pre>"},{"location":"advanced/mixins_deep_dive/#advanced-caching-with-unified-api","title":"Advanced Caching with Unified API","text":"<pre><code># Enable advanced caching\nfm = YAPFileManager(\n    \"config.json\",\n    enable_cache=True,\n    cache_size=2000,\n    cache_ttl=7200  # 2 hours\n)\n\n# Cache-aware operations\nfm.set(\"database.host\", \"localhost\")  # Automatically cached\nhost = fm.get(\"database.host\")        # Retrieved from cache\n\n# Batch operations with cache optimization\nfm.set_multiple({\n    \"key1\": \"value1\",\n    \"key2\": \"value2\",\n    \"key3\": \"value3\"\n})  # All keys cached efficiently\n\n# Cache statistics\nstats = fm.get_cache_stats()\nprint(f\"Cache hit rate: {stats['unified_cache']['hit_rate']:.2%}\")\nprint(f\"Cache size: {stats['unified_cache']['size']}\")\nprint(f\"Memory usage: {stats['unified_cache']['memory_usage']} bytes\")\n\n# Cache invalidation\nfm.invalidate_cache(\"database.*\")  # Invalidate all database keys\nfm.clear_cache()  # Clear all cache\n</code></pre>"},{"location":"advanced/mixins_deep_dive/#error-handling-and-validation_1","title":"Error Handling and Validation","text":"<pre><code>def safe_batch_operations(fm, operations):\n    \"\"\"Safely perform batch operations with error handling.\"\"\"\n    results = {\n        \"successful\": [],\n        \"failed\": [],\n        \"skipped\": []\n    }\n\n    for operation_type, data in operations.items():\n        try:\n            if operation_type == \"set\":\n                fm.set_multiple(data)\n                results[\"successful\"].extend(data.keys())\n            elif operation_type == \"delete\":\n                deleted = fm.delete_multiple(data)\n                results[\"successful\"].extend(data[:deleted])\n                results[\"skipped\"].extend(data[deleted:])\n            elif operation_type == \"get\":\n                values = fm.get_multiple(data)\n                results[\"successful\"].extend(values.keys())\n        except Exception as e:\n            results[\"failed\"].append({\n                \"operation\": operation_type,\n                \"data\": data,\n                \"error\": str(e)\n            })\n\n    return results\n\n# Usage\noperations = {\n    \"set\": {\"key1\": \"value1\", \"key2\": \"value2\"},\n    \"delete\": [\"old_key1\", \"old_key2\"],\n    \"get\": [\"key1\", \"key2\", \"key3\"]\n}\n\nresults = safe_batch_operations(fm, operations)\nprint(f\"Successful: {len(results['successful'])}\")\nprint(f\"Failed: {len(results['failed'])}\")\nprint(f\"Skipped: {len(results['skipped'])}\")\n</code></pre>"},{"location":"advanced/mixins_deep_dive/#creating-custom-mixins","title":"Creating Custom Mixins","text":"<pre><code>from yapfm.mixins import FileOperationsMixin\nfrom typing import Any, Dict, List, Optional\nimport hashlib\n\nclass ValidationMixin:\n    \"\"\"Mixin for configuration validation.\"\"\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._validation_rules: Dict[str, Any] = {}\n        self._validation_errors: List[str] = []\n\n    def add_validation_rule(self, key: str, rule: callable, message: str = None) -&gt; None:\n        \"\"\"Add a validation rule for a configuration key.\"\"\"\n        self._validation_rules[key] = {\n            \"rule\": rule,\n            \"message\": message or f\"Validation failed for key: {key}\"\n        }\n\n    def validate_key(self, key: str, value: Any) -&gt; bool:\n        \"\"\"Validate a single key.\"\"\"\n        if key not in self._validation_rules:\n            return True\n\n        rule = self._validation_rules[key][\"rule\"]\n        try:\n            result = rule(value)\n            if not result:\n                self._validation_errors.append(self._validation_rules[key][\"message\"])\n            return result\n        except Exception as e:\n            self._validation_errors.append(f\"Validation error for {key}: {e}\")\n            return False\n\n    def validate_all(self) -&gt; bool:\n        \"\"\"Validate all configuration keys.\"\"\"\n        self._validation_errors.clear()\n\n        if not self.is_loaded():\n            self.load()\n\n        # Validate all keys in the document\n        self._validate_dict(self.data, \"\")\n\n        return len(self._validation_errors) == 0\n\n    def _validate_dict(self, data: Dict[str, Any], prefix: str) -&gt; None:\n        \"\"\"Recursively validate dictionary data.\"\"\"\n        for key, value in data.items():\n            full_key = f\"{prefix}.{key}\" if prefix else key\n\n            if isinstance(value, dict):\n                self._validate_dict(value, full_key)\n            else:\n                self.validate_key(full_key, value)\n\n    def get_validation_errors(self) -&gt; List[str]:\n        \"\"\"Get validation errors.\"\"\"\n        return self._validation_errors.copy()\n\n    def set_key_with_validation(self, value: Any, dot_key: str) -&gt; bool:\n        \"\"\"Set a key with validation.\"\"\"\n        if self.validate_key(dot_key, value):\n            self.set_key(value, dot_key=dot_key)\n            return True\n        return False\n\nclass EncryptionMixin:\n    \"\"\"Mixin for configuration encryption.\"\"\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._encryption_key: Optional[bytes] = None\n\n    def set_encryption_key(self, key: str) -&gt; None:\n        \"\"\"Set encryption key.\"\"\"\n        self._encryption_key = key.encode('utf-8')\n\n    def encrypt_value(self, value: str) -&gt; str:\n        \"\"\"Encrypt a string value.\"\"\"\n        if not self._encryption_key:\n            return value\n\n        from cryptography.fernet import Fernet\n        f = Fernet(self._encryption_key)\n        return f.encrypt(value.encode('utf-8')).decode('utf-8')\n\n    def decrypt_value(self, encrypted_value: str) -&gt; str:\n        \"\"\"Decrypt a string value.\"\"\"\n        if not self._encryption_key:\n            return encrypted_value\n\n        from cryptography.fernet import Fernet\n        f = Fernet(self._encryption_key)\n        return f.decrypt(encrypted_value.encode('utf-8')).decode('utf-8')\n\n    def set_encrypted_key(self, value: str, dot_key: str) -&gt; None:\n        \"\"\"Set an encrypted configuration key.\"\"\"\n        encrypted_value = self.encrypt_value(value)\n        self.set_key(encrypted_value, dot_key=dot_key)\n\n    def get_encrypted_key(self, dot_key: str, default: str = None) -&gt; str:\n        \"\"\"Get and decrypt a configuration key.\"\"\"\n        encrypted_value = self.get_key(dot_key=dot_key, default=default)\n        if encrypted_value is None:\n            return default\n\n        return self.decrypt_value(encrypted_value)\n\n# Create a custom file manager with mixins\nclass AdvancedFileManager(\n    FileOperationsMixin,\n    ValidationMixin,\n    EncryptionMixin\n):\n    def __init__(self, path, **kwargs):\n        self.path = path\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"advanced/mixins_deep_dive/#using-custom-mixins","title":"Using Custom Mixins","text":"<pre><code># Create advanced file manager\nfm = AdvancedFileManager(\"secure_config.json\", auto_create=True)\n\n# Set up validation rules\nfm.add_validation_rule(\"database.port\", lambda x: isinstance(x, int) and 1 &lt;= x &lt;= 65535)\nfm.add_validation_rule(\"app.version\", lambda x: isinstance(x, str) and len(x) &gt; 0)\n\n# Set up encryption\nfm.set_encryption_key(\"my-secret-key\")\n\n# Use validation\nfm.set_key_with_validation(5432, dot_key=\"database.port\")  # Valid\nfm.set_key_with_validation(\"invalid\", dot_key=\"database.port\")  # Invalid\n\n# Use encryption\nfm.set_encrypted_key(\"secret-password\", dot_key=\"database.password\")\npassword = fm.get_encrypted_key(dot_key=\"database.password\")\n</code></pre>"},{"location":"advanced/performance_optimization/","title":"Performance Optimization","text":""},{"location":"advanced/performance_optimization/#lazy-loading-strategies","title":"Lazy Loading Strategies","text":"<pre><code>from yapfm import YAPFileManager\nfrom typing import Any, Dict, Optional\nimport threading\nimport time\n\nclass LazyFileManager:\n    \"\"\"File manager with lazy loading and caching.\"\"\"\n\n    def __init__(self, path: str, cache_ttl: int = 300):\n        self.path = path\n        self.cache_ttl = cache_ttl\n        self._cache: Optional[Dict[str, Any]] = None\n        self._cache_timestamp: Optional[float] = None\n        self._lock = threading.RLock()\n        self._fm = YAPFileManager(path, auto_create=True)\n\n    def _is_cache_valid(self) -&gt; bool:\n        \"\"\"Check if cache is still valid.\"\"\"\n        if self._cache is None or self._cache_timestamp is None:\n            return False\n\n        return time.time() - self._cache_timestamp &lt; self.cache_ttl\n\n    def _load_data(self) -&gt; Dict[str, Any]:\n        \"\"\"Load data from file.\"\"\"\n        with self._fm:\n            return self._fm.data.copy()\n\n    def get_data(self) -&gt; Dict[str, Any]:\n        \"\"\"Get data with lazy loading.\"\"\"\n        with self._lock:\n            if not self._is_cache_valid():\n                self._cache = self._load_data()\n                self._cache_timestamp = time.time()\n\n            return self._cache.copy()\n\n    def get_key(self, dot_key: str, default: Any = None) -&gt; Any:\n        \"\"\"Get a key with lazy loading.\"\"\"\n        data = self.get_data()\n\n        # Navigate through nested keys\n        keys = dot_key.split('.')\n        value = data\n\n        for key in keys:\n            if isinstance(value, dict) and key in value:\n                value = value[key]\n            else:\n                return default\n\n        return value\n\n    def invalidate_cache(self) -&gt; None:\n        \"\"\"Invalidate the cache.\"\"\"\n        with self._lock:\n            self._cache = None\n            self._cache_timestamp = None\n\n# Usage\nlazy_fm = LazyFileManager(\"config.json\", cache_ttl=60)  # 1 minute cache\n\n# First access loads from file\ndata = lazy_fm.get_data()\n\n# Subsequent accesses use cache\nkey_value = lazy_fm.get_key(\"database.host\")\n</code></pre>"},{"location":"advanced/performance_optimization/#memory-efficient-processing","title":"Memory-Efficient Processing","text":"<pre><code>from yapfm import YAPFileManager\nfrom typing import Iterator, Dict, Any\nimport json\n\nclass StreamingFileManager:\n    \"\"\"File manager for processing large files in chunks.\"\"\"\n\n    def __init__(self, path: str, chunk_size: int = 1000):\n        self.path = path\n        self.chunk_size = chunk_size\n        self._fm = YAPFileManager(path, auto_create=True)\n\n    def process_large_data(self, processor: callable) -&gt; None:\n        \"\"\"Process large data in chunks.\"\"\"\n        with self._fm:\n            data = self._fm.data\n\n            # Process data in chunks\n            items = list(data.items())\n            for i in range(0, len(items), self.chunk_size):\n                chunk = dict(items[i:i + self.chunk_size])\n                processor(chunk)\n\n    def stream_keys(self) -&gt; Iterator[tuple]:\n        \"\"\"Stream keys and values for memory-efficient processing.\"\"\"\n        with self._fm:\n            data = self._fm.data\n\n            def _stream_dict(d: Dict[str, Any], prefix: str = \"\") -&gt; Iterator[tuple]:\n                for key, value in d.items():\n                    full_key = f\"{prefix}.{key}\" if prefix else key\n\n                    if isinstance(value, dict):\n                        yield from _stream_dict(value, full_key)\n                    else:\n                        yield (full_key, value)\n\n            yield from _stream_dict(data)\n\n    def batch_update(self, updates: Dict[str, Any]) -&gt; None:\n        \"\"\"Update multiple keys efficiently.\"\"\"\n        with self._fm:\n            # Get current data\n            current_data = self._fm.data.copy()\n\n            # Apply updates\n            for key, value in updates.items():\n                keys = key.split('.')\n                target = current_data\n\n                # Navigate to target\n                for k in keys[:-1]:\n                    if k not in target:\n                        target[k] = {}\n                    target = target[k]\n\n                # Set value\n                target[keys[-1]] = value\n\n            # Save updated data\n            self._fm.data = current_data\n\n# Usage\nstreaming_fm = StreamingFileManager(\"large_config.json\")\n\n# Process large data\ndef process_chunk(chunk: Dict[str, Any]) -&gt; None:\n    print(f\"Processing chunk with {len(chunk)} items\")\n\nstreaming_fm.process_large_data(process_chunk)\n\n# Stream keys for memory-efficient processing\nfor key, value in streaming_fm.stream_keys():\n    print(f\"{key}: {value}\")\n</code></pre>"},{"location":"advanced/plugin_architecture/","title":"Plugin Architecture","text":""},{"location":"advanced/plugin_architecture/#plugin-system","title":"Plugin System","text":"<pre><code>from yapfm import YAPFileManager\nfrom typing import Any, Dict, List, Optional, Protocol\nimport importlib\nimport os\n\nclass Plugin(Protocol):\n    \"\"\"Plugin protocol for extending file manager functionality.\"\"\"\n\n    def initialize(self, file_manager: YAPFileManager) -&gt; None:\n        \"\"\"Initialize the plugin with the file manager.\"\"\"\n        ...\n\n    def before_load(self, file_manager: YAPFileManager) -&gt; None:\n        \"\"\"Called before loading the file.\"\"\"\n        ...\n\n    def after_load(self, file_manager: YAPFileManager) -&gt; None:\n        \"\"\"Called after loading the file.\"\"\"\n        ...\n\n    def before_save(self, file_manager: YAPFileManager) -&gt; None:\n        \"\"\"Called before saving the file.\"\"\"\n        ...\n\n    def after_save(self, file_manager: YAPFileManager) -&gt; None:\n        \"\"\"Called after saving the file.\"\"\"\n        ...\n\nclass PluginManager:\n    \"\"\"Manager for file manager plugins.\"\"\"\n\n    def __init__(self, file_manager: YAPFileManager):\n        self.file_manager = file_manager\n        self.plugins: List[Plugin] = []\n\n    def register_plugin(self, plugin: Plugin) -&gt; None:\n        \"\"\"Register a plugin.\"\"\"\n        plugin.initialize(self.file_manager)\n        self.plugins.append(plugin)\n\n    def load_plugins_from_directory(self, directory: str) -&gt; None:\n        \"\"\"Load plugins from a directory.\"\"\"\n        for filename in os.listdir(directory):\n            if filename.endswith('.py') and not filename.startswith('_'):\n                module_name = filename[:-3]\n                module = importlib.import_module(f\"{directory}.{module_name}\")\n\n                # Look for plugin classes\n                for attr_name in dir(module):\n                    attr = getattr(module, attr_name)\n                    if (isinstance(attr, type) and \n                        hasattr(attr, 'initialize') and\n                        hasattr(attr, 'before_load')):\n                        plugin = attr()\n                        self.register_plugin(plugin)\n\n    def before_load(self) -&gt; None:\n        \"\"\"Call before_load on all plugins.\"\"\"\n        for plugin in self.plugins:\n            plugin.before_load(self.file_manager)\n\n    def after_load(self) -&gt; None:\n        \"\"\"Call after_load on all plugins.\"\"\"\n        for plugin in self.plugins:\n            plugin.after_load(self.file_manager)\n\n    def before_save(self) -&gt; None:\n        \"\"\"Call before_save on all plugins.\"\"\"\n        for plugin in self.plugins:\n            plugin.before_save(self.file_manager)\n\n    def after_save(self) -&gt; None:\n        \"\"\"Call after_save on all plugins.\"\"\"\n        for plugin in self.plugins:\n            plugin.after_save(self.file_manager)\n\nclass LoggingPlugin:\n    \"\"\"Plugin for logging file operations.\"\"\"\n\n    def __init__(self):\n        self.logger = None\n\n    def initialize(self, file_manager: YAPFileManager) -&gt; None:\n        import logging\n        self.logger = logging.getLogger(\"file_manager_plugin\")\n\n    def before_load(self, file_manager: YAPFileManager) -&gt; None:\n        self.logger.info(f\"Loading file: {file_manager.path}\")\n\n    def after_load(self, file_manager: YAPFileManager) -&gt; None:\n        self.logger.info(f\"File loaded: {file_manager.path}\")\n\n    def before_save(self, file_manager: YAPFileManager) -&gt; None:\n        self.logger.info(f\"Saving file: {file_manager.path}\")\n\n    def after_save(self, file_manager: YAPFileManager) -&gt; None:\n        self.logger.info(f\"File saved: {file_manager.path}\")\n\nclass ValidationPlugin:\n    \"\"\"Plugin for validating configuration.\"\"\"\n\n    def __init__(self):\n        self.validation_rules = {}\n\n    def initialize(self, file_manager: YAPFileManager) -&gt; None:\n        pass\n\n    def before_save(self, file_manager: YAPFileManager) -&gt; None:\n        # Validate configuration before saving\n        if not self._validate_config(file_manager.data):\n            raise ValueError(\"Configuration validation failed\")\n\n    def _validate_config(self, data: Dict[str, Any]) -&gt; bool:\n        # Add your validation logic here\n        return True\n\n# Usage\nfm = YAPFileManager(\"plugin_config.json\", auto_create=True)\nplugin_manager = PluginManager(fm)\n\n# Register plugins\nplugin_manager.register_plugin(LoggingPlugin())\nplugin_manager.register_plugin(ValidationPlugin())\n\n# Use file manager with plugins\nwith fm:\n    plugin_manager.before_load()\n    fm.load()\n    plugin_manager.after_load()\n\n    fm.set_key(\"value\", dot_key=\"key\")\n\n    plugin_manager.before_save()\n    fm.save()\n    plugin_manager.after_save()\n</code></pre>"},{"location":"advanced/proxy_pattern/","title":"Proxy Pattern","text":"<p>The <code>FileManagerProxy</code> provides powerful capabilities for monitoring, logging, and auditing file operations without modifying the core functionality.</p>"},{"location":"advanced/proxy_pattern/#basic-proxy-usage","title":"Basic Proxy Usage","text":"<pre><code>from yapfm import YAPFileManager, FileManagerProxy\nimport logging\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"config_proxy\")\n\n# Create file manager\nfm = YAPFileManager(\"config.json\", auto_create=True)\n\n# Create proxy with monitoring\nproxy = FileManagerProxy(\n    fm,\n    enable_logging=True,\n    enable_metrics=True,\n    enable_audit=True,\n    logger=logger\n)\n\n# Use proxy like the original manager\nwith proxy:\n    proxy.set_key(\"value\", dot_key=\"key\")\n    # All operations are logged and measured\n</code></pre>"},{"location":"advanced/proxy_pattern/#custom-audit-hooks","title":"Custom Audit Hooks","text":"<pre><code>def custom_audit_hook(method: str, args: tuple, kwargs: dict, result: Any) -&gt; None:\n    \"\"\"Custom audit hook for tracking configuration changes.\"\"\"\n    print(f\"\ud83d\udd0d AUDIT: {method} called with {args}, {kwargs} =&gt; {result}\")\n\n    # Track specific operations\n    if method == \"set_key\":\n        key = args[1] if len(args) &gt; 1 else kwargs.get('dot_key', 'unknown')\n        value = args[0] if len(args) &gt; 0 else 'unknown'\n        print(f\"Configuration changed: {key} = {value}\")\n\n    elif method == \"delete_key\":\n        key = args[0] if len(args) &gt; 0 else kwargs.get('dot_key', 'unknown')\n        print(f\"Configuration deleted: {key}\")\n\n# Use custom audit hook\nproxy = FileManagerProxy(\n    fm,\n    enable_audit=True,\n    audit_hook=custom_audit_hook\n)\n</code></pre>"},{"location":"advanced/proxy_pattern/#metrics-collection","title":"Metrics Collection","text":"<pre><code>import time\nfrom collections import defaultdict\n\nclass MetricsCollector:\n    def __init__(self):\n        self.operation_times = defaultdict(list)\n        self.operation_counts = defaultdict(int)\n        self.error_counts = defaultdict(int)\n\n    def collect_metrics(self, method: str, args: tuple, kwargs: dict, result: Any, execution_time: float) -&gt; None:\n        \"\"\"Collect metrics for operations.\"\"\"\n        self.operation_times[method].append(execution_time)\n        self.operation_counts[method] += 1\n\n        if isinstance(result, Exception):\n            self.error_counts[method] += 1\n\n    def get_stats(self) -&gt; dict:\n        \"\"\"Get collected statistics.\"\"\"\n        stats = {}\n        for method, times in self.operation_times.items():\n            stats[method] = {\n                \"count\": self.operation_counts[method],\n                \"avg_time\": sum(times) / len(times),\n                \"min_time\": min(times),\n                \"max_time\": max(times),\n                \"errors\": self.error_counts[method]\n            }\n        return stats\n\n# Use metrics collector\nmetrics = MetricsCollector()\n\ndef metrics_audit_hook(method: str, args: tuple, kwargs: dict, result: Any) -&gt; None:\n    # This would be called by the proxy with execution time\n    pass\n\nproxy = FileManagerProxy(\n    fm,\n    enable_metrics=True,\n    enable_audit=True,\n    audit_hook=metrics_audit_hook\n)\n</code></pre>"},{"location":"advanced/proxy_pattern/#production-monitoring","title":"Production Monitoring","text":"<pre><code>import json\nfrom datetime import datetime\nfrom typing import Dict, Any\n\nclass ProductionMonitor:\n    def __init__(self, log_file: str = \"config_operations.log\"):\n        self.log_file = log_file\n        self.operations = []\n\n    def log_operation(self, method: str, args: tuple, kwargs: dict, result: Any, execution_time: float) -&gt; None:\n        \"\"\"Log operation for production monitoring.\"\"\"\n        operation = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"method\": method,\n            \"args\": str(args),\n            \"kwargs\": str(kwargs),\n            \"result_type\": type(result).__name__,\n            \"execution_time_ms\": execution_time * 1000,\n            \"success\": not isinstance(result, Exception)\n        }\n\n        self.operations.append(operation)\n\n        # Write to log file\n        with open(self.log_file, \"a\") as f:\n            f.write(json.dumps(operation) + \"\\n\")\n\n    def get_operation_summary(self) -&gt; Dict[str, Any]:\n        \"\"\"Get summary of operations.\"\"\"\n        if not self.operations:\n            return {}\n\n        total_operations = len(self.operations)\n        successful_operations = sum(1 for op in self.operations if op[\"success\"])\n        avg_execution_time = sum(op[\"execution_time_ms\"] for op in self.operations) / total_operations\n\n        return {\n            \"total_operations\": total_operations,\n            \"successful_operations\": successful_operations,\n            \"success_rate\": successful_operations / total_operations,\n            \"average_execution_time_ms\": avg_execution_time\n        }\n\n# Use production monitor\nmonitor = ProductionMonitor()\n\ndef monitor_audit_hook(method: str, args: tuple, kwargs: dict, result: Any) -&gt; None:\n    # This would be called by the proxy with execution time\n    pass\n\nproxy = FileManagerProxy(\n    fm,\n    enable_metrics=True,\n    enable_audit=True,\n    audit_hook=monitor_audit_hook\n)\n</code></pre>"},{"location":"advanced/thread_safety/","title":"Thread Safety","text":""},{"location":"advanced/thread_safety/#thread-safe-file-manager","title":"Thread-Safe File Manager","text":"<pre><code>from yapfm import YAPFileManager\nimport threading\nfrom typing import Any, Dict, Optional\nimport time\n\nclass ThreadSafeFileManager:\n    \"\"\"Thread-safe wrapper for file manager.\"\"\"\n\n    def __init__(self, path: str, **kwargs):\n        self._fm = YAPFileManager(path, **kwargs)\n        self._lock = threading.RLock()\n        self._readers = 0\n        self._writers = 0\n        self._read_ready = threading.Condition(self._lock)\n        self._write_ready = threading.Condition(self._lock)\n\n    def read_operation(self, operation: callable) -&gt; Any:\n        \"\"\"Perform a read operation with reader-writer lock.\"\"\"\n        with self._lock:\n            while self._writers &gt; 0:\n                self._read_ready.wait()\n            self._readers += 1\n\n        try:\n            return operation(self._fm)\n        finally:\n            with self._lock:\n                self._readers -= 1\n                if self._readers == 0:\n                    self._write_ready.notify_all()\n\n    def write_operation(self, operation: callable) -&gt; Any:\n        \"\"\"Perform a write operation with reader-writer lock.\"\"\"\n        with self._lock:\n            while self._readers &gt; 0 or self._writers &gt; 0:\n                self._write_ready.wait()\n            self._writers += 1\n\n        try:\n            return operation(self._fm)\n        finally:\n            with self._lock:\n                self._writers -= 1\n                self._read_ready.notify_all()\n                self._write_ready.notify_all()\n\n    def get_key(self, dot_key: str, default: Any = None) -&gt; Any:\n        \"\"\"Thread-safe get key operation.\"\"\"\n        return self.read_operation(lambda fm: fm.get_key(dot_key=dot_key, default=default))\n\n    def set_key(self, value: Any, dot_key: str) -&gt; None:\n        \"\"\"Thread-safe set key operation.\"\"\"\n        self.write_operation(lambda fm: fm.set_key(value, dot_key=dot_key))\n\n    def load(self) -&gt; None:\n        \"\"\"Thread-safe load operation.\"\"\"\n        self.write_operation(lambda fm: fm.load())\n\n    def save(self) -&gt; None:\n        \"\"\"Thread-safe save operation.\"\"\"\n        self.write_operation(lambda fm: fm.save())\n\n# Usage\nthread_safe_fm = ThreadSafeFileManager(\"thread_safe_config.json\")\n\n# Multiple threads can safely access the file manager\ndef reader_thread():\n    for i in range(10):\n        value = thread_safe_fm.get_key(\"counter\", default=0)\n        print(f\"Reader: {value}\")\n        time.sleep(0.1)\n\ndef writer_thread():\n    for i in range(10):\n        thread_safe_fm.set_key(i, \"counter\")\n        print(f\"Writer: {i}\")\n        time.sleep(0.1)\n\n# Start threads\nthreading.Thread(target=reader_thread).start()\nthreading.Thread(target=writer_thread).start()\n</code></pre>"},{"location":"api/","title":"API Reference","text":"<p>Complete API documentation for YAPFM, including all classes, methods, and their parameters.</p>"},{"location":"api/#table-of-contents","title":"\ud83d\udcda Table of Contents","text":"<ol> <li>Core Classes - Main classes and their constructors</li> <li>Strategies - File format handling strategies</li> <li>Merge Strategies - Multi-file merge strategies</li> <li>Mixins - Mixin classes providing functionality</li> <li>Registry - Strategy registry and management</li> <li>Proxy - Proxy wrapper for monitoring and auditing</li> <li>Exceptions - Exception classes and error handling</li> <li>Helpers - Utility functions and helpers</li> </ol>"},{"location":"api/#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Need to understand the main classes? Check Core Classes</li> <li>Working with different file formats? See Strategies</li> <li>Merging multiple files? See Merge Strategies</li> <li>Looking for specific functionality? Browse Mixins</li> <li>Want to register custom strategies? Read Registry</li> <li>Need monitoring capabilities? Go to Proxy</li> <li>Handling errors? See Exceptions</li> <li>Looking for utility functions? Check Helpers</li> </ul>"},{"location":"api/#additional-resources","title":"Additional Resources","text":"<ul> <li>User Guide - Basic usage and common patterns</li> <li>Advanced Features - Advanced patterns and optimization</li> <li>Examples - More code examples and use cases</li> <li>Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"api/core_classes/","title":"Core Classes","text":""},{"location":"api/core_classes/#yapfilemanager","title":"YAPFileManager","text":"<p>The main class that combines all functionality through mixins.</p> <pre><code>from yapfm import YAPFileManager\n</code></pre>"},{"location":"api/core_classes/#constructor","title":"Constructor","text":"<pre><code>YAPFileManager(\n    path: Union[str, Path],\n    strategy: Optional[BaseFileStrategy] = None,\n    *,\n    auto_create: bool = False,\n    enable_context: bool = True,\n    enable_cache: bool = True,\n    cache_size: int = 1000,\n    cache_ttl: Optional[float] = 3600,\n    enable_streaming: bool = False,\n    enable_lazy_loading: bool = False,\n    **kwargs: Any\n) -&gt; None\n</code></pre> <p>Parameters: - <code>path</code> (Union[str, Path]): Path to the file to manage - <code>strategy</code> (Optional[BaseFileStrategy]): Custom strategy for file handling. If None, auto-detects based on file extension - <code>auto_create</code> (bool): Whether to create the file if it doesn't exist. Default: False - <code>enable_context</code> (bool): Enable context manager functionality. Default: True - <code>enable_cache</code> (bool): Enable intelligent caching. Default: True - <code>cache_size</code> (int): Maximum number of keys to cache. Default: 1000 - <code>cache_ttl</code> (Optional[float]): Cache time-to-live in seconds. Default: 3600 (1 hour) - <code>enable_streaming</code> (bool): Enable streaming for large files. Default: False - <code>enable_lazy_loading</code> (bool): Enable lazy loading for sections. Default: False - <code>**kwargs</code> (Any): Additional keyword arguments passed to mixins</p> <p>Example: <pre><code># Basic usage\nfm = YAPFileManager(\"config.json\")\n\n# With auto-creation\nfm = YAPFileManager(\"config.json\", auto_create=True)\n\n# With custom strategy\nfrom yapfm.strategies import JsonStrategy\nfm = YAPFileManager(\"config.json\", strategy=JsonStrategy())\n\n# With advanced features\nfm = YAPFileManager(\n    \"large_config.json\",\n    enable_cache=True,\n    cache_size=2000,\n    cache_ttl=7200,  # 2 hours\n    enable_streaming=True,\n    enable_lazy_loading=True\n)\n</code></pre></p>"},{"location":"api/core_classes/#properties","title":"Properties","text":""},{"location":"api/core_classes/#data","title":"data","text":"<pre><code>@property\ndata -&gt; Dict[str, Any]\n</code></pre> <p>Get or set the file data. Automatically loads the file on first access if not loaded.</p> <p>Getter: - Returns: Dictionary containing the file data - Note: Automatically loads the file on first access if it hasn't been loaded yet</p> <p>Setter: - Parameters: <code>value</code> (Dict[str, Any]): Dictionary containing the data to set - Raises: <code>TypeError</code> if value is not a dictionary</p> <p>Example: <pre><code># Get data (auto-loads if needed)\ndata = fm.data\n\n# Set data\nfm.data = {\"key\": \"value\"}\n</code></pre></p>"},{"location":"api/core_classes/#unified-api-methods","title":"Unified API Methods","text":"<p>YAPFileManager provides a simplified, unified API that delegates to the appropriate mixins:</p>"},{"location":"api/core_classes/#basic-operations","title":"Basic Operations","text":"<pre><code>def set(key: str, value: Any, overwrite: bool = True) -&gt; None\ndef get(key: str, default: Any = None) -&gt; Any\ndef has(key: str) -&gt; bool\ndef delete(key: str) -&gt; bool\n</code></pre> <p>Example: <pre><code># Set a value\nfm.set(\"database.host\", \"localhost\")\n\n# Get a value\nhost = fm.get(\"database.host\", \"localhost\")\n\n# Check if key exists\nif fm.has(\"database.host\"):\n    print(\"Database host is configured\")\n\n# Delete a key\nfm.delete(\"database.host\")\n</code></pre></p>"},{"location":"api/core_classes/#dictionary-like-interface","title":"Dictionary-like Interface","text":"<p>YAPFileManager supports dictionary-like syntax for seamless integration:</p> <pre><code># Dictionary-like access\nfm[\"database.host\"] = \"localhost\"\nhost = fm[\"database.host\"]\n\"database.host\" in fm\ndel fm[\"database.host\"]\n\n# Dictionary methods\nfor key in fm:  # Iterate over keys\n    print(key)\n\nfor key, value in fm.items():  # Iterate over items\n    print(f\"{key}: {value}\")\n\n# Other dict methods\nfm.update({\"new.key\": \"value\"})\nfm.clear()\nvalue = fm.pop(\"key\", \"default\")\n</code></pre>"},{"location":"api/core_classes/#batch-operations","title":"Batch Operations","text":"<p>Efficient operations for handling multiple keys at once:</p> <pre><code>def set_multiple(items: Dict[str, Any], overwrite: bool = True) -&gt; None\ndef get_multiple(keys: List[str], default: Any = None, defaults: Optional[Dict[str, Any]] = None) -&gt; Dict[str, Any]\ndef delete_multiple(keys: List[str]) -&gt; int\ndef has_multiple(keys: List[str]) -&gt; Dict[str, bool]\n</code></pre> <p>Example: <pre><code># Set multiple values efficiently\nfm.set_multiple({\n    \"database.host\": \"localhost\",\n    \"database.port\": 5432,\n    \"logging.level\": \"INFO\"\n})\n\n# Get multiple values\nvalues = fm.get_multiple([\"database.host\", \"database.port\"])\n\n# Get multiple values with specific defaults\nvalues = fm.get_multiple(\n    [\"database.host\", \"database.port\"],\n    defaults={\"database.host\": \"localhost\", \"database.port\": 5432}\n)\n\n# Check existence of multiple keys\nexists = fm.has_multiple([\"database.host\", \"database.port\"])\n# Returns: {\"database.host\": True, \"database.port\": False}\n\n# Delete multiple keys\ndeleted_count = fm.delete_multiple([\"database.host\", \"database.port\"])\n</code></pre></p>"},{"location":"api/core_classes/#cache-management","title":"Cache Management","text":"<pre><code>def get_cache_stats() -&gt; Dict[str, Any]\ndef clear_key_cache() -&gt; None\n</code></pre> <p>Example: <pre><code># Get comprehensive cache statistics\nstats = fm.get_cache_stats()\nprint(f\"Cache hits: {stats['unified_cache']['hits']}\")\nprint(f\"Cache misses: {stats['unified_cache']['misses']}\")\nprint(f\"Lazy sections: {stats['lazy_sections']['total_sections']}\")\n\n# Clear key generation cache\nfm.clear_key_cache()\n</code></pre></p>"},{"location":"api/core_classes/#advanced-features","title":"Advanced Features","text":"<p>All advanced functionality is available through mixins. See Mixins section for detailed documentation:</p> <ul> <li>File Operations: Basic file management (load, save, exists, etc.)</li> <li>Key Operations: Dot notation access and manipulation</li> <li>Section Operations: Section-based data management</li> <li>Context Management: Automatic loading/saving with context managers</li> <li>Batch Operations: Efficient multi-key operations</li> <li>Caching: Intelligent caching with TTL and LRU eviction</li> <li>Lazy Loading: Memory-efficient section loading</li> <li>Streaming: Large file processing capabilities</li> <li>Multi-File: Multiple file loading and merging</li> <li>Search: Key and value searching</li> <li>Analysis: Data analysis and statistics</li> <li>Transform: Data transformation and restructuring</li> <li>Cleanup: Data cleanup and optimization</li> <li>Clone: Data cloning and copying</li> <li>Export: Export to different formats</li> <li>Security: Sensitive data handling and masking</li> </ul>"},{"location":"api/core_classes/#filemanagerproxy","title":"FileManagerProxy","text":"<p>Proxy wrapper that adds logging, metrics, and auditing capabilities.</p> <pre><code>from yapfm import FileManagerProxy\n</code></pre>"},{"location":"api/core_classes/#constructor_1","title":"Constructor","text":"<pre><code>FileManagerProxy(\n    manager: Any,\n    *,\n    enable_logging: bool = False,\n    enable_metrics: bool = False,\n    enable_audit: bool = False,\n    logger: Optional[logging.Logger] = None,\n    audit_hook: Optional[Callable[[str, tuple, dict, Any], None]] = None\n) -&gt; None\n</code></pre> <p>Parameters: - <code>manager</code> (Any): The underlying FileManager instance to proxy - <code>enable_logging</code> (bool): Enable debug logging of method calls and results. Default: False - <code>enable_metrics</code> (bool): Enable execution time measurement. Default: False - <code>enable_audit</code> (bool): Enable audit hook execution. Default: False - <code>logger</code> (Optional[logging.Logger]): Custom logger. Defaults to <code>logging.getLogger(__name__)</code> - <code>audit_hook</code> (Optional[Callable]): Custom hook called as <code>audit_hook(method: str, args: tuple, kwargs: dict, result: Any)</code></p> <p>Example: <pre><code>from yapfm import YAPFileManager, FileManagerProxy\nimport logging\n\n# Create file manager\nfm = YAPFileManager(\"config.json\")\n\n# Create proxy with logging and metrics\nproxy = FileManagerProxy(\n    fm,\n    enable_logging=True,\n    enable_metrics=True,\n    enable_audit=True\n)\n\n# Use proxy like the original manager\nwith proxy:\n    proxy.set_key(\"value\", dot_key=\"key\")\n</code></pre></p>"},{"location":"api/exceptions/","title":"Exceptions","text":""},{"location":"api/exceptions/#filemanagererror","title":"FileManagerError","text":"<p>Base exception for all file manager errors.</p> <pre><code>from yapfm.exceptions import FileManagerError\n</code></pre>"},{"location":"api/exceptions/#loadfileerror","title":"LoadFileError","text":"<p>Raised when there's an error loading a file.</p> <pre><code>from yapfm.exceptions import LoadFileError\n</code></pre> <p>Example: <pre><code>try:\n    fm.load()\nexcept LoadFileError as e:\n    print(f\"Failed to load file: {e}\")\n</code></pre></p>"},{"location":"api/exceptions/#filewriteerror","title":"FileWriteError","text":"<p>Raised when there's an error writing to a file.</p> <pre><code>from yapfm.exceptions import FileWriteError\n</code></pre> <p>Example: <pre><code>try:\n    fm.save()\nexcept FileWriteError as e:\n    print(f\"Failed to save file: {e}\")\n</code></pre></p>"},{"location":"api/exceptions/#strategyerror","title":"StrategyError","text":"<p>Raised when there's an error with file strategies.</p> <pre><code>from yapfm.exceptions import StrategyError\n</code></pre> <p>Example: <pre><code>try:\n    fm = YAPFileManager(\"file.xyz\")\nexcept StrategyError as e:\n    print(f\"Strategy error: {e}\")\n</code></pre></p>"},{"location":"api/helpers/","title":"Helpers","text":""},{"location":"api/helpers/#split_dot_key","title":"split_dot_key","text":"<p>Split a dot-separated key into path and key name.</p> <pre><code>from yapfm.helpers import split_dot_key\n</code></pre> <p>Parameters: - <code>dot_key</code> (str): The dot-separated key</p> <p>Returns: - <code>Tuple[List[str], str]</code>: The path and key name</p> <p>Example: <pre><code>path, key = split_dot_key(\"database.host\")\nprint(path)  # ['database']\nprint(key)   # 'host'\n</code></pre></p>"},{"location":"api/helpers/#navigate_dict_like","title":"navigate_dict_like","text":"<p>Navigate through a dictionary-like structure.</p> <pre><code>from yapfm.helpers import navigate_dict_like\n</code></pre> <p>Parameters: - <code>document</code> (Any): The document to navigate - <code>path</code> (List[str]): The path to traverse - <code>create</code> (bool): Whether to create missing intermediate structures</p> <p>Returns: - <code>Optional[Any]</code>: The value at the specified path</p> <p>Example: <pre><code>document = {\"database\": {\"host\": \"localhost\"}}\nvalue = navigate_dict_like(document, [\"database\", \"host\"])\nprint(value)  # \"localhost\"\n</code></pre></p>"},{"location":"api/helpers/#load_file","title":"load_file","text":"<p>Load a file using a custom loader function.</p> <pre><code>from yapfm.helpers import load_file\n</code></pre> <p>Parameters: - <code>file_path</code> (Union[Path, str]): Path to the file - <code>loader</code> (Callable): Function to load the file content</p> <p>Returns: - <code>Any</code>: The loaded file content</p> <p>Example: <pre><code>import json\ndata = load_file(\"config.json\", json.loads)\n</code></pre></p>"},{"location":"api/helpers/#save_file","title":"save_file","text":"<p>Save data to a file using a custom serializer.</p> <pre><code>from yapfm.helpers import save_file\n</code></pre> <p>Parameters: - <code>file_path</code> (Union[Path, str]): Path to save the file - <code>data</code> (Any): Data to save - <code>serializer</code> (Callable): Function to serialize the data</p> <p>Example: <pre><code>import json\nsave_file(\"config.json\", data, lambda x: json.dumps(x, indent=2))\n</code></pre></p>"},{"location":"api/helpers/#open_file","title":"open_file","text":"<p>Open a configuration file with the appropriate strategy.</p> <pre><code>from yapfm.helpers import open_file\n</code></pre> <p>Parameters: - <code>path</code> (Union[str, Path]): Path to the file - <code>format</code> (Optional[str]): Optional format override (e.g. \"toml\", \"json\", \"yaml\"). If provided, will select the strategy based on this format instead of the file extension - <code>auto_create</code> (bool): Whether to create the file if it doesn't exist. Default: False</p> <p>Returns: - <code>YAPFileManager</code>: File manager instance configured for the specified file</p> <p>Example: <pre><code># Open file with automatic format detection\nfm = open_file(\"config.json\")\n\n# Open file with format override\nfm = open_file(\"config.txt\", format=\"toml\")\n\n# Open file with auto-creation\nfm = open_file(\"new_config.json\", auto_create=True)\n\n# Use the file manager\nwith fm:\n    fm.set_key(\"value\", dot_key=\"key\")\n</code></pre></p>"},{"location":"api/helpers/#load_file_with_stream","title":"load_file_with_stream","text":"<p>Load a file using a custom loader function with stream support.</p> <pre><code>from yapfm.helpers import load_file_with_stream\n</code></pre> <p>Parameters: - <code>file_path</code> (Union[Path, str]): Path to the file - <code>parser_func</code> (Callable[[Any], T]): Function to parse the file stream</p> <p>Returns: - <code>T</code>: Parsed file content</p> <p>Example: <pre><code>import json\n\ndef parse_json_stream(stream):\n    return json.load(stream)\n\ndata = load_file_with_stream(\"large_config.json\", parse_json_stream)\n</code></pre></p>"},{"location":"api/helpers/#save_file_with_stream","title":"save_file_with_stream","text":"<p>Save data to a file using a custom writer function with stream support.</p> <pre><code>from yapfm.helpers import save_file_with_stream\n</code></pre> <p>Parameters: - <code>file_path</code> (Union[Path, str]): Path to save the file - <code>data</code> (Any): Data to save - <code>writer_func</code> (Callable[[Any, Any], None]): Function to write data to stream</p> <p>Example: <pre><code>import json\n\ndef write_json_stream(data, stream):\n    json.dump(data, stream, indent=2)\n\nsave_file_with_stream(\"output.json\", data, write_json_stream)\n</code></pre></p>"},{"location":"api/helpers/#join_dot_key","title":"join_dot_key","text":"<p>Join a path and key name into a dot-separated key.</p> <pre><code>from yapfm.helpers import join_dot_key\n</code></pre> <p>Parameters: - <code>path</code> (List[str]): The path components - <code>key_name</code> (str): The key name</p> <p>Returns: - <code>str</code>: The dot-separated key</p> <p>Example: <pre><code>key = join_dot_key([\"database\", \"connection\"], \"host\")\nprint(key)  # \"database.connection.host\"\n</code></pre></p>"},{"location":"api/helpers/#resolve_file_extension","title":"resolve_file_extension","text":"<p>Resolve file extension from a file path or extension string.</p> <pre><code>from yapfm.helpers import resolve_file_extension\n</code></pre> <p>Parameters: - <code>file_ext_or_path</code> (str): File path or extension string</p> <p>Returns: - <code>str</code>: The resolved file extension</p> <p>Example: <pre><code>ext = resolve_file_extension(\"config.json\")  # \".json\"\next = resolve_file_extension(\".toml\")        # \".toml\"\n</code></pre></p>"},{"location":"api/helpers/#deep_merge","title":"deep_merge","text":"<p>Deep merge two dictionaries.</p> <pre><code>from yapfm.helpers import deep_merge\n</code></pre> <p>Parameters: - <code>dict1</code> (Dict[str, Any]): First dictionary - <code>dict2</code> (Dict[str, Any]): Second dictionary</p> <p>Returns: - <code>Dict[str, Any]</code>: Merged dictionary</p> <p>Example: <pre><code>base = {\"database\": {\"host\": \"localhost\"}}\noverride = {\"database\": {\"port\": 5432}}\nmerged = deep_merge(base, override)\n# Result: {\"database\": {\"host\": \"localhost\", \"port\": 5432}}\n</code></pre></p>"},{"location":"api/helpers/#traverse_data_structure","title":"traverse_data_structure","text":"<p>Traverse a data structure and apply a function to each element.</p> <pre><code>from yapfm.helpers import traverse_data_structure\n</code></pre> <p>Parameters: - <code>data</code> (Any): The data structure to traverse - <code>path</code> (str): The current path - <code>visitor_func</code> (Callable[[Any, str], None]): Function to apply to each element - <code>include_containers</code> (bool): Whether to include containers in traversal</p> <p>Example: <pre><code>def print_paths(value, path):\n    print(f\"{path}: {value}\")\n\ntraverse_data_structure(data, \"\", print_paths)\n</code></pre></p>"},{"location":"api/helpers/#transform_data_in_place","title":"transform_data_in_place","text":"<p>Transform data in place using a transformation function.</p> <pre><code>from yapfm.helpers import transform_data_in_place\n</code></pre> <p>Parameters: - <code>data</code> (Any): The data to transform - <code>transformer_func</code> (Callable): Function to transform values - <code>target</code> (str): What to transform (\"key\", \"value\", or \"both\") - <code>deep</code> (bool): Whether to transform recursively</p> <p>Example: <pre><code>def uppercase_strings(value):\n    return value.upper() if isinstance(value, str) else value\n\ntransform_data_in_place(data, uppercase_strings, \"value\", deep=True)\n</code></pre></p>"},{"location":"api/helpers/#validate_strategy","title":"validate_strategy","text":"<p>Validate that a strategy implements the required interface.</p> <pre><code>from yapfm.helpers import validate_strategy\n</code></pre> <p>Parameters: - <code>strategy</code> (BaseFileStrategy): The strategy to validate</p> <p>Raises: - <code>ValueError</code>: If the strategy is invalid</p> <p>Example: <pre><code>from yapfm.strategies import JsonStrategy\n\nstrategy = JsonStrategy()\nvalidate_strategy(strategy)  # Validates the strategy\n</code></pre></p>"},{"location":"api/merge_strategies/","title":"Merge Strategies","text":"<p>YAPFM provides multiple merge strategies for combining data from multiple files. Each strategy defines how files should be merged into a single dictionary.</p>"},{"location":"api/merge_strategies/#available-strategies","title":"Available Strategies","text":""},{"location":"api/merge_strategies/#deep-merge-strategy","title":"Deep Merge Strategy","text":"<p>Recursively merges dictionaries, combining nested structures.</p> <pre><code>from yapfm.multi_file.strategies import MergeStrategy\n\n# Using enum\nstrategy = MergeStrategy.DEEP\n\n# Using string\nstrategy = \"deep\"\n</code></pre> <p>Behavior: - Recursively merges nested dictionaries - Preserves all values from all files - Later files override earlier files for conflicting keys - Arrays are replaced (not merged)</p> <p>Example: <pre><code># File 1: base.json\n{\n    \"database\": {\n        \"host\": \"localhost\",\n        \"port\": 5432\n    },\n    \"logging\": {\n        \"level\": \"INFO\"\n    }\n}\n\n# File 2: override.json\n{\n    \"database\": {\n        \"host\": \"prod-server\",\n        \"ssl\": true\n    },\n    \"api\": {\n        \"version\": \"v2\"\n    }\n}\n\n# Result after deep merge\n{\n    \"database\": {\n        \"host\": \"prod-server\",  # Overridden\n        \"port\": 5432,           # Preserved\n        \"ssl\": true             # Added\n    },\n    \"logging\": {\n        \"level\": \"INFO\"         # Preserved\n    },\n    \"api\": {\n        \"version\": \"v2\"         # Added\n    }\n}\n</code></pre></p>"},{"location":"api/merge_strategies/#namespace-merge-strategy","title":"Namespace Merge Strategy","text":"<p>Merges files into separate namespaces based on file names.</p> <pre><code>strategy = MergeStrategy.NAMESPACE\n</code></pre> <p>Parameters: - <code>namespace_prefix</code> (str): Prefix for namespaces (default: file name without extension)</p> <p>Behavior: - Each file becomes a separate namespace - File names are used as namespace keys - No conflicts between files</p> <p>Example: <pre><code># File: database.json\n{\n    \"host\": \"localhost\",\n    \"port\": 5432\n}\n\n# File: api.json\n{\n    \"version\": \"v2\",\n    \"timeout\": 30\n}\n\n# Result with namespace merge\n{\n    \"database\": {\n        \"host\": \"localhost\",\n        \"port\": 5432\n    },\n    \"api\": {\n        \"version\": \"v2\",\n        \"timeout\": 30\n    }\n}\n</code></pre></p>"},{"location":"api/merge_strategies/#priority-merge-strategy","title":"Priority Merge Strategy","text":"<p>Merges files with priority-based overwriting.</p> <pre><code>strategy = MergeStrategy.PRIORITY\n</code></pre> <p>Parameters: - <code>priorities</code> (Dict[str, int]): File priorities (higher number = higher priority)</p> <p>Behavior: - Files with higher priority override lower priority files - Priority is determined by file order or explicit priorities - Only conflicting keys are overridden</p> <p>Example: <pre><code># File 1: base.json (priority: 1)\n{\n    \"database\": {\n        \"host\": \"localhost\",\n        \"port\": 5432\n    }\n}\n\n# File 2: prod.json (priority: 2)\n{\n    \"database\": {\n        \"host\": \"prod-server\"\n    }\n}\n\n# Result: prod.json overrides base.json for conflicting keys\n{\n    \"database\": {\n        \"host\": \"prod-server\",  # Overridden by higher priority\n        \"port\": 5432            # Preserved from base\n    }\n}\n</code></pre></p>"},{"location":"api/merge_strategies/#append-merge-strategy","title":"Append Merge Strategy","text":"<p>Appends values to lists instead of replacing them.</p> <pre><code>strategy = MergeStrategy.APPEND\n</code></pre> <p>Behavior: - Arrays are concatenated instead of replaced - Dictionaries are merged normally - Useful for collecting values from multiple sources</p> <p>Example: <pre><code># File 1: servers.json\n{\n    \"servers\": [\"server1\", \"server2\"],\n    \"config\": {\n        \"timeout\": 30\n    }\n}\n\n# File 2: more_servers.json\n{\n    \"servers\": [\"server3\", \"server4\"],\n    \"config\": {\n        \"retries\": 3\n    }\n}\n\n# Result: arrays are appended\n{\n    \"servers\": [\"server1\", \"server2\", \"server3\", \"server4\"],\n    \"config\": {\n        \"timeout\": 30,\n        \"retries\": 3\n    }\n}\n</code></pre></p>"},{"location":"api/merge_strategies/#replace-merge-strategy","title":"Replace Merge Strategy","text":"<p>Completely replaces data with the last file.</p> <pre><code>strategy = MergeStrategy.REPLACE\n</code></pre> <p>Behavior: - Each file completely replaces the previous data - Only the last file's data is kept - Useful for configuration overrides</p> <p>Example: <pre><code># File 1: base.json\n{\n    \"database\": {\"host\": \"localhost\"},\n    \"logging\": {\"level\": \"INFO\"}\n}\n\n# File 2: override.json\n{\n    \"database\": {\"host\": \"prod-server\"}\n}\n\n# Result: only override.json data is kept\n{\n    \"database\": {\"host\": \"prod-server\"}\n}\n</code></pre></p>"},{"location":"api/merge_strategies/#conditional-merge-strategy","title":"Conditional Merge Strategy","text":"<p>Merges files based on conditions.</p> <pre><code>strategy = MergeStrategy.CONDITIONAL\n</code></pre> <p>Parameters: - <code>condition_func</code> (Callable): Function that determines if a file should be merged - <code>condition_args</code> (Dict): Arguments passed to the condition function</p> <p>Behavior: - Only files that meet the condition are merged - Condition function receives file path and data - Useful for environment-specific configurations</p> <p>Example: <pre><code>def is_production_file(file_path, data):\n    return \"prod\" in str(file_path) or data.get(\"environment\") == \"production\"\n\n# Only production files will be merged\nstrategy = MergeStrategy.CONDITIONAL\ncondition_func = is_production_file\n</code></pre></p>"},{"location":"api/merge_strategies/#using-merge-strategies","title":"Using Merge Strategies","text":""},{"location":"api/merge_strategies/#with-multifilemixin","title":"With MultiFileMixin","text":"<pre><code>from yapfm import YAPFileManager\n\nfm = YAPFileManager(\"config.json\")\n\n# Load multiple files with deep merge\ndata = fm.load_multiple_files([\n    \"base.json\",\n    \"override.json\"\n], strategy=\"deep\")\n\n# Load with namespace strategy\ndata = fm.load_multiple_files([\n    \"database.json\",\n    \"api.json\"\n], strategy=\"namespace\", namespace_prefix=\"app\")\n\n# Load with priority strategy\ndata = fm.load_multiple_files([\n    \"base.json\",\n    \"prod.json\"\n], strategy=\"priority\", priorities={\"prod.json\": 2, \"base.json\": 1})\n</code></pre>"},{"location":"api/merge_strategies/#with-file-groups","title":"With File Groups","text":"<pre><code># Define file groups in configuration\nconfig = {\n    \"app_config\": {\n        \"files\": [\"base.json\", \"override.json\"],\n        \"strategy\": \"deep\"\n    },\n    \"environment_config\": {\n        \"files\": [\"dev.json\", \"prod.json\"],\n        \"strategy\": \"namespace\",\n        \"namespace_prefix\": \"env\"\n    }\n}\n\n# Load file groups\napp_data = fm.load_file_group(\"app_config\", config)\nenv_data = fm.load_file_group(\"environment_config\", config)\n</code></pre>"},{"location":"api/merge_strategies/#custom-merge-strategies","title":"Custom Merge Strategies","text":"<p>You can create custom merge strategies by extending <code>BaseMergeStrategy</code>:</p> <pre><code>from yapfm.multi_file.merge_strategies.base import BaseMergeStrategy\n\nclass CustomMergeStrategy(BaseMergeStrategy):\n    def merge(self, file_data: List[Tuple[Path, Dict[str, Any]]]) -&gt; Dict[str, Any]:\n        # Custom merge logic\n        result = {}\n        for file_path, data in file_data:\n            # Your custom merge logic here\n            result.update(data)\n        return result\n\n# Use custom strategy\nstrategy = CustomMergeStrategy()\ndata = fm.load_multiple_files([\"file1.json\", \"file2.json\"], strategy=strategy)\n</code></pre>"},{"location":"api/merge_strategies/#strategy-selection-guidelines","title":"Strategy Selection Guidelines","text":"<ul> <li>Deep Merge: Best for configuration files that need to be layered</li> <li>Namespace: Best for organizing different types of configuration</li> <li>Priority: Best when you have clear precedence rules</li> <li>Append: Best for collecting lists from multiple sources</li> <li>Replace: Best for complete configuration overrides</li> <li>Conditional: Best for environment-specific or dynamic configurations</li> </ul>"},{"location":"api/proxy/","title":"Proxy","text":"<p>The <code>FileManagerProxy</code> provides powerful capabilities for monitoring, logging, and auditing file operations without modifying the core functionality.</p>"},{"location":"api/proxy/#filemanagerproxy","title":"FileManagerProxy","text":"<p>Proxy wrapper that adds logging, metrics, and auditing capabilities.</p> <pre><code>from yapfm import FileManagerProxy\n</code></pre>"},{"location":"api/proxy/#constructor","title":"Constructor","text":"<pre><code>FileManagerProxy(\n    manager: Any,\n    *,\n    enable_logging: bool = False,\n    enable_metrics: bool = False,\n    enable_audit: bool = False,\n    logger: Optional[logging.Logger] = None,\n    audit_hook: Optional[Callable[[str, tuple, dict, Any], None]] = None\n) -&gt; None\n</code></pre> <p>Parameters: - <code>manager</code> (Any): The underlying FileManager instance to proxy - <code>enable_logging</code> (bool): Enable debug logging of method calls and results. Default: False - <code>enable_metrics</code> (bool): Enable execution time measurement. Default: False - <code>enable_audit</code> (bool): Enable audit hook execution. Default: False - <code>logger</code> (Optional[logging.Logger]): Custom logger. Defaults to <code>logging.getLogger(__name__)</code> - <code>audit_hook</code> (Optional[Callable]): Custom hook called as <code>audit_hook(method: str, args: tuple, kwargs: dict, result: Any)</code></p> <p>Example: <pre><code>from yapfm import YAPFileManager, FileManagerProxy\nimport logging\n\n# Create file manager\nfm = YAPFileManager(\"config.json\")\n\n# Create proxy with logging and metrics\nproxy = FileManagerProxy(\n    fm,\n    enable_logging=True,\n    enable_metrics=True,\n    enable_audit=True\n)\n\n# Use proxy like the original manager\nwith proxy:\n    proxy.set_key(\"value\", dot_key=\"key\")\n</code></pre></p>"},{"location":"api/proxy/#features","title":"Features","text":"<p>The proxy automatically wraps all method calls to the underlying file manager and provides:</p> <ul> <li>Logging: Debug logging of method calls and results</li> <li>Metrics: Execution time measurement for performance monitoring</li> <li>Audit: Custom hook execution for tracking operations</li> <li>Transparency: All methods are proxied transparently</li> </ul>"},{"location":"api/proxy/#usage-patterns","title":"Usage Patterns","text":""},{"location":"api/proxy/#basic-monitoring","title":"Basic Monitoring","text":"<pre><code># Create proxy with basic monitoring\nproxy = FileManagerProxy(\n    fm,\n    enable_logging=True,\n    enable_metrics=True\n)\n\n# All operations are logged and measured\nwith proxy:\n    proxy.set_key(\"value\", dot_key=\"key\")\n    data = proxy.get_key(dot_key=\"key\")\n</code></pre>"},{"location":"api/proxy/#custom-audit-hooks","title":"Custom Audit Hooks","text":"<pre><code>def custom_audit_hook(method: str, args: tuple, kwargs: dict, result: Any) -&gt; None:\n    \"\"\"Custom audit hook for tracking configuration changes.\"\"\"\n    print(f\"\ud83d\udd0d AUDIT: {method} called with {args}, {kwargs} =&gt; {result}\")\n\n    # Track specific operations\n    if method == \"set_key\":\n        key = args[1] if len(args) &gt; 1 else kwargs.get('dot_key', 'unknown')\n        value = args[0] if len(args) &gt; 0 else 'unknown'\n        print(f\"Configuration changed: {key} = {value}\")\n\n    elif method == \"delete_key\":\n        key = args[0] if len(args) &gt; 0 else kwargs.get('dot_key', 'unknown')\n        print(f\"Configuration deleted: {key}\")\n\n# Use custom audit hook\nproxy = FileManagerProxy(\n    fm,\n    enable_audit=True,\n    audit_hook=custom_audit_hook\n)\n</code></pre>"},{"location":"api/proxy/#production-monitoring","title":"Production Monitoring","text":"<pre><code>import json\nfrom datetime import datetime\nfrom typing import Dict, Any\n\nclass ProductionMonitor:\n    def __init__(self, log_file: str = \"config_operations.log\"):\n        self.log_file = log_file\n        self.operations = []\n\n    def log_operation(self, method: str, args: tuple, kwargs: dict, result: Any, execution_time: float) -&gt; None:\n        \"\"\"Log operation for production monitoring.\"\"\"\n        operation = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"method\": method,\n            \"args\": str(args),\n            \"kwargs\": str(kwargs),\n            \"result_type\": type(result).__name__,\n            \"execution_time_ms\": execution_time * 1000,\n            \"success\": not isinstance(result, Exception)\n        }\n\n        self.operations.append(operation)\n\n        # Write to log file\n        with open(self.log_file, \"a\") as f:\n            f.write(json.dumps(operation) + \"\\n\")\n\n    def get_operation_summary(self) -&gt; Dict[str, Any]:\n        \"\"\"Get summary of operations.\"\"\"\n        if not self.operations:\n            return {}\n\n        total_operations = len(self.operations)\n        successful_operations = sum(1 for op in self.operations if op[\"success\"])\n        avg_execution_time = sum(op[\"execution_time_ms\"] for op in self.operations) / total_operations\n\n        return {\n            \"total_operations\": total_operations,\n            \"successful_operations\": successful_operations,\n            \"success_rate\": successful_operations / total_operations,\n            \"average_execution_time_ms\": avg_execution_time\n        }\n\n# Use production monitor\nmonitor = ProductionMonitor()\n\ndef monitor_audit_hook(method: str, args: tuple, kwargs: dict, result: Any) -&gt; None:\n    # This would be called by the proxy with execution time\n    pass\n\nproxy = FileManagerProxy(\n    fm,\n    enable_metrics=True,\n    enable_audit=True,\n    audit_hook=monitor_audit_hook\n)\n</code></pre>"},{"location":"api/registry/","title":"Registry","text":""},{"location":"api/registry/#filestrategyregistry","title":"FileStrategyRegistry","text":"<p>Registry for managing file strategies.</p> <pre><code>from yapfm.registry import FileStrategyRegistry\n</code></pre>"},{"location":"api/registry/#class-methods","title":"Class Methods","text":""},{"location":"api/registry/#register_strategy","title":"register_strategy","text":"<pre><code>@classmethod\ndef register_strategy(\n    cls,\n    file_exts: Union[str, List[str]],\n    strategy_cls: Type[BaseFileStrategy]\n) -&gt; None\n</code></pre> <p>Register one or multiple extensions for a strategy class.</p> <p>Parameters: - <code>file_exts</code> (Union[str, List[str]]): File extension(s) to register the strategy for - <code>strategy_cls</code> (Type[BaseFileStrategy]): Strategy class to register</p> <p>Raises: - <code>TypeError</code>: If the strategy does not inherit from BaseFileStrategy</p> <p>Example: <pre><code>from yapfm.strategies import JsonStrategy\n\n# Register single extension\nFileStrategyRegistry.register_strategy(\".json\", JsonStrategy)\n\n# Register multiple extensions\nFileStrategyRegistry.register_strategy([\".json\", \".jsonc\"], JsonStrategy)\n</code></pre></p>"},{"location":"api/registry/#unregister_strategy","title":"unregister_strategy","text":"<pre><code>@classmethod\ndef unregister_strategy(cls, file_ext: str) -&gt; None\n</code></pre> <p>Unregister a strategy for a file extension.</p> <p>Parameters: - <code>file_ext</code> (str): File extension to unregister the strategy for</p> <p>Example: <pre><code>FileStrategyRegistry.unregister_strategy(\".json\")\n</code></pre></p>"},{"location":"api/registry/#get_strategy","title":"get_strategy","text":"<pre><code>@classmethod\ndef get_strategy(cls, file_ext_or_path: str) -&gt; Optional[BaseFileStrategy]\n</code></pre> <p>Get a strategy for a file extension or path.</p> <p>Parameters: - <code>file_ext_or_path</code> (str): File extension or path to get the strategy for</p> <p>Returns: - <code>Optional[BaseFileStrategy]</code>: The strategy for the file extension or path</p> <p>Example: <pre><code># Get strategy by extension\nstrategy = FileStrategyRegistry.get_strategy(\".json\")\n\n# Get strategy by path\nstrategy = FileStrategyRegistry.get_strategy(\"config.json\")\n</code></pre></p>"},{"location":"api/registry/#list_strategies","title":"list_strategies","text":"<pre><code>@classmethod\ndef list_strategies(cls) -&gt; Dict[str, Type[BaseFileStrategy]]\n</code></pre> <p>List all registered strategies.</p> <p>Returns: - <code>Dict[str, Type[BaseFileStrategy]]</code>: Dictionary mapping extensions to strategy classes</p> <p>Example: <pre><code>strategies = FileStrategyRegistry.list_strategies()\nprint(strategies)  # {'.json': &lt;class 'JsonStrategy'&gt;, '.toml': &lt;class 'TomlStrategy'&gt;}\n</code></pre></p>"},{"location":"api/registry/#get_supported_formats","title":"get_supported_formats","text":"<pre><code>@classmethod\ndef get_supported_formats(cls) -&gt; List[str]\n</code></pre> <p>Get the supported formats for all registered strategies.</p> <p>Returns: - <code>List[str]</code>: List of supported file extensions</p> <p>Example: <pre><code>formats = FileStrategyRegistry.get_supported_formats()\nprint(formats)  # ['.json', '.toml', '.yaml']\n</code></pre></p>"},{"location":"api/registry/#is_format_supported","title":"is_format_supported","text":"<pre><code>@classmethod\ndef is_format_supported(cls, file_ext: str) -&gt; bool\n</code></pre> <p>Check if a format is supported.</p> <p>Parameters: - <code>file_ext</code> (str): File extension to check</p> <p>Returns: - <code>bool</code>: True if the format is supported, False otherwise</p> <p>Example: <pre><code>if FileStrategyRegistry.is_format_supported(\".json\"):\n    print(\"JSON format is supported\")\n</code></pre></p>"},{"location":"api/registry/#register_file_strategy","title":"register_file_strategy","text":"<p>Decorator to register a strategy for one or more formats.</p> <pre><code>from yapfm.registry import register_file_strategy\n</code></pre>"},{"location":"api/registry/#usage","title":"Usage","text":"<pre><code>@register_file_strategy(\".json\")\nclass MyJsonStrategy:\n    def load(self, file_path):\n        # Implementation\n        pass\n\n    def save(self, file_path, data):\n        # Implementation\n        pass\n\n    def navigate(self, document, path, create=False):\n        # Implementation\n        pass\n</code></pre> <p>Parameters: - <code>file_exts</code> (Union[str, List[str]]): The extensions to register the strategy for - <code>registry</code> (Type[FileStrategyRegistry]): The registry to register the strategy for</p> <p>Example: <pre><code>@register_file_strategy([\".json\", \".jsonc\"])\nclass MyJsonStrategy:\n    # Implementation\n    pass\n</code></pre></p>"},{"location":"api/strategies/","title":"Strategies","text":""},{"location":"api/strategies/#basefilestrategy","title":"BaseFileStrategy","text":"<p>Abstract base protocol for all file handling strategies.</p> <pre><code>from yapfm.strategies import BaseFileStrategy\n</code></pre>"},{"location":"api/strategies/#methods","title":"Methods","text":""},{"location":"api/strategies/#load","title":"load","text":"<pre><code>def load(self, file_path: Union[Path, str]) -&gt; Any\n</code></pre> <p>Load data from a file.</p> <p>Parameters: - <code>file_path</code> (Union[Path, str]): Path to the file to load</p> <p>Returns: - <code>Any</code>: The parsed file contents, typically a dictionary or list</p> <p>Raises: - <code>FileNotFoundError</code>: If the file doesn't exist - <code>ValueError</code>: If the file format is invalid</p> <p>Example: <pre><code>strategy = TomlStrategy()\ndata = strategy.load(\"config.toml\")\nprint(data[\"database\"][\"host\"])\n</code></pre></p>"},{"location":"api/strategies/#save","title":"save","text":"<pre><code>def save(self, file_path: Union[Path, str], data: Any) -&gt; None\n</code></pre> <p>Save data to a file.</p> <p>Parameters: - <code>file_path</code> (Union[Path, str]): Path where to save the file - <code>data</code> (Any): The data to save, typically a dictionary or list</p> <p>Raises: - <code>PermissionError</code>: If the file cannot be written due to permissions - <code>ValueError</code>: If the data cannot be serialized to the target format</p> <p>Example: <pre><code>strategy = TomlStrategy()\ndata = {\"database\": {\"host\": \"localhost\", \"port\": 5432}}\nstrategy.save(\"config.toml\", data)\n</code></pre></p>"},{"location":"api/strategies/#navigate","title":"navigate","text":"<pre><code>def navigate(\n    self, \n    document: Any, \n    path: List[str], \n    create: bool = False\n) -&gt; Optional[Any]\n</code></pre> <p>Navigate through the document structure.</p> <p>Parameters: - <code>document</code> (Any): The document to navigate through - <code>path</code> (List[str]): List of keys representing the path to traverse - <code>create</code> (bool): Whether to create missing intermediate structures</p> <p>Returns: - <code>Optional[Any]</code>: The value at the specified path, or None if not found and create is False</p> <p>Example: <pre><code>strategy = TomlStrategy()\ndocument = {\"database\": {\"host\": \"localhost\"}}\nvalue = strategy.navigate(document, [\"database\", \"host\"])\nprint(value)  # \"localhost\"\n\n# Create missing path\nvalue = strategy.navigate(document, [\"cache\", \"redis\"], create=True)\nprint(document)  # {\"database\": {...}, \"cache\": {\"redis\": None}}\n</code></pre></p>"},{"location":"api/strategies/#jsonstrategy","title":"JsonStrategy","text":"<p>Strategy for handling JSON files.</p> <pre><code>from yapfm.strategies import JsonStrategy\n</code></pre> <p>Features: - Standard JSON with pretty printing - 2-space indentation - UTF-8 encoding support</p> <p>Example: <pre><code>strategy = JsonStrategy()\ndata = strategy.load(\"config.json\")\nstrategy.save(\"output.json\", data)\n</code></pre></p>"},{"location":"api/strategies/#tomlstrategy","title":"TomlStrategy","text":"<p>Strategy for handling TOML files.</p> <pre><code>from yapfm.strategies import TomlStrategy\n</code></pre> <p>Features: - Full TOML specification support - Comment and formatting preservation - Type-safe operations with tomlkit - Support for nested tables and arrays</p> <p>Example: <pre><code>strategy = TomlStrategy()\ndata = strategy.load(\"config.toml\")\nstrategy.save(\"output.toml\", data)\n</code></pre></p>"},{"location":"api/strategies/#yamlstrategy","title":"YamlStrategy","text":"<p>Strategy for handling YAML files.</p> <pre><code>from yapfm.strategies import YamlStrategy\n</code></pre> <p>Features: - YAML 1.2 with safe loading - UTF-8 encoding support - Pretty printing with proper indentation</p> <p>Example: <pre><code>strategy = YamlStrategy()\ndata = strategy.load(\"config.yaml\")\nstrategy.save(\"output.yaml\", data)\n</code></pre></p>"},{"location":"api/mixins/","title":"Mixins","text":"<p>YAPFM mixins provide modular functionality to extend file manager capabilities. Each mixin can be used independently or in combination with other mixins.</p>"},{"location":"api/mixins/#available-mixins","title":"Available Mixins","text":""},{"location":"api/mixins/#core-mixins","title":"Core Mixins","text":"<ul> <li>FileOperationsMixin - Basic file operations</li> <li>KeyOperationsMixin - Key-based data access with dot notation</li> <li>SectionOperationsMixin - Section-based data management</li> <li>ContextMixin - Context manager for automatic loading/saving</li> <li>Batch Operations - Efficient batch operations for multiple keys</li> </ul>"},{"location":"api/mixins/#performance-mixins","title":"Performance Mixins","text":"<ul> <li>CacheMixin - Intelligent caching with TTL and LRU eviction</li> <li>LazySectionsMixin - Lazy loading of sections</li> <li>StreamingMixin - Large file processing</li> </ul>"},{"location":"api/mixins/#analysis-and-search-mixins","title":"Analysis and Search Mixins","text":"<ul> <li>AnalysisMixin - Data analysis and statistics</li> <li>SearchMixin - Search in keys and values</li> </ul>"},{"location":"api/mixins/#transformation-mixins","title":"Transformation Mixins","text":"<ul> <li>TransformMixin - Data transformation and restructuring</li> <li>CleanupMixin - Data cleanup (removing nulls, empty sections)</li> </ul>"},{"location":"api/mixins/#advanced-management-mixins","title":"Advanced Management Mixins","text":"<ul> <li>MultiFileMixin - Multi-file management and merging</li> <li>CloneMixin - Data cloning and copying</li> <li>ExportMixin - Export to different formats</li> <li>SecurityMixin - Security and sensitive data masking</li> </ul>"},{"location":"api/mixins/#usage","title":"Usage","text":"<p>Mixins are automatically included in <code>YAPFileManager</code> and can be used directly:</p> <pre><code>from yapfm import YAPFileManager\n\n# All mixins are available\nfm = YAPFileManager(\"config.json\")\n\n# Using mixin functionality\nfm.set_key(\"value\", dot_key=\"database.host\")  # KeyOperationsMixin\nfm.set_value(\"key\", \"value\")  # CacheMixin\nfm.get_stats()  # AnalysisMixin\nfm.search_in_values(\"localhost\")  # SearchMixin\n</code></pre>"},{"location":"api/mixins/#architecture","title":"Architecture","text":"<p>Mixins follow the composition pattern and are designed to be: - Modular: Each mixin has a specific responsibility - Composable: Can be combined as needed - Thread-safe: Safe for concurrent usage - Performant: Optimized for frequent operations</p>"},{"location":"api/mixins/analysis_mixin/","title":"AnalysisMixin","text":"<p>Provides analysis functionality for the file manager. The AnalysisMixin contains operations for analyzing data structure, types, and statistics.</p>"},{"location":"api/mixins/analysis_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/analysis_mixin/#get_all_keys","title":"get_all_keys","text":"<pre><code>def get_all_keys(self, flat: bool = True) -&gt; List[str]\n</code></pre> <p>Get all keys in the file.</p> <p>Parameters: - <code>flat</code> (bool): If True, returns in dot notation (database.host). If False, returns hierarchical structure</p> <p>Returns: - <code>List[str]</code>: List of keys</p> <p>Example: <pre><code># Get keys in dot notation\nkeys = fm.get_all_keys()  # ['database.host', 'database.port', 'api.version']\n\n# Get hierarchical keys\nkeys = fm.get_all_keys(flat=False)  # ['database', 'api']\n</code></pre></p>"},{"location":"api/mixins/analysis_mixin/#get_stats","title":"get_stats","text":"<pre><code>def get_stats(self) -&gt; Dict[str, Any]\n</code></pre> <p>Get comprehensive statistics about the content.</p> <p>Returns: - <code>Dict[str, Any]</code>: Dictionary with detailed statistics</p> <p>Example: <pre><code>stats = fm.get_stats()\nprint(f\"Total keys: {stats['total_keys']}\")\nprint(f\"Max depth: {stats['max_depth']}\")\nprint(f\"File size: {stats['file_size']} bytes\")\nprint(f\"File format: {stats['file_format']}\")\nprint(f\"Cache enabled: {stats['cache_enabled']}\")\n</code></pre></p>"},{"location":"api/mixins/analysis_mixin/#get_type_distribution","title":"get_type_distribution","text":"<pre><code>def get_type_distribution(self) -&gt; Dict[str, int]\n</code></pre> <p>Get distribution of data types in the file.</p> <p>Returns: - <code>Dict[str, int]</code>: Dictionary with type counts</p> <p>Example: <pre><code>types = fm.get_type_distribution()\nprint(f\"Strings: {types['str']}, Numbers: {types['int'] + types['float']}\")\n</code></pre></p>"},{"location":"api/mixins/analysis_mixin/#get_size_info","title":"get_size_info","text":"<pre><code>def get_size_info(self) -&gt; Dict[str, Any]\n</code></pre> <p>Get size information about the file and data.</p> <p>Returns: - <code>Dict[str, Any]</code>: Dictionary with size information</p> <p>Example: <pre><code>size_info = fm.get_size_info()\nprint(f\"File size: {size_info['file_size_bytes']} bytes\")\nprint(f\"Memory usage: {size_info['memory_usage_bytes']} bytes\")\nprint(f\"Compression ratio: {size_info['compression_ratio']}\")\n</code></pre></p>"},{"location":"api/mixins/analysis_mixin/#find_duplicates","title":"find_duplicates","text":"<pre><code>def find_duplicates(self) -&gt; Dict[Any, List[str]]\n</code></pre> <p>Find duplicate values and their keys.</p> <p>Returns: - <code>Dict[Any, List[str]]</code>: Dictionary mapping values to lists of keys that contain them</p> <p>Example: <pre><code>duplicates = fm.find_duplicates()\nfor value, keys in duplicates.items():\n    if len(keys) &gt; 1:\n        print(f\"Value '{value}' found in: {keys}\")\n</code></pre></p>"},{"location":"api/mixins/batch_operations_mixin/","title":"Batch Operations","text":"<p>YAPFileManager includes built-in batch operations for efficient handling of multiple keys at once.</p>"},{"location":"api/mixins/batch_operations_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/batch_operations_mixin/#set_multiple","title":"set_multiple","text":"<pre><code>def set_multiple(self, items: Dict[str, Any], overwrite: bool = True) -&gt; None\n</code></pre> <p>Set multiple key-value pairs efficiently.</p> <p>Parameters: - <code>items</code> (Dict[str, Any]): Dictionary of key-value pairs to set - <code>overwrite</code> (bool): Whether to overwrite existing values</p> <p>Raises: - <code>ValueError</code>: If any key fails to be set</p> <p>Example: <pre><code>fm.set_multiple({\n    \"database.host\": \"localhost\",\n    \"database.port\": 5432,\n    \"logging.level\": \"INFO\"\n})\n</code></pre></p>"},{"location":"api/mixins/batch_operations_mixin/#get_multiple","title":"get_multiple","text":"<pre><code>def get_multiple(\n    self,\n    keys: List[str],\n    default: Any = None,\n    defaults: Optional[Dict[str, Any]] = None\n) -&gt; Dict[str, Any]\n</code></pre> <p>Get multiple values efficiently.</p> <p>Parameters: - <code>keys</code> (List[str]): List of keys to get - <code>default</code> (Any): Default value for missing keys - <code>defaults</code> (Optional[Dict[str, Any]]): Optional dictionary with specific default values per key</p> <p>Returns: - <code>Dict[str, Any]</code>: Dictionary with key-value pairs</p> <p>Example: <pre><code># Get multiple values with same default\nvalues = fm.get_multiple([\"database.host\", \"database.port\"])\n\n# Get multiple values with specific defaults\nvalues = fm.get_multiple(\n    [\"database.host\", \"database.port\"],\n    defaults={\"database.host\": \"localhost\", \"database.port\": 5432}\n)\n</code></pre></p>"},{"location":"api/mixins/batch_operations_mixin/#delete_multiple","title":"delete_multiple","text":"<pre><code>def delete_multiple(self, keys: List[str]) -&gt; int\n</code></pre> <p>Delete multiple keys efficiently.</p> <p>Parameters: - <code>keys</code> (List[str]): List of keys to delete</p> <p>Returns: - <code>int</code>: Number of keys deleted</p> <p>Raises: - <code>ValueError</code>: If keys is not a list or contains invalid keys</p> <p>Example: <pre><code>deleted_count = fm.delete_multiple([\"database.host\", \"database.port\"])\nprint(f\"Deleted {deleted_count} keys\")\n</code></pre></p>"},{"location":"api/mixins/cache_mixin/","title":"CacheMixin","text":"<p>Provides intelligent caching functionality for individual keys with TTL, LRU eviction, and statistics tracking.</p>"},{"location":"api/mixins/cache_mixin/#features","title":"Features","text":"<ul> <li>Smart Caching: Automatic caching of individual key values</li> <li>TTL Support: Time-to-live for cached entries</li> <li>LRU Eviction: Least Recently Used eviction when cache is full</li> <li>Memory Management: Size-based eviction to prevent memory issues</li> <li>Statistics Tracking: Hit/miss ratios and performance metrics</li> <li>Pattern Invalidation: Invalidate cache entries using patterns</li> <li>Thread Safety: Safe for use in multi-threaded environments</li> </ul>"},{"location":"api/mixins/cache_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/cache_mixin/#get_value","title":"get_value","text":"<pre><code>def get_value(\n    self,\n    key: str = None,\n    default: Any = None\n) -&gt; Any\n</code></pre> <p>Get a value from the file using key with intelligent caching.</p> <p>Parameters: - <code>key</code> (str): The key - <code>default</code> (Any): The default value if the key is not found</p> <p>Returns: - <code>Any</code>: The value at the specified key or default</p> <p>Example: <pre><code># Using with caching\nhost = fm.get_value(\"database.host\", default=\"localhost\")\n\n# First call loads from file and caches\n# Subsequent calls return from cache (much faster)\n</code></pre></p>"},{"location":"api/mixins/cache_mixin/#set_value","title":"set_value","text":"<pre><code>def set_value(\n    self,\n    key: str,\n    value: Any,\n    overwrite: bool = True\n) -&gt; None\n</code></pre> <p>Set a value in the file using key.</p> <p>The cache will be automatically updated on the next get_value() call.</p> <p>Parameters: - <code>key</code> (str): The key to set - <code>value</code> (Any): The value to set - <code>overwrite</code> (bool): Whether to overwrite existing values</p> <p>Example: <pre><code>fm.set_value(\"database.host\", \"localhost\")\nfm.set_value(\"database.port\", 5432, overwrite=False)\n</code></pre></p>"},{"location":"api/mixins/cache_mixin/#clear_cache","title":"clear_cache","text":"<pre><code>def clear_cache(self) -&gt; None\n</code></pre> <p>Clear all cached keys.</p> <p>Example: <pre><code>fm.clear_cache()  # Clears all cached values\n</code></pre></p>"},{"location":"api/mixins/cache_mixin/#invalidate_cache","title":"invalidate_cache","text":"<pre><code>def invalidate_cache(self, pattern: Optional[str] = None) -&gt; int\n</code></pre> <p>Invalidate cache entries, optionally using a pattern.</p> <p>Parameters: - <code>pattern</code> (Optional[str]): Pattern to match keys (supports wildcards). If None, invalidates all</p> <p>Returns: - <code>int</code>: Number of entries invalidated</p> <p>Example: <pre><code># Invalidate all cache entries\ncount = fm.invalidate_cache()\n\n# Invalidate only database-related entries\ncount = fm.invalidate_cache(\"key:database.*\")\n</code></pre></p>"},{"location":"api/mixins/cleanup_mixin/","title":"CleanupMixin","text":"<p>Provides cleanup functionality for the file manager. The CleanupMixin contains operations for cleaning empty sections, removing nulls, and compacting data.</p>"},{"location":"api/mixins/cleanup_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/cleanup_mixin/#clean_empty_sections","title":"clean_empty_sections","text":"<pre><code>def clean_empty_sections(self) -&gt; int\n</code></pre> <p>Remove empty sections from the data.</p> <p>Returns: - <code>int</code>: Number of empty sections removed</p> <p>Example: <pre><code>removed = fm.clean_empty_sections()\nprint(f\"Removed {removed} empty sections\")\n</code></pre></p>"},{"location":"api/mixins/cleanup_mixin/#remove_nulls","title":"remove_nulls","text":"<pre><code>def remove_nulls(self) -&gt; int\n</code></pre> <p>Remove null/None values from the data.</p> <p>Returns: - <code>int</code>: Number of null values removed</p> <p>Example: <pre><code>removed = fm.remove_nulls()\nprint(f\"Removed {removed} null values\")\n</code></pre></p>"},{"location":"api/mixins/cleanup_mixin/#compact","title":"compact","text":"<pre><code>def compact(self) -&gt; Dict[str, int]\n</code></pre> <p>Optimize the data structure by removing empty sections and nulls.</p> <p>Returns: - <code>Dict[str, int]</code>: Dictionary with counts of operations performed</p> <p>Example: <pre><code>result = fm.compact()\nprint(f\"Removed {result['empty_sections']} empty sections and {result['nulls']} nulls\")\nprint(f\"Total operations: {result['total_operations']}\")\n</code></pre></p>"},{"location":"api/mixins/clone_mixin/","title":"CloneMixin","text":"<p>Provides cloning and copying functionality for the file manager. The CloneMixin contains operations for cloning, copying, and merging data.</p>"},{"location":"api/mixins/clone_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/clone_mixin/#clone","title":"clone","text":"<pre><code>def clone(self) -&gt; \"YAPFileManager\"\n</code></pre> <p>Create a complete copy of the manager.</p> <p>Returns: - <code>YAPFileManager</code>: New YAPFileManager with the same data</p> <p>Example: <pre><code>original = YAPFileManager(\"config.json\")\ncopy = original.clone()\nprint(copy.path != original.path)  # Different temporary file\n</code></pre></p>"},{"location":"api/mixins/clone_mixin/#copy_to","title":"copy_to","text":"<pre><code>def copy_to(\n    self, \n    destination: Union[str, Path], \n    strategy: Optional[BaseFileStrategy] = None\n) -&gt; \"YAPFileManager\"\n</code></pre> <p>Copy content to another file.</p> <p>Parameters: - <code>destination</code> (Union[str, Path]): Destination file path - <code>strategy</code> (Optional[BaseFileStrategy]): Optional strategy for the destination file</p> <p>Returns: - <code>YAPFileManager</code>: New YAPFileManager for the destination file</p> <p>Example: <pre><code># Copy to JSON\nfm.copy_to(\"backup.json\")\n\n# Copy to TOML with auto-detection\nfm.copy_to(\"config.toml\")\n</code></pre></p>"},{"location":"api/mixins/clone_mixin/#merge_from","title":"merge_from","text":"<pre><code>def merge_from(\n    self, \n    source: Union[str, Path, \"YAPFileManager\"], \n    strategy: str = \"deep\"\n) -&gt; None\n</code></pre> <p>Merge from another file or manager.</p> <p>Parameters: - <code>source</code> (Union[str, Path, \"YAPFileManager\"]): Source file or YAPFileManager - <code>strategy</code> (str): Merge strategy (\"deep\", \"shallow\", \"replace\")</p> <p>Example: <pre><code># Deep merge\nfm.merge_from(\"override.json\", strategy=\"deep\")\n\n# Replace merge\nfm.merge_from(other_manager, strategy=\"replace\")\n</code></pre></p>"},{"location":"api/mixins/context_mixin/","title":"ContextMixin","text":"<p>Provides context manager functionality.</p>"},{"location":"api/mixins/context_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/context_mixin/#enter","title":"enter","text":"<pre><code>def __enter__(self) -&gt; Self\n</code></pre> <p>Enter the context manager and load the file.</p> <p>Returns: - <code>Self</code>: The file manager instance</p> <p>Example: <pre><code>with YAPFileManager(\"config.json\") as fm:\n    # File is automatically loaded\n    fm.set_key(\"value\", dot_key=\"key\")\n</code></pre></p>"},{"location":"api/mixins/context_mixin/#exit","title":"exit","text":"<pre><code>def __exit__(self, exc_type, exc_val, exc_tb) -&gt; None\n</code></pre> <p>Exit the context manager and save if dirty.</p> <p>Parameters: - <code>exc_type</code>: Exception type - <code>exc_val</code>: Exception value - <code>exc_tb</code>: Exception traceback</p> <p>Example: <pre><code>with YAPFileManager(\"config.json\") as fm:\n    fm.set_key(\"value\", dot_key=\"key\")\n    # File is automatically saved when exiting context\n</code></pre></p>"},{"location":"api/mixins/context_mixin/#lazy_save","title":"lazy_save","text":"<pre><code>@contextmanager\ndef lazy_save(self, save_on_exit: bool = True) -&gt; Iterator[Self]\n</code></pre> <p>Context manager for lazy saving.</p> <p>Parameters: - <code>save_on_exit</code> (bool): Whether to save when exiting the context. Default: True</p> <p>Returns: - <code>Iterator[Self]</code>: The file manager instance</p> <p>Example: <pre><code>with fm.lazy_save():\n    fm.set_key(\"value1\", dot_key=\"key1\")\n    fm.set_key(\"value2\", dot_key=\"key2\")\n    # Save happens here when exiting lazy_save context\n</code></pre></p>"},{"location":"api/mixins/context_mixin/#auto_save","title":"auto_save","text":"<pre><code>@contextmanager\ndef auto_save(self, save_on_exit: bool = True) -&gt; Iterator[Self]\n</code></pre> <p>Context manager for automatic saving.</p> <p>Parameters: - <code>save_on_exit</code> (bool): Whether to save when exiting the context. Default: True</p> <p>Returns: - <code>Iterator[Self]</code>: The file manager instance</p> <p>Example: <pre><code>with fm.auto_save():\n    fm.set_key(\"value\", dot_key=\"key\")\n    # Save happens here when exiting auto_save context\n</code></pre></p>"},{"location":"api/mixins/export_mixin/","title":"ExportMixin","text":"<p>Provides export functionality for the file manager. The ExportMixin contains operations for exporting data to different formats.</p>"},{"location":"api/mixins/export_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/export_mixin/#to_current_format","title":"to_current_format","text":"<pre><code>def to_current_format(self) -&gt; str\n</code></pre> <p>Export data to the current file's format using the manager's strategy.</p> <p>Returns: - <code>str</code>: String content in the current format</p> <p>Example: <pre><code>fm = YAPFileManager(\"config.json\")\njson_str = fm.to_current_format()  # Uses JSON strategy\n</code></pre></p>"},{"location":"api/mixins/export_mixin/#to_json","title":"to_json","text":"<pre><code>def to_json(self, pretty: bool = True) -&gt; str\n</code></pre> <p>Export data to JSON format.</p> <p>Parameters: - <code>pretty</code> (bool): If True, formats with indentation</p> <p>Returns: - <code>str</code>: JSON string</p> <p>Example: <pre><code>json_str = fm.to_json()\njson_str = fm.to_json(pretty=False)  # Compact format\n</code></pre></p>"},{"location":"api/mixins/export_mixin/#to_yaml","title":"to_yaml","text":"<pre><code>def to_yaml(self) -&gt; str\n</code></pre> <p>Export data to YAML format.</p> <p>Returns: - <code>str</code>: YAML string</p> <p>Example: <pre><code>yaml_str = fm.to_yaml()\n</code></pre></p>"},{"location":"api/mixins/export_mixin/#to_toml","title":"to_toml","text":"<pre><code>def to_toml(self) -&gt; str\n</code></pre> <p>Export data to TOML format.</p> <p>Returns: - <code>str</code>: TOML string</p> <p>Example: <pre><code>toml_str = fm.to_toml()\n</code></pre></p>"},{"location":"api/mixins/export_mixin/#export_section","title":"export_section","text":"<pre><code>def export_section(\n    self,\n    section_path: str,\n    format: str = \"json\",\n    output_path: Optional[Union[str, Path]] = None,\n) -&gt; Union[str, Path]\n</code></pre> <p>Export a specific section to a file or return as string.</p> <p>Parameters: - <code>section_path</code> (str): Dot-separated path to the section - <code>format</code> (str): Output format (\"json\", \"yaml\", \"toml\") - <code>output_path</code> (Optional[Union[str, Path]]): Optional output file path. If None, returns string</p> <p>Returns: - <code>Union[str, Path]</code>: String content or output file path</p> <p>Example: <pre><code># Returns JSON string\njson_str = fm.export_section(\"database\", \"json\")\n\n# Saves to file\nfm.export_section(\"api\", \"yaml\", \"api_config.yaml\")\n</code></pre></p>"},{"location":"api/mixins/export_mixin/#export_to_file","title":"export_to_file","text":"<pre><code>def export_to_file(\n    self, \n    output_path: Union[str, Path], \n    format: Optional[str] = None\n) -&gt; Path\n</code></pre> <p>Export the entire data to a file in the specified format.</p> <p>Parameters: - <code>output_path</code> (Union[str, Path]): Output file path - <code>format</code> (Optional[str]): Output format. If None, inferred from file extension</p> <p>Returns: - <code>Path</code>: Output file path</p> <p>Example: <pre><code>fm.export_to_file(\"backup.json\")\nfm.export_to_file(\"config.yaml\", \"yaml\")\n</code></pre></p>"},{"location":"api/mixins/file_operations_mixin/","title":"FileOperationsMixin","text":"<p>Provides basic file operations.</p>"},{"location":"api/mixins/file_operations_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/file_operations_mixin/#exists","title":"exists","text":"<pre><code>def exists(self) -&gt; bool\n</code></pre> <p>Check if the file exists.</p> <p>Returns: - <code>bool</code>: True if the file exists, False otherwise</p> <p>Example: <pre><code>if fm.exists():\n    print(\"File exists\")\n</code></pre></p>"},{"location":"api/mixins/file_operations_mixin/#is_dirty","title":"is_dirty","text":"<pre><code>def is_dirty(self) -&gt; bool\n</code></pre> <p>Check if the file is dirty (has unsaved changes).</p> <p>Returns: - <code>bool</code>: True if the file has unsaved changes, False otherwise</p> <p>Example: <pre><code>if fm.is_dirty():\n    print(\"File has unsaved changes\")\n</code></pre></p>"},{"location":"api/mixins/file_operations_mixin/#is_loaded","title":"is_loaded","text":"<pre><code>def is_loaded(self) -&gt; bool\n</code></pre> <p>Check if the file is loaded in memory.</p> <p>Returns: - <code>bool</code>: True if the file is loaded, False otherwise</p> <p>Example: <pre><code>if fm.is_loaded():\n    print(\"File is loaded in memory\")\n</code></pre></p>"},{"location":"api/mixins/file_operations_mixin/#load","title":"load","text":"<pre><code>def load(self) -&gt; None\n</code></pre> <p>Load data from the file.</p> <p>Raises: - <code>FileNotFoundError</code>: If the file doesn't exist and auto_create is False - <code>ValueError</code>: If the file format is invalid or corrupted - <code>LoadFileError</code>: If there's an error during the loading process</p> <p>Example: <pre><code>fm.load()  # Loads the file content into memory\n</code></pre></p>"},{"location":"api/mixins/file_operations_mixin/#save","title":"save","text":"<pre><code>def save(self) -&gt; None\n</code></pre> <p>Save data to the file.</p> <p>Raises: - <code>PermissionError</code>: If the file cannot be written due to permissions - <code>ValueError</code>: If the data format is invalid for the file type - <code>FileWriteError</code>: If there's an error during the writing process</p> <p>Example: <pre><code>fm.save()  # Saves the current data to disk\n</code></pre></p>"},{"location":"api/mixins/file_operations_mixin/#save_if_dirty","title":"save_if_dirty","text":"<pre><code>def save_if_dirty(self) -&gt; None\n</code></pre> <p>Save the file only if it has been modified.</p> <p>Example: <pre><code>fm.save_if_dirty()  # Only saves if there are unsaved changes\n</code></pre></p>"},{"location":"api/mixins/file_operations_mixin/#reload","title":"reload","text":"<pre><code>def reload(self) -&gt; None\n</code></pre> <p>Reload data from the file, discarding any unsaved changes.</p> <p>Example: <pre><code>fm.reload()  # Reloads from disk, discards unsaved changes\n</code></pre></p>"},{"location":"api/mixins/file_operations_mixin/#mark_as_dirty","title":"mark_as_dirty","text":"<pre><code>def mark_as_dirty(self) -&gt; None\n</code></pre> <p>Mark the file as dirty (has unsaved changes).</p> <p>Example: <pre><code>fm.mark_as_dirty()  # Mark as having unsaved changes\n</code></pre></p>"},{"location":"api/mixins/file_operations_mixin/#mark_as_clean","title":"mark_as_clean","text":"<pre><code>def mark_as_clean(self) -&gt; None\n</code></pre> <p>Mark the file as clean (no unsaved changes).</p> <p>Example: <pre><code>fm.mark_as_clean()  # Mark as clean\n</code></pre></p>"},{"location":"api/mixins/file_operations_mixin/#mark_as_loaded","title":"mark_as_loaded","text":"<pre><code>def mark_as_loaded(self) -&gt; None\n</code></pre> <p>Mark the file as loaded in memory.</p> <p>Example: <pre><code>fm.mark_as_loaded()  # Mark as loaded\n</code></pre></p>"},{"location":"api/mixins/file_operations_mixin/#unload","title":"unload","text":"<pre><code>def unload(self) -&gt; None\n</code></pre> <p>Unload the file from memory.</p> <p>Example: <pre><code>fm.unload()  # Free memory\n</code></pre></p>"},{"location":"api/mixins/file_operations_mixin/#create_empty_file","title":"create_empty_file","text":"<pre><code>def create_empty_file(self) -&gt; None\n</code></pre> <p>Create an empty file.</p> <p>Example: <pre><code>fm.create_empty_file()  # Creates empty file\n</code></pre></p>"},{"location":"api/mixins/file_operations_mixin/#load_if_not_loaded","title":"load_if_not_loaded","text":"<pre><code>def load_if_not_loaded(self) -&gt; None\n</code></pre> <p>Load the file if it is not loaded.</p> <p>Example: <pre><code>fm.load_if_not_loaded()  # Load only if not already loaded\n</code></pre></p>"},{"location":"api/mixins/key_operations_mixin/","title":"KeyOperationsMixin","text":"<p>Provides key-based data access with dot notation.</p>"},{"location":"api/mixins/key_operations_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/key_operations_mixin/#set_key","title":"set_key","text":"<pre><code>def set_key(\n    self,\n    value: Any,\n    dot_key: Optional[str] = None,\n    *,\n    path: Optional[List[str]] = None,\n    key_name: Optional[str] = None,\n    overwrite: bool = True\n) -&gt; None\n</code></pre> <p>Set a value in the file using dot notation.</p> <p>Parameters: - <code>value</code> (Any): The value to set - <code>dot_key</code> (Optional[str]): The dot-separated key - <code>path</code> (Optional[List[str]]): The path to the key - <code>key_name</code> (Optional[str]): The name of the key - <code>overwrite</code> (bool): Whether to overwrite the existing value. Default: True</p> <p>Example: <pre><code># Using dot notation\nfm.set_key(\"localhost\", dot_key=\"database.host\")\n\n# Using path and key name\nfm.set_key(5432, path=[\"database\"], key_name=\"port\")\n\n# Only set if key doesn't exist\nfm.set_key(\"default\", dot_key=\"database.host\", overwrite=False)\n</code></pre></p>"},{"location":"api/mixins/key_operations_mixin/#get_key","title":"get_key","text":"<pre><code>def get_key(\n    self,\n    dot_key: Optional[str] = None,\n    *,\n    path: Optional[List[str]] = None,\n    key_name: Optional[str] = None,\n    default: Any = None\n) -&gt; Any\n</code></pre> <p>Get a value from the file using dot notation.</p> <p>Parameters: - <code>dot_key</code> (Optional[str]): The dot-separated key - <code>path</code> (Optional[List[str]]): The path to the key - <code>key_name</code> (Optional[str]): The name of the key - <code>default</code> (Any): The default value if the key is not found</p> <p>Returns: - <code>Any</code>: The value at the specified path or default</p> <p>Example: <pre><code># Using dot notation\nhost = fm.get_key(dot_key=\"database.host\", default=\"localhost\")\n\n# Using path and key name\nport = fm.get_key(path=[\"database\"], key_name=\"port\", default=5432)\n</code></pre></p>"},{"location":"api/mixins/key_operations_mixin/#has_key","title":"has_key","text":"<pre><code>def has_key(\n    self,\n    dot_key: Optional[str] = None,\n    *,\n    path: Optional[List[str]] = None,\n    key_name: Optional[str] = None\n) -&gt; bool\n</code></pre> <p>Check if a key exists in the file using dot notation.</p> <p>Parameters: - <code>dot_key</code> (Optional[str]): The dot-separated key - <code>path</code> (Optional[List[str]]): The path to the key - <code>key_name</code> (Optional[str]): The name of the key</p> <p>Returns: - <code>bool</code>: True if the key exists, False otherwise</p> <p>Example: <pre><code># Using dot notation\nif fm.has_key(dot_key=\"database.host\"):\n    print(\"Database host exists\")\n\n# Using path and key name\nif fm.has_key(path=[\"database\"], key_name=\"port\"):\n    print(\"Database port exists\")\n</code></pre></p>"},{"location":"api/mixins/key_operations_mixin/#delete_key","title":"delete_key","text":"<pre><code>def delete_key(\n    self,\n    dot_key: Optional[str] = None,\n    *,\n    path: Optional[List[str]] = None,\n    key_name: Optional[str] = None\n) -&gt; bool\n</code></pre> <p>Delete a key from the file using dot notation.</p> <p>Parameters: - <code>dot_key</code> (Optional[str]): The dot-separated key - <code>path</code> (Optional[List[str]]): The path to the key - <code>key_name</code> (Optional[str]): The name of the key</p> <p>Returns: - <code>bool</code>: True if the key was deleted, False if it didn't exist</p> <p>Example: <pre><code># Using dot notation\ndeleted = fm.delete_key(dot_key=\"database.host\")\n\n# Using path and key name\ndeleted = fm.delete_key(path=[\"database\"], key_name=\"port\")\n</code></pre></p>"},{"location":"api/mixins/lazy_sections_mixin/","title":"LazySectionsMixin","text":"<p>Provides lazy loading functionality for entire sections to optimize memory usage and performance.</p>"},{"location":"api/mixins/lazy_sections_mixin/#features","title":"Features","text":"<ul> <li>Lazy Loading: Sections are loaded only when accessed</li> <li>Memory Efficient: Prevents loading large sections unnecessarily</li> <li>Cache Integration: Works with the unified cache system</li> <li>Automatic Invalidation: Cache invalidation when sections are modified</li> <li>Statistics Tracking: Monitor lazy loading performance</li> </ul>"},{"location":"api/mixins/lazy_sections_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/lazy_sections_mixin/#get_section","title":"get_section","text":"<pre><code>def get_section(\n    self,\n    dot_key: Optional[str] = None,\n    *,\n    path: Optional[List[str]] = None,\n    key_name: Optional[str] = None,\n    default: Any = None,\n    lazy: bool = True\n) -&gt; Any\n</code></pre> <p>Get an entire section from the file with lazy loading.</p> <p>Parameters: - <code>dot_key</code> (Optional[str]): The dot-separated key for the section - <code>path</code> (Optional[List[str]]): The path to the section - <code>key_name</code> (Optional[str]): The name of the section - <code>default</code> (Any): The default value if the section is not found - <code>lazy</code> (bool): Whether to use lazy loading. Default: True</p> <p>Returns: - <code>Any</code>: The section data or default</p> <p>Example: <pre><code># Lazy loading (default behavior)\ndb_section = fm.get_section(\"database\", lazy=True)\n\n# Force immediate loading\ndb_section = fm.get_section(\"database\", lazy=False)\n</code></pre></p>"},{"location":"api/mixins/lazy_sections_mixin/#set_section","title":"set_section","text":"<pre><code>def set_section(\n    self,\n    data: Dict[str, Any],\n    dot_key: Optional[str] = None,\n    *,\n    path: Optional[List[str]] = None,\n    key_name: Optional[str] = None,\n    overwrite: bool = True,\n    update_lazy_cache: bool = True\n) -&gt; None\n</code></pre> <p>Set an entire section in the file with lazy cache invalidation.</p> <p>Parameters: - <code>data</code> (Dict[str, Any]): The section data to set - <code>dot_key</code> (Optional[str]): The dot-separated key for the section - <code>path</code> (Optional[List[str]]): The path to the section - <code>key_name</code> (Optional[str]): The name of the section - <code>overwrite</code> (bool): Whether to overwrite the existing section. Default: True - <code>update_lazy_cache</code> (bool): Whether to invalidate lazy cache. Default: True</p> <p>Example: <pre><code>fm.set_section({\n    \"host\": \"localhost\",\n    \"port\": 5432,\n    \"ssl\": True\n}, dot_key=\"database\")\n</code></pre></p>"},{"location":"api/mixins/lazy_sections_mixin/#delete_section","title":"delete_section","text":"<pre><code>def delete_section(\n    self,\n    dot_key: Optional[str] = None,\n    *,\n    path: Optional[List[str]] = None,\n    key_name: Optional[str] = None\n) -&gt; bool\n</code></pre> <p>Delete an entire section from the file with lazy cache invalidation.</p> <p>Parameters: - <code>dot_key</code> (Optional[str]): The dot-separated key for the section - <code>path</code> (Optional[List[str]]): The path to the section - <code>key_name</code> (Optional[str]): The name of the section</p> <p>Returns: - <code>bool</code>: True if the section was deleted, False if it didn't exist</p> <p>Example: <pre><code>deleted = fm.delete_section(dot_key=\"database\")\n</code></pre></p>"},{"location":"api/mixins/lazy_sections_mixin/#clear_lazy_cache","title":"clear_lazy_cache","text":"<pre><code>def clear_lazy_cache(self) -&gt; None\n</code></pre> <p>Clear all lazy-loaded sections from cache.</p> <p>Example: <pre><code>fm.clear_lazy_cache()  # Clears all lazy-loaded sections\n</code></pre></p>"},{"location":"api/mixins/lazy_sections_mixin/#get_lazy_stats","title":"get_lazy_stats","text":"<pre><code>def get_lazy_stats(self) -&gt; Dict[str, Any]\n</code></pre> <p>Get statistics about lazy loading.</p> <p>Returns: - <code>Dict[str, Any]</code>: Statistics including total sections, loaded sections, etc.</p> <p>Example: <pre><code>stats = fm.get_lazy_stats()\nprint(f\"Total sections: {stats['total_sections']}\")\nprint(f\"Loaded sections: {stats['loaded_sections']}\")\n</code></pre></p>"},{"location":"api/mixins/multi_file_mixin/","title":"MultiFileMixin","text":"<p>Provides functionality to load and merge multiple files into a single dictionary. It uses the Strategy pattern for different merge approaches and integrates with the existing cache system.</p>"},{"location":"api/mixins/multi_file_mixin/#key-features","title":"Key Features","text":"<ul> <li>Multiple merge strategies (deep, namespace, priority, conditional, append, replace)</li> <li>File pattern support (glob patterns)</li> <li>Integration with existing cache system</li> <li>Conditional merging based on environment or context</li> <li>Namespace prefixing for organized data structure</li> <li>Performance optimization with lazy loading</li> </ul>"},{"location":"api/mixins/multi_file_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/multi_file_mixin/#load_multiple_files","title":"load_multiple_files","text":"<pre><code>def load_multiple_files(\n    self,\n    file_paths: Union[List[Union[str, Path]], str],\n    strategy: Union[str, MergeStrategy, BaseMergeStrategy] = MergeStrategy.DEEP,\n    file_patterns: Optional[List[str]] = None,\n    conditional_filter: Optional[Callable[[str, Dict[str, Any]], bool]] = None,\n    use_cache: bool = True,\n    **kwargs: Any,\n) -&gt; Dict[str, Any]\n</code></pre> <p>Load and merge multiple files into a single dictionary.</p> <p>Parameters: - <code>file_paths</code> (Union[List[Union[str, Path]], str]): List of file paths or single path/pattern string - <code>strategy</code> (Union[str, MergeStrategy, BaseMergeStrategy]): Strategy to use for merging files - <code>file_patterns</code> (Optional[List[str]]): Optional list of glob patterns to expand - <code>conditional_filter</code> (Optional[Callable[[str, Dict[str, Any]], bool]]): Optional function to filter files based on content - <code>use_cache</code> (bool): Whether to use caching for loaded files - <code>**kwargs</code> (Any): Additional arguments passed to the strategy</p> <p>Returns: - <code>Dict[str, Any]</code>: Dictionary containing merged data from all files</p> <p>Example: <pre><code># Deep merge multiple files\ndata = fm.load_multiple_files([\n    \"config.json\",\n    \"secrets.json\"\n], strategy=\"deep\")\n\n# Namespace merge with prefix\ndata = fm.load_multiple_files([\n    \"database.json\",\n    \"cache.toml\"\n], strategy=\"namespace\", namespace_prefix=\"app\")\n\n# Use file patterns\ndata = fm.load_multiple_files(\n    \"config/*.json\",\n    strategy=\"deep\"\n)\n</code></pre></p>"},{"location":"api/mixins/multi_file_mixin/#get_available_merge_strategies","title":"get_available_merge_strategies","text":"<pre><code>def get_available_merge_strategies(self) -&gt; List[str]\n</code></pre> <p>Get list of available merge strategies.</p> <p>Returns: - <code>List[str]</code>: List of strategy names</p> <p>Example: <pre><code>strategies = fm.get_available_merge_strategies()\nprint(f\"Available strategies: {strategies}\")\n</code></pre></p>"},{"location":"api/mixins/multi_file_mixin/#invalidate_multi_file_cache","title":"invalidate_multi_file_cache","text":"<pre><code>def invalidate_multi_file_cache(self, file_path: Union[str, Path]) -&gt; None\n</code></pre> <p>Invalidate cache for a specific file in multi-file operations.</p> <p>Parameters: - <code>file_path</code> (Union[str, Path]): Path to the file to invalidate</p> <p>Example: <pre><code>fm.invalidate_multi_file_cache(\"config.json\")\n</code></pre></p>"},{"location":"api/mixins/multi_file_mixin/#load_file_group","title":"load_file_group","text":"<pre><code>def load_file_group(\n    self, \n    group_name: str, \n    config: Dict[str, Any], \n    **kwargs: Any\n) -&gt; Dict[str, Any]\n</code></pre> <p>Load a predefined group of files based on configuration.</p> <p>Parameters: - <code>group_name</code> (str): Name of the file group - <code>config</code> (Dict[str, Any]): Configuration dictionary defining the group - <code>**kwargs</code> (Any): Additional arguments for file loading</p> <p>Returns: - <code>Dict[str, Any]</code>: Merged dictionary from the file group</p> <p>Example: <pre><code>config = {\n    \"app_config\": {\n        \"files\": [\"config.json\", \"secrets.json\"],\n        \"strategy\": \"deep\",\n        \"namespace_prefix\": \"app\"\n    }\n}\ndata = fm.load_file_group(\"app_config\", config)\n</code></pre></p>"},{"location":"api/mixins/search_mixin/","title":"SearchMixin","text":"<p>Provides search functionality for the file manager. The SearchMixin contains operations for finding keys, values, and searching content.</p>"},{"location":"api/mixins/search_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/search_mixin/#find_key","title":"find_key","text":"<pre><code>def find_key(self, pattern: str, use_wildcards: bool = True) -&gt; List[str]\n</code></pre> <p>Find all keys matching a pattern.</p> <p>Parameters: - <code>pattern</code> (str): Search pattern (supports wildcards like *, ?, []) - <code>use_wildcards</code> (bool): If True, uses fnmatch wildcards, otherwise simple substring search</p> <p>Returns: - <code>List[str]</code>: List of matching keys</p> <p>Example: <pre><code># Search with wildcards\nkeys = fm.find_key(\"database.*\")  # Find database.host, database.port\nkeys = fm.find_key(\"api.v[0-9]*\")  # Find api.v1, api.v2, etc.\n\n# Simple substring search\nkeys = fm.find_key(\"host\", use_wildcards=False)\n</code></pre></p>"},{"location":"api/mixins/search_mixin/#find_value","title":"find_value","text":"<pre><code>def find_value(self, value: Any, deep: bool = True) -&gt; List[str]\n</code></pre> <p>Find all keys containing a specific value.</p> <p>Parameters: - <code>value</code> (Any): Value to search for - <code>deep</code> (bool): If True, searches recursively in nested structures</p> <p>Returns: - <code>List[str]</code>: List of keys containing the value</p> <p>Example: <pre><code># Value search\nkeys = fm.find_value(\"localhost\")  # Find all keys with \"localhost\"\nkeys = fm.find_value(5432)  # Find all keys with port 5432\n</code></pre></p>"},{"location":"api/mixins/search_mixin/#search_in_values","title":"search_in_values","text":"<pre><code>def search_in_values(self, query: str, case_sensitive: bool = True) -&gt; List[tuple]\n</code></pre> <p>Search for text in string values.</p> <p>Parameters: - <code>query</code> (str): Text to search for - <code>case_sensitive</code> (bool): Whether search should be case sensitive</p> <p>Returns: - <code>List[tuple]</code>: List of tuples (key, value) containing the query</p> <p>Example: <pre><code># Search in values\nresults = fm.search_in_values(\"localhost\")  # Find all string values containing \"localhost\"\nresults = fm.search_in_values(\"API\", case_sensitive=False)  # Case insensitive search\n\nfor key, value in results:\n    print(f\"Key: {key}, Value: {value}\")\n</code></pre></p>"},{"location":"api/mixins/section_operations_mixin/","title":"SectionOperationsMixin","text":"<p>Provides section-based data management.</p>"},{"location":"api/mixins/section_operations_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/section_operations_mixin/#set_section","title":"set_section","text":"<pre><code>def set_section(\n    self,\n    section_data: Dict[str, Any],\n    dot_key: Optional[str] = None,\n    *,\n    path: Optional[List[str]] = None,\n    section_name: Optional[str] = None,\n    overwrite: bool = True\n) -&gt; None\n</code></pre> <p>Set an entire section in the file.</p> <p>Parameters: - <code>section_data</code> (Dict[str, Any]): The section data to set - <code>dot_key</code> (Optional[str]): The dot-separated key for the section - <code>path</code> (Optional[List[str]]): The path to the section - <code>section_name</code> (Optional[str]): The name of the section - <code>overwrite</code> (bool): Whether to overwrite the existing section. Default: True</p> <p>Example: <pre><code># Using dot notation\nfm.set_section({\n    \"host\": \"localhost\",\n    \"port\": 5432,\n    \"ssl\": True\n}, dot_key=\"database\")\n\n# Using path and section name\nfm.set_section({\n    \"version\": \"v1\",\n    \"timeout\": 30\n}, path=[\"api\"], section_name=\"config\")\n</code></pre></p>"},{"location":"api/mixins/section_operations_mixin/#get_section","title":"get_section","text":"<pre><code>def get_section(\n    self,\n    dot_key: Optional[str] = None,\n    *,\n    path: Optional[List[str]] = None,\n    section_name: Optional[str] = None,\n    default: Optional[Dict[str, Any]] = None\n) -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Get an entire section from the file.</p> <p>Parameters: - <code>dot_key</code> (Optional[str]): The dot-separated key for the section - <code>path</code> (Optional[List[str]]): The path to the section - <code>section_name</code> (Optional[str]): The name of the section - <code>default</code> (Optional[Dict[str, Any]]): The default value if the section is not found</p> <p>Returns: - <code>Optional[Dict[str, Any]]</code>: The section data or default</p> <p>Example: <pre><code># Using dot notation\ndb_config = fm.get_section(dot_key=\"database\")\n\n# Using path and section name\napi_config = fm.get_section(path=[\"api\"], section_name=\"config\")\n</code></pre></p>"},{"location":"api/mixins/section_operations_mixin/#has_section","title":"has_section","text":"<pre><code>def has_section(\n    self,\n    dot_key: Optional[str] = None,\n    *,\n    path: Optional[List[str]] = None,\n    section_name: Optional[str] = None\n) -&gt; bool\n</code></pre> <p>Check if a section exists in the file.</p> <p>Parameters: - <code>dot_key</code> (Optional[str]): The dot-separated key for the section - <code>path</code> (Optional[List[str]]): The path to the section - <code>section_name</code> (Optional[str]): The name of the section</p> <p>Returns: - <code>bool</code>: True if the section exists, False otherwise</p> <p>Example: <pre><code># Using dot notation\nif fm.has_section(dot_key=\"database\"):\n    print(\"Database section exists\")\n\n# Using path and section name\nif fm.has_section(path=[\"api\"], section_name=\"config\"):\n    print(\"API config section exists\")\n</code></pre></p>"},{"location":"api/mixins/section_operations_mixin/#delete_section","title":"delete_section","text":"<pre><code>def delete_section(\n    self,\n    dot_key: Optional[str] = None,\n    *,\n    path: Optional[List[str]] = None,\n    section_name: Optional[str] = None\n) -&gt; bool\n</code></pre> <p>Delete an entire section from the file.</p> <p>Parameters: - <code>dot_key</code> (Optional[str]): The dot-separated key for the section - <code>path</code> (Optional[List[str]]): The path to the section - <code>section_name</code> (Optional[str]): The name of the section</p> <p>Returns: - <code>bool</code>: True if the section was deleted, False if it didn't exist</p> <p>Example: <pre><code># Using dot notation\ndeleted = fm.delete_section(dot_key=\"database\")\n\n# Using path and section name\ndeleted = fm.delete_section(path=[\"api\"], section_name=\"config\")\n</code></pre></p>"},{"location":"api/mixins/security_mixin/","title":"SecurityMixin","text":"<p>Provides security functionality for the file manager. The SecurityMixin contains operations for freezing, unfreezing, and masking sensitive data.</p>"},{"location":"api/mixins/security_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/security_mixin/#freeze","title":"freeze","text":"<pre><code>def freeze(self) -&gt; None\n</code></pre> <p>Make the file read-only by preventing modifications.</p> <p>Example: <pre><code>fm.freeze()\nfm.set(\"new.key\", \"value\")  # Raises PermissionError\n</code></pre></p>"},{"location":"api/mixins/security_mixin/#unfreeze","title":"unfreeze","text":"<pre><code>def unfreeze(self) -&gt; None\n</code></pre> <p>Re-enable write operations on the file.</p> <p>Example: <pre><code>fm.unfreeze()\nfm.set(\"new.key\", \"value\")  # Now works\n</code></pre></p>"},{"location":"api/mixins/security_mixin/#is_frozen","title":"is_frozen","text":"<pre><code>def is_frozen(self) -&gt; bool\n</code></pre> <p>Check if the file is frozen (read-only).</p> <p>Returns: - <code>bool</code>: True if frozen, False otherwise</p> <p>Example: <pre><code>if fm.is_frozen():\n    print(\"File is read-only\")\n</code></pre></p>"},{"location":"api/mixins/security_mixin/#mask_sensitive","title":"mask_sensitive","text":"<pre><code>def mask_sensitive(\n    self, \n    keys_to_mask: Optional[List[str]] = None, \n    mask: str = \"***\"\n) -&gt; Dict[str, Any]\n</code></pre> <p>Create a masked version of the data with sensitive information hidden.</p> <p>Parameters: - <code>keys_to_mask</code> (Optional[List[str]]): List of keys to mask. If None, uses default sensitive keys - <code>mask</code> (str): String to use for masking</p> <p>Returns: - <code>Dict[str, Any]</code>: Dictionary with sensitive data masked</p> <p>Example: <pre><code># Mask with default sensitive keys\nmasked = fm.mask_sensitive()\n\n# Mask with specific keys\nmasked = fm.mask_sensitive([\"password\", \"secret\"], \"HIDDEN\")\n</code></pre></p>"},{"location":"api/mixins/security_mixin/#get_public_config","title":"get_public_config","text":"<pre><code>def get_public_config(\n    self, \n    sensitive_keys: Optional[List[str]] = None\n) -&gt; Dict[str, Any]\n</code></pre> <p>Get a public version of the configuration with sensitive data removed.</p> <p>Parameters: - <code>sensitive_keys</code> (Optional[List[str]]): List of keys to remove. If None, uses default sensitive keys</p> <p>Returns: - <code>Dict[str, Any]</code>: Dictionary with sensitive data removed</p> <p>Example: <pre><code># Public config with default sensitive data removal\npublic = fm.get_public_config()\n\n# Public config with specific keys\npublic = fm.get_public_config([\"password\", \"secret\"])\n</code></pre></p>"},{"location":"api/mixins/security_mixin/#default-sensitive-keys","title":"Default Sensitive Keys","text":"<p>The SecurityMixin automatically recognizes the following key patterns as sensitive: - password, passwd, pwd - secret, key, token, auth, credential - private, sensitive, confidential - api_key, access_token, refresh_token - session_id, cookie</p>"},{"location":"api/mixins/streaming_mixin/","title":"StreamingMixin","text":"<p>Provides streaming functionality for processing large files that don't fit in memory.</p>"},{"location":"api/mixins/streaming_mixin/#features","title":"Features","text":"<ul> <li>Chunked Reading: Process files in configurable chunks</li> <li>Memory Efficient: Handle files larger than available RAM</li> <li>Multiple Formats: Support for different file encodings</li> <li>Progress Tracking: Monitor processing progress</li> <li>Search Capabilities: Search within large files</li> <li>Section Extraction: Extract specific sections from large files</li> <li>Thread Safety: Safe for concurrent access</li> </ul>"},{"location":"api/mixins/streaming_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/streaming_mixin/#create_streaming_reader","title":"create_streaming_reader","text":"<pre><code>def create_streaming_reader(\n    self,\n    chunk_size: Optional[int] = 1024 * 1024,\n    buffer_size: int = 8192,\n    encoding: str = \"utf-8\"\n) -&gt; StreamingFileReader\n</code></pre> <p>Create a streaming reader for use as a context manager.</p> <p>Parameters: - <code>chunk_size</code> (Optional[int]): Size of each chunk in bytes - <code>buffer_size</code> (int): Buffer size for reading - <code>encoding</code> (str): File encoding</p> <p>Returns: - <code>StreamingFileReader</code>: StreamingFileReader instance for use as context manager</p> <p>Example: <pre><code>with fm.create_streaming_reader() as reader:\n    for chunk in reader.read_chunks():\n        process_chunk(chunk)\n</code></pre></p>"},{"location":"api/mixins/streaming_mixin/#stream_file","title":"stream_file","text":"<pre><code>def stream_file(\n    self,\n    chunk_size: Optional[int] = 1024 * 1024,  # 1MB par d\u00e9faut\n    buffer_size: int = 8192,  # 8KB par d\u00e9faut\n    encoding: str = \"utf-8\"  # utf-8 par d\u00e9faut\n) -&gt; Iterator[str]\n</code></pre> <p>Stream file chunks from a large file.</p> <p>Parameters: - <code>chunk_size</code> (Optional[int]): Size of each chunk in bytes. Default: 1MB - <code>buffer_size</code> (int): Buffer size for reading. Default: 8KB - <code>encoding</code> (str): File encoding. Default: utf-8</p> <p>Yields: - <code>str</code>: File chunks as strings</p> <p>Example: <pre><code>for chunk in fm.stream_file():\n    process_chunk(chunk)\n</code></pre></p>"},{"location":"api/mixins/streaming_mixin/#stream_lines","title":"stream_lines","text":"<pre><code>def stream_lines(\n    self,\n    chunk_size: Optional[int] = 1024 * 1024  # 1MB par d\u00e9faut\n) -&gt; Iterator[str]\n</code></pre> <p>Stream file lines from a large file.</p> <p>Parameters: - <code>chunk_size</code> (Optional[int]): Size of each chunk in bytes. Default: 1MB</p> <p>Yields: - <code>str</code>: File lines</p> <p>Example: <pre><code>for line in fm.stream_lines():\n    if \"error\" in line.lower():\n        print(f\"Error line: {line}\")\n</code></pre></p>"},{"location":"api/mixins/streaming_mixin/#stream_sections","title":"stream_sections","text":"<pre><code>def stream_sections(\n    self,\n    section_marker: str,\n    end_marker: Optional[str] = None,\n    chunk_size: Optional[int] = 1024 * 1024  # 1MB par d\u00e9faut\n) -&gt; Iterator[Dict[str, Any]]\n</code></pre> <p>Stream file sections from a large file.</p> <p>Parameters: - <code>section_marker</code> (str): Marker that starts a section - <code>end_marker</code> (Optional[str]): Optional marker that ends a section - <code>chunk_size</code> (Optional[int]): Size of each chunk in bytes. Default: 1MB</p> <p>Yields: - <code>Dict[str, Any]</code>: Dictionary with section information</p> <p>Example: <pre><code>for section in fm.stream_sections(\"[\", \"]\"):\n    print(f\"Section: {section['name']}\")\n    print(f\"Content: {section['content']}\")\n</code></pre></p>"},{"location":"api/mixins/streaming_mixin/#process_large_file","title":"process_large_file","text":"<pre><code>def process_large_file(\n    self,\n    processor: Callable[[str], Any],\n    progress_callback: Optional[Callable[[float], None]] = None\n) -&gt; Iterator[Any]\n</code></pre> <p>Process a large file with a custom processor function.</p> <p>Parameters: - <code>processor</code> (Callable[[str], Any]): Function to process each chunk - <code>progress_callback</code> (Optional[Callable[[float], None]]): Callback for progress updates</p> <p>Yields: - <code>Any</code>: Results from the processor function</p> <p>Example: <pre><code>def count_lines(chunk):\n    return chunk.count('\\n')\n\ndef progress_callback(progress):\n    print(f\"Progress: {progress:.1%}\")\n\nresults = list(fm.process_large_file(count_lines, progress_callback))\ntotal_lines = sum(results)\n</code></pre></p>"},{"location":"api/mixins/streaming_mixin/#search_in_file","title":"search_in_file","text":"<pre><code>def search_in_file(\n    self,\n    pattern: str,\n    case_sensitive: bool = True,\n    context_lines: int = 2\n) -&gt; Iterator[Dict[str, Any]]\n</code></pre> <p>Search for a pattern in a large file.</p> <p>Parameters: - <code>pattern</code> (str): Pattern to search for - <code>case_sensitive</code> (bool): Whether search is case sensitive. Default: True - <code>context_lines</code> (int): Number of context lines around matches. Default: 2</p> <p>Yields: - <code>Dict[str, Any]</code>: Match information with context</p> <p>Example: <pre><code>for match in fm.search_in_file(\"error\", case_sensitive=False):\n    print(f\"Found: {match['match']}\")\n    print(f\"Context: {match['context']}\")\n</code></pre></p>"},{"location":"api/mixins/streaming_mixin/#get_file_progress","title":"get_file_progress","text":"<pre><code>def get_file_progress(self) -&gt; float\n</code></pre> <p>Get the current progress of file processing.</p> <p>Returns: - <code>float</code>: Progress as a value between 0.0 and 1.0</p> <p>Example: <pre><code>progress = fm.get_file_progress()\nprint(f\"Progress: {progress:.1%}\")\n</code></pre></p>"},{"location":"api/mixins/streaming_mixin/#get_file_size","title":"get_file_size","text":"<pre><code>def get_file_size(self) -&gt; int\n</code></pre> <p>Get the size of the current file in bytes.</p> <p>Returns: - <code>int</code>: File size in bytes</p> <p>Example: <pre><code>size = fm.get_file_size()\nprint(f\"File size: {size} bytes\")\n</code></pre></p>"},{"location":"api/mixins/streaming_mixin/#estimate_processing_time","title":"estimate_processing_time","text":"<pre><code>def estimate_processing_time(\n    self,\n    processor: Callable[[str], Any]\n) -&gt; float\n</code></pre> <p>Estimate the time needed to process the file with a given processor.</p> <p>Parameters: - <code>processor</code> (Callable[[str], Any]): Function to estimate processing time for</p> <p>Returns: - <code>float</code>: Estimated processing time in seconds</p> <p>Example: <pre><code>def simple_processor(chunk):\n    return len(chunk)\n\nestimated_time = fm.estimate_processing_time(simple_processor)\nprint(f\"Estimated time: {estimated_time:.2f} seconds\")\n</code></pre></p>"},{"location":"api/mixins/transform_mixin/","title":"TransformMixin","text":"<p>Provides transformation functionality for the file manager. The TransformMixin contains operations for flattening, unflattening, and transforming data.</p>"},{"location":"api/mixins/transform_mixin/#methods","title":"Methods","text":""},{"location":"api/mixins/transform_mixin/#flatten","title":"flatten","text":"<pre><code>def flatten(self, separator: str = \".\") -&gt; Dict[str, Any]\n</code></pre> <p>Flatten the structure into a single-level dictionary.</p> <p>Parameters: - <code>separator</code> (str): Separator to use for nested keys</p> <p>Returns: - <code>Dict[str, Any]</code>: Flattened dictionary</p> <p>Example: <pre><code>flat = fm.flatten()\nprint(flat)  # {'database.host': 'localhost', 'database.port': 5432}\n\n# With custom separator\nflat = fm.flatten(separator=\"_\")\nprint(flat)  # {'database_host': 'localhost', 'database_port': 5432}\n</code></pre></p>"},{"location":"api/mixins/transform_mixin/#unflatten","title":"unflatten","text":"<pre><code>def unflatten(self, separator: str = \".\") -&gt; Dict[str, Any]\n</code></pre> <p>Reconstruct nested structure from flattened data.</p> <p>Parameters: - <code>separator</code> (str): Separator used in flattened keys</p> <p>Returns: - <code>Dict[str, Any]</code>: Nested dictionary</p> <p>Example: <pre><code># Flatten then unflatten\nflat_data = fm.flatten()\nnested = fm.unflatten()\n\n# With custom separator\nflat_data = fm.flatten(separator=\"_\")\nnested = fm.unflatten(separator=\"_\")\n</code></pre></p>"},{"location":"api/mixins/transform_mixin/#transform_values","title":"transform_values","text":"<pre><code>def transform_values(\n    self, \n    transformer_func: Callable[[Any], Any], \n    deep: bool = True\n) -&gt; None\n</code></pre> <p>Transform all values using a function.</p> <p>Parameters: - <code>transformer_func</code> (Callable[[Any], Any]): Function to transform values - <code>deep</code> (bool): If True, transforms recursively in nested structures</p> <p>Example: <pre><code># Convert all strings to uppercase\nfm.transform_values(lambda x: x.upper() if isinstance(x, str) else x)\n\n# Multiply all integers by 2\nfm.transform_values(lambda x: x * 2 if isinstance(x, int) else x)\n\n# Type conversion\nfm.transform_values(lambda x: str(x) if isinstance(x, (int, float)) else x)\n</code></pre></p>"},{"location":"api/mixins/transform_mixin/#transform_keys","title":"transform_keys","text":"<pre><code>def transform_keys(\n    self, \n    transformer_func: Callable[[str], str], \n    deep: bool = True\n) -&gt; None\n</code></pre> <p>Transform all keys using a function.</p> <p>Parameters: - <code>transformer_func</code> (Callable[[str], str]): Function to transform keys - <code>deep</code> (bool): If True, transforms recursively in nested structures</p> <p>Example: <pre><code># Convert all keys to uppercase\nfm.transform_keys(str.upper)\n\n# Replace underscores with dashes\nfm.transform_keys(lambda k: k.replace('_', '-'))\n\n# Add prefix\nfm.transform_keys(lambda k: f\"app_{k}\")\n\n# Convert snake_case to camelCase\ndef snake_to_camel(snake_str):\n    components = snake_str.split('_')\n    return components[0] + ''.join(x.title() for x in components[1:])\n\nfm.transform_keys(snake_to_camel)\n</code></pre></p>"},{"location":"roadmap/","title":"Roadmap &amp; Future Enhancements","text":"<p>This document outlines the planned features, improvements, and enhancements for YAPFM. These features are organized by priority and development phases.</p>"},{"location":"roadmap/#table-of-contents","title":"\ud83d\udccb Table of Contents","text":"<ol> <li>Phase 1: Core Enhancements - Additional file formats, enhanced caching, performance optimizations, and conflict resolution</li> <li>Phase 2: Advanced Features - Batch operations, cross-format merging, and advanced validation</li> <li>Phase 3: Enterprise Features - Distributed configuration, security features, and monitoring</li> <li>Phase 4: Ecosystem Integration - Framework integrations, cloud services, and database support</li> <li>Contributing to Development - How to contribute, development guidelines, and timeline</li> </ol>"},{"location":"roadmap/#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Core improvements? Check Phase 1: Core Enhancements</li> <li>Advanced features? See Phase 2: Advanced Features</li> <li>Enterprise needs? Read Phase 3: Enterprise Features</li> <li>Framework integration? Go to Phase 4: Ecosystem Integration</li> <li>Want to contribute? Browse Contributing to Development</li> </ul>"},{"location":"roadmap/#development-phases-overview","title":"Development Phases Overview","text":""},{"location":"roadmap/#phase-1-core-enhancements","title":"\ud83d\ude80 Phase 1: Core Enhancements","text":"<p>Focus on expanding file format support, improving performance, and adding essential features like conflict resolution.</p>"},{"location":"roadmap/#phase-2-advanced-features","title":"\ud83d\udd27 Phase 2: Advanced Features","text":"<p>Introduce batch operations, cross-format merging capabilities, and advanced validation systems.</p>"},{"location":"roadmap/#phase-3-enterprise-features","title":"\ud83c\udfe2 Phase 3: Enterprise Features","text":"<p>Add distributed configuration management, security features, and comprehensive monitoring.</p>"},{"location":"roadmap/#phase-4-ecosystem-integration","title":"\ud83c\udf10 Phase 4: Ecosystem Integration","text":"<p>Integrate with popular frameworks, cloud services, and database systems.</p>"},{"location":"roadmap/#getting-involved","title":"Getting Involved","text":"<ul> <li>Report Issues: Use GitHub Issues to report bugs or request features</li> <li>Contribute Code: Follow our Contributing Guidelines</li> <li>Discuss Ideas: Join our community discussions</li> <li>Spread the Word: Help others discover YAPFM</li> </ul>"},{"location":"roadmap/#additional-resources","title":"Additional Resources","text":"<ul> <li>User Guide - Basic usage and common patterns</li> <li>Advanced Features - Advanced patterns and optimization</li> <li>API Reference - Complete API documentation</li> <li>Examples - Real-world usage examples</li> <li>Troubleshooting - Problem resolution and FAQ</li> </ul>"},{"location":"roadmap/contributing_to_development/","title":"Contributing to Development","text":""},{"location":"roadmap/contributing_to_development/#how-to-contribute","title":"How to Contribute","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Implement the feature</li> <li>Add tests</li> <li>Update documentation</li> <li>Submit a pull request</li> </ol>"},{"location":"roadmap/contributing_to_development/#development-guidelines","title":"Development Guidelines","text":""},{"location":"roadmap/contributing_to_development/#code-style","title":"Code Style","text":"<ul> <li>Follow PEP 8</li> <li>Use type hints</li> <li>Write comprehensive docstrings</li> <li>Maintain test coverage above 90%</li> </ul>"},{"location":"roadmap/contributing_to_development/#testing-requirements","title":"Testing Requirements","text":"<ul> <li>Unit tests for all new features</li> <li>Integration tests for complex features</li> <li>Performance tests for optimization features</li> <li>Documentation tests for examples</li> </ul>"},{"location":"roadmap/contributing_to_development/#documentation-standards","title":"Documentation Standards","text":"<ul> <li>Update README for user-facing changes</li> <li>Add API documentation for new methods</li> <li>Include usage examples</li> <li>Update changelog</li> </ul>"},{"location":"roadmap/contributing_to_development/#feature-request-process","title":"Feature Request Process","text":"<ol> <li>Create an issue describing the feature</li> <li>Discuss the design with maintainers</li> <li>Create a design document if needed</li> <li>Implement the feature following guidelines</li> <li>Submit for review</li> </ol>"},{"location":"roadmap/contributing_to_development/#priority-guidelines","title":"Priority Guidelines","text":"<p>High Priority: - Bug fixes - Security improvements - Performance optimizations - Core functionality enhancements</p> <p>Medium Priority: - New file format support - Advanced features - Framework integrations - Documentation improvements</p> <p>Low Priority: - Nice-to-have features - Experimental features - UI/UX improvements - Additional examples</p>"},{"location":"roadmap/contributing_to_development/#timeline","title":"Timeline","text":""},{"location":"roadmap/contributing_to_development/#q1-2024","title":"Q1 2024","text":"<ul> <li>XML and INI format support</li> <li>Enhanced caching system</li> <li>Basic conflict resolution</li> </ul>"},{"location":"roadmap/contributing_to_development/#q2-2024","title":"Q2 2024","text":"<ul> <li>Batch operations</li> <li>Cross-format merging</li> <li>Advanced validation</li> </ul>"},{"location":"roadmap/contributing_to_development/#q3-2024","title":"Q3 2024","text":"<ul> <li>Remote configuration support</li> <li>Security features</li> <li>Monitoring and metrics</li> </ul>"},{"location":"roadmap/contributing_to_development/#q4-2024","title":"Q4 2024","text":"<ul> <li>Framework integrations</li> <li>Cloud integrations</li> <li>Database integration</li> </ul>"},{"location":"roadmap/contributing_to_development/#long-term-vision","title":"Long-term Vision","text":""},{"location":"roadmap/contributing_to_development/#ultimate-goals","title":"Ultimate Goals","text":"<ul> <li>Universal Configuration Management: Support for all major configuration formats</li> <li>Cloud-Native: Seamless integration with cloud services</li> <li>Enterprise-Ready: Full enterprise features and compliance</li> <li>Ecosystem Integration: Deep integration with popular frameworks</li> <li>Performance Excellence: Sub-millisecond operations for large configurations</li> <li>Developer Experience: Intuitive API with excellent tooling</li> </ul>"},{"location":"roadmap/contributing_to_development/#research-areas","title":"Research Areas","text":"<ul> <li>AI-Powered Configuration: Machine learning for configuration optimization</li> <li>GraphQL Integration: Query configuration data with GraphQL</li> <li>WebAssembly Support: Run YAPFM in browsers</li> <li>Blockchain Integration: Immutable configuration storage</li> <li>Edge Computing: Distributed configuration management</li> </ul> <p>This roadmap is a living document that evolves based on community feedback and changing requirements. Contributions and suggestions are always welcome!</p>"},{"location":"roadmap/phase1_core_enhancements/","title":"Phase 1: Core Enhancements","text":""},{"location":"roadmap/phase1_core_enhancements/#additional-file-format-support","title":"Additional File Format Support","text":""},{"location":"roadmap/phase1_core_enhancements/#xml-support","title":"XML Support","text":"<pre><code># Planned XML strategy\n@register_file_strategy(\".xml\")\nclass XmlStrategy:\n    def load(self, file_path):\n        # Parse XML to dictionary structure\n        pass\n\n    def save(self, file_path, data):\n        # Convert dictionary to XML\n        pass\n\n    def navigate(self, document, path, create=False):\n        # Navigate XML structure\n        pass\n</code></pre> <p>Features: - Full XML 1.0 and 1.1 support - Namespace handling - Attribute support - Comment preservation - CDATA sections</p>"},{"location":"roadmap/phase1_core_enhancements/#iniconfigparser-support","title":"INI/ConfigParser Support","text":"<pre><code># Planned INI strategy\n@register_file_strategy([\".ini\", \".cfg\", \".conf\"])\nclass IniStrategy:\n    def load(self, file_path):\n        # Parse INI files to nested dictionary\n        pass\n\n    def save(self, file_path, data):\n        # Convert dictionary to INI format\n        pass\n</code></pre> <p>Features: - Section-based configuration - Type conversion (strings, numbers, booleans) - Comment preservation - Multi-line value support</p>"},{"location":"roadmap/phase1_core_enhancements/#csv-support","title":"CSV Support","text":"<pre><code># Planned CSV strategy\n@register_file_strategy(\".csv\")\nclass CsvStrategy:\n    def load(self, file_path):\n        # Load CSV as list of dictionaries\n        pass\n\n    def save(self, file_path, data):\n        # Save list of dictionaries as CSV\n        pass\n</code></pre> <p>Features: - Header row handling - Type inference - Custom delimiters - Encoding support</p>"},{"location":"roadmap/phase1_core_enhancements/#properties-files-support","title":"Properties Files Support","text":"<pre><code># Planned Properties strategy\n@register_file_strategy([\".properties\", \".props\"])\nclass PropertiesStrategy:\n    def load(self, file_path):\n        # Parse Java-style properties files\n        pass\n\n    def save(self, file_path, data):\n        # Convert to properties format\n        pass\n</code></pre>"},{"location":"roadmap/phase1_core_enhancements/#enhanced-caching-system","title":"Enhanced Caching System","text":""},{"location":"roadmap/phase1_core_enhancements/#multi-level-caching","title":"Multi-Level Caching","text":"<pre><code>class AdvancedCacheManager:\n    def __init__(self, memory_cache_size=1000, disk_cache_enabled=True):\n        self.memory_cache = LRUCache(memory_cache_size)\n        self.disk_cache = DiskCache() if disk_cache_enabled else None\n        self.cache_stats = CacheStats()\n\n    def get(self, key):\n        # L1: Memory cache\n        if key in self.memory_cache:\n            self.cache_stats.hit_memory()\n            return self.memory_cache[key]\n\n        # L2: Disk cache\n        if self.disk_cache and key in self.disk_cache:\n            value = self.disk_cache[key]\n            self.memory_cache[key] = value\n            self.cache_stats.hit_disk()\n            return value\n\n        # Cache miss\n        self.cache_stats.miss()\n        return None\n</code></pre> <p>Features: - LRU memory cache - Disk-based persistent cache - Cache invalidation strategies - Cache statistics and monitoring - Configurable cache policies</p>"},{"location":"roadmap/phase1_core_enhancements/#smart-cache-invalidation","title":"Smart Cache Invalidation","text":"<pre><code>class SmartCacheInvalidator:\n    def __init__(self):\n        self.file_watchers = {}\n        self.dependency_graph = {}\n\n    def watch_file(self, file_path, callback):\n        # Watch file for changes and invalidate cache\n        pass\n\n    def add_dependency(self, cache_key, file_path):\n        # Add file dependency for cache invalidation\n        pass\n</code></pre>"},{"location":"roadmap/phase1_core_enhancements/#performance-optimizations","title":"Performance Optimizations","text":""},{"location":"roadmap/phase1_core_enhancements/#lazy-loading-enhancements","title":"Lazy Loading Enhancements","text":"<pre><code>class LazyFileManager:\n    def __init__(self, path, lazy_sections=True, lazy_keys=True):\n        self.path = path\n        self.lazy_sections = lazy_sections\n        self.lazy_keys = lazy_keys\n        self._loaded_sections = set()\n        self._loaded_keys = set()\n\n    def get_section(self, section_name):\n        if section_name not in self._loaded_sections:\n            self._load_section(section_name)\n        return self._sections[section_name]\n\n    def get_key(self, dot_key):\n        if self.lazy_keys and not self._is_key_loaded(dot_key):\n            self._load_key(dot_key)\n        return self._get_key_value(dot_key)\n</code></pre> <p>Features: - Section-level lazy loading - Key-level lazy loading - Background loading - Prefetching strategies - Memory usage optimization</p>"},{"location":"roadmap/phase1_core_enhancements/#streaming-support","title":"Streaming Support","text":"<pre><code>class StreamingFileManager:\n    def __init__(self, path, chunk_size=1024):\n        self.path = path\n        self.chunk_size = chunk_size\n\n    def stream_sections(self):\n        # Stream large files section by section\n        pass\n\n    def stream_keys(self):\n        # Stream keys for memory-efficient processing\n        pass\n\n    def parallel_processing(self, processor_func):\n        # Process large files in parallel\n        pass\n</code></pre>"},{"location":"roadmap/phase1_core_enhancements/#conflict-resolution","title":"Conflict Resolution","text":""},{"location":"roadmap/phase1_core_enhancements/#merge-strategies","title":"Merge Strategies","text":"<pre><code>class ConflictResolver:\n    def __init__(self):\n        self.strategies = {\n            'last_wins': self._last_wins,\n            'first_wins': self._first_wins,\n            'merge': self._merge_values,\n            'custom': None\n        }\n\n    def resolve_conflicts(self, local_data, remote_data, strategy='last_wins'):\n        # Resolve conflicts between local and remote data\n        pass\n\n    def _last_wins(self, local, remote):\n        # Remote data takes precedence\n        return remote\n\n    def _first_wins(self, local, remote):\n        # Local data takes precedence\n        return local\n\n    def _merge_values(self, local, remote):\n        # Intelligent merging of values\n        pass\n</code></pre> <p>Features: - Multiple conflict resolution strategies - Custom conflict handlers - Three-way merge support - Conflict detection and reporting - Automatic resolution where possible</p>"},{"location":"roadmap/phase1_core_enhancements/#version-control-integration","title":"Version Control Integration","text":"<pre><code>class VersionControlIntegration:\n    def __init__(self, vcs_type='git'):\n        self.vcs_type = vcs_type\n        self.vcs_client = self._create_vcs_client()\n\n    def track_changes(self, file_path):\n        # Track file changes in version control\n        pass\n\n    def resolve_merge_conflicts(self, file_path):\n        # Resolve merge conflicts in tracked files\n        pass\n\n    def create_branch(self, branch_name):\n        # Create branch for configuration changes\n        pass\n</code></pre>"},{"location":"roadmap/phase2_advanced_features/","title":"Phase 2: Advanced Features","text":""},{"location":"roadmap/phase2_advanced_features/#batch-operations","title":"Batch Operations","text":""},{"location":"roadmap/phase2_advanced_features/#transaction-support","title":"Transaction Support","text":"<pre><code>class TransactionManager:\n    def __init__(self, file_manager):\n        self.fm = file_manager\n        self.transaction_log = []\n        self.rollback_stack = []\n\n    @contextmanager\n    def transaction(self):\n        # Start transaction\n        self._begin_transaction()\n        try:\n            yield self\n            self._commit_transaction()\n        except Exception:\n            self._rollback_transaction()\n            raise\n\n    def batch_set(self, operations):\n        # Execute multiple operations atomically\n        pass\n\n    def batch_delete(self, keys):\n        # Delete multiple keys atomically\n        pass\n</code></pre> <p>Features: - ACID transaction support - Rollback capabilities - Batch operations - Transaction logging - Deadlock detection</p>"},{"location":"roadmap/phase2_advanced_features/#bulk-operations","title":"Bulk Operations","text":"<pre><code>class BulkOperations:\n    def __init__(self, file_manager):\n        self.fm = file_manager\n\n    def bulk_import(self, data_source, mapping=None):\n        # Import large datasets efficiently\n        pass\n\n    def bulk_export(self, filter_func=None, format='json'):\n        # Export data in various formats\n        pass\n\n    def bulk_update(self, updates_dict):\n        # Update multiple keys efficiently\n        pass\n\n    def bulk_delete(self, key_patterns):\n        # Delete multiple keys matching patterns\n        pass\n</code></pre>"},{"location":"roadmap/phase2_advanced_features/#cross-format-merging","title":"Cross-Format Merging","text":""},{"location":"roadmap/phase2_advanced_features/#format-agnostic-merging","title":"Format-Agnostic Merging","text":"<pre><code>class CrossFormatMerger:\n    def __init__(self):\n        self.converters = {\n            'json': JsonConverter(),\n            'toml': TomlConverter(),\n            'yaml': YamlConverter(),\n            'xml': XmlConverter(),\n            'ini': IniConverter()\n        }\n\n    def merge_files(self, files, output_format='json', strategy='deep_merge'):\n        # Merge files of different formats\n        pass\n\n    def convert_and_merge(self, source_files, target_format):\n        # Convert files to common format and merge\n        pass\n\n    def create_unified_config(self, config_files):\n        # Create unified configuration from multiple sources\n        pass\n</code></pre> <p>Features: - Format conversion - Intelligent merging - Conflict resolution - Schema validation - Output format selection</p>"},{"location":"roadmap/phase2_advanced_features/#configuration-inheritance","title":"Configuration Inheritance","text":"<pre><code>class ConfigInheritance:\n    def __init__(self):\n        self.inheritance_rules = {}\n        self.override_priorities = {}\n\n    def define_inheritance(self, child_file, parent_files):\n        # Define inheritance relationships\n        pass\n\n    def resolve_inheritance(self, file_path):\n        # Resolve inherited configuration\n        pass\n\n    def create_derived_config(self, base_config, overrides):\n        # Create derived configuration\n        pass\n</code></pre>"},{"location":"roadmap/phase2_advanced_features/#advanced-validation","title":"Advanced Validation","text":""},{"location":"roadmap/phase2_advanced_features/#schema-validation","title":"Schema Validation","text":"<pre><code>class SchemaValidator:\n    def __init__(self):\n        self.schemas = {}\n        self.validators = {}\n\n    def define_schema(self, name, schema_definition):\n        # Define JSON schema for validation\n        pass\n\n    def validate_against_schema(self, data, schema_name):\n        # Validate data against defined schema\n        pass\n\n    def auto_generate_schema(self, sample_data):\n        # Generate schema from sample data\n        pass\n</code></pre> <p>Features: - JSON Schema support - Custom validation rules - Schema evolution - Validation reporting - Auto-schema generation</p>"},{"location":"roadmap/phase2_advanced_features/#type-safety","title":"Type Safety","text":"<pre><code>class TypeSafeFileManager:\n    def __init__(self, path, type_definitions=None):\n        self.fm = YAPFileManager(path)\n        self.type_definitions = type_definitions or {}\n        self.type_checker = TypeChecker()\n\n    def set_typed_key(self, value, dot_key, expected_type):\n        # Set key with type validation\n        pass\n\n    def get_typed_key(self, dot_key, expected_type, default=None):\n        # Get key with type checking\n        pass\n\n    def define_type(self, name, type_definition):\n        # Define custom types\n        pass\n</code></pre>"},{"location":"roadmap/phase3_enterprise_features/","title":"Phase 3: Enterprise Features","text":""},{"location":"roadmap/phase3_enterprise_features/#distributed-configuration","title":"Distributed Configuration","text":""},{"location":"roadmap/phase3_enterprise_features/#remote-configuration-support","title":"Remote Configuration Support","text":"<pre><code>class RemoteConfigManager:\n    def __init__(self, remote_url, auth_token=None):\n        self.remote_url = remote_url\n        self.auth_token = auth_token\n        self.local_cache = {}\n        self.sync_manager = SyncManager()\n\n    def fetch_remote_config(self, config_name):\n        # Fetch configuration from remote source\n        pass\n\n    def sync_with_remote(self, local_changes=None):\n        # Synchronize with remote configuration\n        pass\n\n    def push_changes(self, changes):\n        # Push local changes to remote\n        pass\n</code></pre> <p>Features: - REST API integration - Real-time synchronization - Conflict resolution - Offline support - Change tracking</p>"},{"location":"roadmap/phase3_enterprise_features/#configuration-as-code","title":"Configuration as Code","text":"<pre><code>class ConfigAsCode:\n    def __init__(self, repository_url):\n        self.repo_url = repository_url\n        self.git_client = GitClient()\n        self.ci_cd_integration = CICDIntegration()\n\n    def deploy_config(self, environment, config_version):\n        # Deploy configuration to environment\n        pass\n\n    def validate_deployment(self, environment):\n        # Validate configuration in environment\n        pass\n\n    def rollback_config(self, environment, previous_version):\n        # Rollback to previous configuration\n        pass\n</code></pre>"},{"location":"roadmap/phase3_enterprise_features/#security-features","title":"Security Features","text":""},{"location":"roadmap/phase3_enterprise_features/#encryption-at-rest","title":"Encryption at Rest","text":"<pre><code>class EncryptedFileManager:\n    def __init__(self, path, encryption_key, algorithm='AES-256-GCM'):\n        self.fm = YAPFileManager(path)\n        self.encryption_key = encryption_key\n        self.algorithm = algorithm\n        self.crypto_manager = CryptoManager(algorithm)\n\n    def encrypt_data(self, data):\n        # Encrypt data before saving\n        pass\n\n    def decrypt_data(self, encrypted_data):\n        # Decrypt data after loading\n        pass\n\n    def rotate_key(self, new_key):\n        # Rotate encryption key\n        pass\n</code></pre> <p>Features: - Multiple encryption algorithms - Key rotation - Encrypted metadata - Secure key storage - Compliance support</p>"},{"location":"roadmap/phase3_enterprise_features/#access-control","title":"Access Control","text":"<pre><code>class AccessControlManager:\n    def __init__(self):\n        self.permissions = {}\n        self.roles = {}\n        self.audit_log = AuditLog()\n\n    def define_role(self, role_name, permissions):\n        # Define user roles and permissions\n        pass\n\n    def check_permission(self, user, action, resource):\n        # Check if user has permission for action\n        pass\n\n    def audit_action(self, user, action, resource, result):\n        # Log action for audit purposes\n        pass\n</code></pre>"},{"location":"roadmap/phase3_enterprise_features/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"roadmap/phase3_enterprise_features/#advanced-metrics","title":"Advanced Metrics","text":"<pre><code>class MetricsCollector:\n    def __init__(self):\n        self.metrics = {\n            'operations': Counter(),\n            'latency': Histogram(),\n            'errors': Counter(),\n            'cache_hits': Counter(),\n            'cache_misses': Counter()\n        }\n        self.exporters = []\n\n    def record_operation(self, operation, duration, success):\n        # Record operation metrics\n        pass\n\n    def export_metrics(self, format='prometheus'):\n        # Export metrics in various formats\n        pass\n\n    def create_dashboard(self, dashboard_config):\n        # Create monitoring dashboard\n        pass\n</code></pre> <p>Features: - Prometheus metrics - Grafana dashboards - Custom metrics - Alerting - Performance profiling</p>"},{"location":"roadmap/phase3_enterprise_features/#health-checks","title":"Health Checks","text":"<pre><code>class HealthChecker:\n    def __init__(self, file_manager):\n        self.fm = file_manager\n        self.checks = []\n        self.health_status = HealthStatus()\n\n    def add_health_check(self, name, check_function):\n        # Add custom health check\n        pass\n\n    def run_health_checks(self):\n        # Run all health checks\n        pass\n\n    def get_health_status(self):\n        # Get overall health status\n        pass\n</code></pre>"},{"location":"roadmap/phase4_ecosystem_integration/","title":"Phase 4: Ecosystem Integration","text":""},{"location":"roadmap/phase4_ecosystem_integration/#framework-integrations","title":"Framework Integrations","text":""},{"location":"roadmap/phase4_ecosystem_integration/#django-integration","title":"Django Integration","text":"<pre><code># django_yapfm/settings.py\nfrom yapfm import YAPFileManager\n\n# Django settings integration\nYAPFM_CONFIG = {\n    'default_file': 'settings.json',\n    'auto_reload': True,\n    'environment_specific': True\n}\n\n# Usage in Django\nfrom django_yapfm import get_config\n\nDEBUG = get_config('debug', default=False)\nDATABASE_URL = get_config('database.url')\n</code></pre>"},{"location":"roadmap/phase4_ecosystem_integration/#flask-integration","title":"Flask Integration","text":"<pre><code># flask_yapfm/extension.py\nfrom flask import Flask\nfrom yapfm import YAPFileManager\n\nclass YAPFMExtension:\n    def __init__(self, app=None):\n        self.app = app\n        self.file_managers = {}\n        if app:\n            self.init_app(app)\n\n    def init_app(self, app):\n        app.config.setdefault('YAPFM_CONFIG_FILE', 'config.json')\n        app.yapfm = self\n\n    def get_config(self, key, default=None):\n        # Get configuration value\n        pass\n</code></pre>"},{"location":"roadmap/phase4_ecosystem_integration/#fastapi-integration","title":"FastAPI Integration","text":"<pre><code># fastapi_yapfm/dependency.py\nfrom fastapi import Depends\nfrom yapfm import YAPFileManager\n\ndef get_config_manager():\n    return YAPFileManager(\"config.json\")\n\ndef get_config_value(key: str, default=None):\n    def _get_value(fm: YAPFileManager = Depends(get_config_manager)):\n        return fm.get_key(dot_key=key, default=default)\n    return _get_value\n</code></pre>"},{"location":"roadmap/phase4_ecosystem_integration/#cloud-integration","title":"Cloud Integration","text":""},{"location":"roadmap/phase4_ecosystem_integration/#aws-integration","title":"AWS Integration","text":"<pre><code>class AWSConfigManager:\n    def __init__(self, region='us-east-1'):\n        self.region = region\n        self.ssm_client = boto3.client('ssm', region_name=region)\n        self.secrets_client = boto3.client('secretsmanager', region_name=region)\n\n    def load_from_ssm(self, parameter_name):\n        # Load configuration from AWS Systems Manager\n        pass\n\n    def load_from_secrets_manager(self, secret_name):\n        # Load secrets from AWS Secrets Manager\n        pass\n\n    def sync_with_aws(self, config_data):\n        # Sync configuration with AWS services\n        pass\n</code></pre>"},{"location":"roadmap/phase4_ecosystem_integration/#azure-integration","title":"Azure Integration","text":"<pre><code>class AzureConfigManager:\n    def __init__(self, connection_string):\n        self.connection_string = connection_string\n        self.key_vault_client = KeyVaultClient()\n        self.app_config_client = AppConfigurationClient()\n\n    def load_from_key_vault(self, secret_name):\n        # Load secrets from Azure Key Vault\n        pass\n\n    def load_from_app_config(self, config_name):\n        # Load configuration from Azure App Configuration\n        pass\n</code></pre>"},{"location":"roadmap/phase4_ecosystem_integration/#database-integration","title":"Database Integration","text":""},{"location":"roadmap/phase4_ecosystem_integration/#database-backed-configuration","title":"Database-Backed Configuration","text":"<pre><code>class DatabaseConfigManager:\n    def __init__(self, database_url, table_name='config'):\n        self.db_url = database_url\n        self.table_name = table_name\n        self.engine = create_engine(database_url)\n        self.session = sessionmaker(bind=self.engine)()\n\n    def load_from_database(self, environment=None):\n        # Load configuration from database\n        pass\n\n    def save_to_database(self, config_data, environment=None):\n        # Save configuration to database\n        pass\n\n    def get_config_history(self, config_key):\n        # Get configuration change history\n        pass\n</code></pre>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>This guide helps you diagnose and resolve common issues with YAPFM, including error messages, performance problems, and configuration issues.</p>"},{"location":"troubleshooting/#table-of-contents","title":"\ud83d\udcda Table of Contents","text":"<ol> <li>Common Issues - File not found, permission errors, strategy errors, and data type issues</li> <li>Error Reference - Detailed information about YAPFM exceptions</li> <li>Performance Issues - Slow operations, memory usage, and thread safety</li> <li>Configuration Problems - Invalid structure and environment-specific issues</li> <li>File Format Issues - JSON, TOML, and YAML format problems</li> <li>Memory and Resource Issues - Memory leaks and resource exhaustion</li> <li>Debugging Tips - Debug logging, inspection, and tracing</li> <li>Frequently Asked Questions - Common questions and advanced scenarios</li> </ol>"},{"location":"troubleshooting/#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Having basic issues? Check Common Issues</li> <li>Need error details? See Error Reference</li> <li>Performance problems? Read Performance Issues</li> <li>Configuration not working? Go to Configuration Problems</li> <li>File format errors? Browse File Format Issues</li> <li>Memory issues? See Memory and Resource Issues</li> <li>Need to debug? Check Debugging Tips</li> <li>Have questions? Explore Frequently Asked Questions</li> </ul>"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":"<p>If you can't find a solution in this guide:</p> <ol> <li>Check the GitHub Issues for similar problems</li> <li>Create a new issue with:</li> <li>YAPFM version</li> <li>Python version</li> <li>Operating system</li> <li>Complete error message</li> <li>Minimal code example that reproduces the issue</li> <li>Include relevant log output and configuration details</li> </ol>"},{"location":"troubleshooting/#additional-resources","title":"Additional Resources","text":"<ul> <li>User Guide - Basic usage and common patterns</li> <li>Advanced Features - Advanced patterns and optimization</li> <li>API Reference - Complete API documentation</li> <li>Examples - Real-world usage examples</li> </ul>"},{"location":"troubleshooting/common_issues/","title":"Common Issues","text":""},{"location":"troubleshooting/common_issues/#file-not-found-errors","title":"File Not Found Errors","text":"<p>Problem: <code>FileNotFoundError</code> when trying to load a file.</p> <p>Solutions: <pre><code># 1. Use auto_create=True\nfm = YAPFileManager(\"config.json\", auto_create=True)\n\n# 2. Check if file exists first\nif fm.exists():\n    fm.load()\nelse:\n    print(\"File does not exist\")\n\n# 3. Create the file manually\nfm.create_empty_file()\n</code></pre></p>"},{"location":"troubleshooting/common_issues/#permission-denied-errors","title":"Permission Denied Errors","text":"<p>Problem: <code>PermissionError</code> when trying to save a file.</p> <p>Solutions: <pre><code># 1. Check file permissions\nimport os\nprint(f\"File permissions: {oct(os.stat('config.json').st_mode)[-3:]}\")\n\n# 2. Check directory permissions\nprint(f\"Directory permissions: {oct(os.stat('.').st_mode)[-3:]}\")\n\n# 3. Run with appropriate permissions\n# On Unix/Linux: chmod 644 config.json\n# On Windows: Check file properties\n</code></pre></p>"},{"location":"troubleshooting/common_issues/#strategy-not-found-errors","title":"Strategy Not Found Errors","text":"<p>Problem: <code>StrategyError</code> when trying to use an unsupported file format.</p> <p>Solutions: <pre><code># 1. Check supported formats\nfrom yapfm.registry import FileStrategyRegistry\nprint(f\"Supported formats: {FileStrategyRegistry.get_supported_formats()}\")\n\n# 2. Register a custom strategy\nfrom yapfm.strategies import BaseFileStrategy\nfrom yapfm.registry import register_file_strategy\n\n@register_file_strategy(\".xml\")\nclass XmlStrategy:\n    def load(self, file_path):\n        # Implementation\n        pass\n\n    def save(self, file_path, data):\n        # Implementation\n        pass\n\n    def navigate(self, document, path, create=False):\n        # Implementation\n        pass\n\n# 3. Use a supported format\nfm = YAPFileManager(\"config.json\")  # Use .json instead of .xml\n</code></pre></p>"},{"location":"troubleshooting/common_issues/#data-type-errors","title":"Data Type Errors","text":"<p>Problem: <code>TypeError</code> when setting data that's not a dictionary.</p> <p>Solutions: <pre><code># 1. Ensure data is a dictionary\ndata = {\"key\": \"value\"}  # Correct\nfm.data = data\n\n# 2. Convert other types to dictionary\nimport json\njson_string = '{\"key\": \"value\"}'\ndata = json.loads(json_string)\nfm.data = data\n\n# 3. Use proper data structure\n# For lists, wrap in a dictionary\nfm.data = {\"items\": [1, 2, 3]}  # Correct\n# fm.data = [1, 2, 3]  # Incorrect\n</code></pre></p>"},{"location":"troubleshooting/configuration_problems/","title":"Configuration Problems","text":""},{"location":"troubleshooting/configuration_problems/#invalid-configuration-structure","title":"Invalid Configuration Structure","text":"<p>Problem: Configuration file has invalid structure.</p> <p>Solutions: <pre><code># 1. Validate configuration\ndef validate_config(data):\n    if not isinstance(data, dict):\n        raise ValueError(\"Configuration must be a dictionary\")\n\n    required_keys = [\"app\", \"database\"]\n    for key in required_keys:\n        if key not in data:\n            raise ValueError(f\"Missing required key: {key}\")\n\n    return True\n\n# 2. Use configuration validator\nclass ConfigValidator:\n    def __init__(self, fm):\n        self.fm = fm\n\n    def validate(self):\n        with self.fm:\n            return validate_config(self.fm.data)\n\n# 3. Fix common issues\ndef fix_config_issues(fm):\n    with fm:\n        data = fm.data\n\n        # Ensure top-level is dictionary\n        if not isinstance(data, dict):\n            fm.data = {\"config\": data}\n\n        # Add missing required keys\n        if \"app\" not in data:\n            data[\"app\"] = {\"name\": \"My App\", \"version\": \"1.0.0\"}\n\n        if \"database\" not in data:\n            data[\"database\"] = {\"host\": \"localhost\", \"port\": 5432}\n</code></pre></p>"},{"location":"troubleshooting/configuration_problems/#environment-specific-issues","title":"Environment-Specific Issues","text":"<p>Problem: Configuration not working in different environments.</p> <p>Solutions: <pre><code>import os\n\n# 1. Use environment variables\ndef load_env_config():\n    env = os.getenv(\"ENVIRONMENT\", \"development\")\n    config_file = f\"config_{env}.json\"\n\n    fm = YAPFileManager(config_file, auto_create=True)\n    with fm:\n        # Set environment-specific defaults\n        if env == \"development\":\n            fm.set_key(True, dot_key=\"debug\")\n        elif env == \"production\":\n            fm.set_key(False, dot_key=\"debug\")\n\n    return fm\n\n# 2. Use configuration inheritance\ndef load_merged_config():\n    base_fm = YAPFileManager(\"base_config.json\")\n    env_fm = YAPFileManager(f\"config_{os.getenv('ENVIRONMENT', 'development')}.json\")\n\n    with base_fm:\n        base_data = base_fm.data\n\n    with env_fm:\n        env_data = env_fm.data\n\n    # Merge configurations\n    merged_data = {**base_data, **env_data}\n\n    return merged_data\n</code></pre></p>"},{"location":"troubleshooting/debugging_tips/","title":"Debugging Tips","text":""},{"location":"troubleshooting/debugging_tips/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code>import logging\n\n# Set up debug logging\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger(\"yapfm\")\n\n# Use proxy with logging\nfrom yapfm import FileManagerProxy\n\nfm = YAPFileManager(\"config.json\")\nproxy = FileManagerProxy(fm, enable_logging=True, logger=logger)\n\n# All operations will be logged\nwith proxy:\n    proxy.set_key(\"value\", dot_key=\"key\")\n</code></pre>"},{"location":"troubleshooting/debugging_tips/#use-debug-mode","title":"Use Debug Mode","text":"<pre><code># Enable debug mode for more verbose output\nimport os\nos.environ[\"YAPFM_DEBUG\"] = \"1\"\n\n# Or set debug flag\nfm = YAPFileManager(\"config.json\", debug=True)\n</code></pre>"},{"location":"troubleshooting/debugging_tips/#inspect-file-state","title":"Inspect File State","text":"<pre><code>def debug_file_state(fm):\n    print(f\"File exists: {fm.exists()}\")\n    print(f\"File loaded: {fm.is_loaded()}\")\n    print(f\"File dirty: {fm.is_dirty()}\")\n    print(f\"File path: {fm.path}\")\n    print(f\"File size: {fm.path.stat().st_size if fm.exists() else 'N/A'}\")\n\n    if fm.is_loaded():\n        print(f\"Data keys: {list(fm.data.keys())}\")\n        print(f\"Data type: {type(fm.data)}\")\n</code></pre>"},{"location":"troubleshooting/debugging_tips/#trace-operations","title":"Trace Operations","text":"<pre><code>def trace_operations(fm):\n    original_set_key = fm.set_key\n    original_get_key = fm.get_key\n\n    def traced_set_key(value, dot_key=None, **kwargs):\n        print(f\"SET: {dot_key} = {value}\")\n        return original_set_key(value, dot_key=dot_key, **kwargs)\n\n    def traced_get_key(dot_key=None, **kwargs):\n        result = original_get_key(dot_key=dot_key, **kwargs)\n        print(f\"GET: {dot_key} = {result}\")\n        return result\n\n    fm.set_key = traced_set_key\n    fm.get_key = traced_get_key\n</code></pre>"},{"location":"troubleshooting/error_reference/","title":"Error Reference","text":""},{"location":"troubleshooting/error_reference/#loadfileerror","title":"LoadFileError","text":"<p>When it occurs: Error loading a file from disk.</p> <p>Common causes: - File doesn't exist - Invalid file format - Corrupted file - Permission issues</p> <p>Solutions: <pre><code>from yapfm.exceptions import LoadFileError\n\ntry:\n    fm.load()\nexcept LoadFileError as e:\n    print(f\"Failed to load file: {e}\")\n    # Handle the error appropriately\n</code></pre></p>"},{"location":"troubleshooting/error_reference/#filewriteerror","title":"FileWriteError","text":"<p>When it occurs: Error writing a file to disk.</p> <p>Common causes: - Permission denied - Disk full - Invalid data format - File locked by another process</p> <p>Solutions: <pre><code>from yapfm.exceptions import FileWriteError\n\ntry:\n    fm.save()\nexcept FileWriteError as e:\n    print(f\"Failed to save file: {e}\")\n    # Handle the error appropriately\n</code></pre></p>"},{"location":"troubleshooting/error_reference/#strategyerror","title":"StrategyError","text":"<p>When it occurs: Error with file strategy.</p> <p>Common causes: - Unsupported file format - Strategy not registered - Invalid strategy implementation</p> <p>Solutions: <pre><code>from yapfm.exceptions import StrategyError\n\ntry:\n    fm = YAPFileManager(\"file.xyz\")\nexcept StrategyError as e:\n    print(f\"Strategy error: {e}\")\n    # Use a supported format or register a custom strategy\n</code></pre></p>"},{"location":"troubleshooting/file_format_issues/","title":"File Format Issues","text":""},{"location":"troubleshooting/file_format_issues/#json-format-issues","title":"JSON Format Issues","text":"<p>Problem: Invalid JSON format.</p> <p>Solutions: <pre><code># 1. Validate JSON before loading\nimport json\n\ndef validate_json_file(file_path):\n    try:\n        with open(file_path, 'r') as f:\n            json.load(f)\n        return True\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON: {e}\")\n        return False\n\n# 2. Fix common JSON issues\ndef fix_json_file(file_path):\n    with open(file_path, 'r') as f:\n        content = f.read()\n\n    # Fix common issues\n    content = content.replace(\"'\", '\"')  # Replace single quotes\n    content = content.replace(\"True\", \"true\")  # Fix boolean values\n    content = content.replace(\"False\", \"false\")\n    content = content.replace(\"None\", \"null\")\n\n    with open(file_path, 'w') as f:\n        f.write(content)\n\n# 3. Use proper JSON formatting\ndef format_json_file(file_path):\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n\n    with open(file_path, 'w') as f:\n        json.dump(data, f, indent=2, ensure_ascii=False)\n</code></pre></p>"},{"location":"troubleshooting/file_format_issues/#toml-format-issues","title":"TOML Format Issues","text":"<p>Problem: Invalid TOML format.</p> <p>Solutions: <pre><code># 1. Validate TOML\nimport toml\n\ndef validate_toml_file(file_path):\n    try:\n        with open(file_path, 'r') as f:\n            toml.load(f)\n        return True\n    except toml.TomlDecodeError as e:\n        print(f\"Invalid TOML: {e}\")\n        return False\n\n# 2. Fix common TOML issues\ndef fix_toml_file(file_path):\n    with open(file_path, 'r') as f:\n        content = f.read()\n\n    # Fix common issues\n    content = content.replace(\"True\", \"true\")\n    content = content.replace(\"False\", \"false\")\n    content = content.replace(\"None\", \"null\")\n\n    with open(file_path, 'w') as f:\n        f.write(content)\n</code></pre></p>"},{"location":"troubleshooting/file_format_issues/#yaml-format-issues","title":"YAML Format Issues","text":"<p>Problem: Invalid YAML format.</p> <p>Solutions: <pre><code># 1. Validate YAML\nimport yaml\n\ndef validate_yaml_file(file_path):\n    try:\n        with open(file_path, 'r') as f:\n            yaml.safe_load(f)\n        return True\n    except yaml.YAMLError as e:\n        print(f\"Invalid YAML: {e}\")\n        return False\n\n# 2. Fix common YAML issues\ndef fix_yaml_file(file_path):\n    with open(file_path, 'r') as f:\n        content = f.read()\n\n    # Fix common issues\n    content = content.replace(\"True\", \"true\")\n    content = content.replace(\"False\", \"false\")\n    content = content.replace(\"None\", \"null\")\n\n    with open(file_path, 'w') as f:\n        f.write(content)\n</code></pre></p>"},{"location":"troubleshooting/frequently_asked_questions/","title":"Frequently Asked Questions","text":""},{"location":"troubleshooting/frequently_asked_questions/#q-how-do-i-handle-large-configuration-files","title":"Q: How do I handle large configuration files?","text":"<p>A: Use streaming and chunked processing:</p> <pre><code># For very large files, process in chunks\ndef process_large_config(fm):\n    with fm:\n        data = fm.data\n\n        # Process in chunks\n        chunk_size = 1000\n        items = list(data.items())\n\n        for i in range(0, len(items), chunk_size):\n            chunk = dict(items[i:i + chunk_size])\n            process_chunk(chunk)\n</code></pre>"},{"location":"troubleshooting/frequently_asked_questions/#q-can-i-use-yapfm-with-multiple-file-formats-in-the-same-application","title":"Q: Can I use YAPFM with multiple file formats in the same application?","text":"<p>A: Yes, you can use different file managers for different formats:</p> <pre><code># Different file managers for different formats\njson_fm = YAPFileManager(\"config.json\")\ntoml_fm = YAPFileManager(\"config.toml\")\nyaml_fm = YAPFileManager(\"config.yaml\")\n\n# Or use a single manager with different files\nconfigs = {\n    \"json\": YAPFileManager(\"config.json\"),\n    \"toml\": YAPFileManager(\"config.toml\"),\n    \"yaml\": YAPFileManager(\"config.yaml\")\n}\n</code></pre>"},{"location":"troubleshooting/frequently_asked_questions/#q-how-do-i-handle-configuration-validation","title":"Q: How do I handle configuration validation?","text":"<p>A: Use a validation mixin or custom validation:</p> <pre><code>class ConfigValidator:\n    def __init__(self, fm):\n        self.fm = fm\n        self.rules = {}\n\n    def add_rule(self, key, rule, message):\n        self.rules[key] = {\"rule\": rule, \"message\": message}\n\n    def validate(self):\n        errors = []\n        with self.fm:\n            data = self.fm.data\n\n            for key, rule_info in self.rules.items():\n                if not rule_info[\"rule\"](data.get(key)):\n                    errors.append(rule_info[\"message\"])\n\n        return errors\n</code></pre>"},{"location":"troubleshooting/frequently_asked_questions/#q-can-i-use-yapfm-in-a-multi-threaded-environment","title":"Q: Can I use YAPFM in a multi-threaded environment?","text":"<p>A: Yes, but you need to handle thread safety:</p> <pre><code>import threading\n\n# Use locks for thread safety\nlock = threading.Lock()\n\ndef thread_safe_operation(fm):\n    with lock:\n        fm.set_key(\"value\", dot_key=\"key\")\n\n# Or use a thread-safe wrapper\nclass ThreadSafeFileManager:\n    def __init__(self, path):\n        self.fm = YAPFileManager(path)\n        self.lock = threading.RLock()\n\n    def __getattr__(self, name):\n        attr = getattr(self.fm, name)\n        if callable(attr):\n            def wrapper(*args, **kwargs):\n                with self.lock:\n                    return attr(*args, **kwargs)\n            return wrapper\n        return attr\n</code></pre>"},{"location":"troubleshooting/frequently_asked_questions/#q-how-do-i-handle-configuration-updates-in-production","title":"Q: How do I handle configuration updates in production?","text":"<p>A: Use safe update patterns:</p> <pre><code>def safe_config_update(fm, updates):\n    # Create backup\n    backup_file = f\"{fm.path}.backup\"\n    if fm.exists():\n        import shutil\n        shutil.copy2(fm.path, backup_file)\n\n    try:\n        # Apply updates\n        with fm:\n            for key, value in updates.items():\n                fm.set_key(value, dot_key=key)\n\n        # Validate configuration\n        if validate_config(fm.data):\n            fm.save()\n        else:\n            raise ValueError(\"Configuration validation failed\")\n\n    except Exception as e:\n        # Restore from backup\n        if os.path.exists(backup_file):\n            import shutil\n            shutil.copy2(backup_file, fm.path)\n        raise e\n</code></pre>"},{"location":"troubleshooting/frequently_asked_questions/#q-how-do-i-monitor-configuration-changes","title":"Q: How do I monitor configuration changes?","text":"<p>A: Use the proxy pattern with audit hooks:</p> <pre><code>def audit_hook(method, args, kwargs, result):\n    print(f\"Configuration changed: {method} with {args}\")\n\n    # Log to file\n    with open(\"config_changes.log\", \"a\") as f:\n        f.write(f\"{datetime.now()}: {method} - {args}\\n\")\n\nproxy = FileManagerProxy(\n    fm,\n    enable_audit=True,\n    audit_hook=audit_hook\n)\n</code></pre>"},{"location":"troubleshooting/frequently_asked_questions/#q-how-do-i-handle-configuration-encryption","title":"Q: How do I handle configuration encryption?","text":"<p>A: Use a custom mixin or wrapper:</p> <pre><code>from cryptography.fernet import Fernet\n\nclass EncryptedFileManager:\n    def __init__(self, path, key):\n        self.fm = YAPFileManager(path)\n        self.cipher = Fernet(key)\n\n    def set_encrypted_key(self, value, dot_key):\n        encrypted = self.cipher.encrypt(value.encode())\n        self.fm.set_key(encrypted.decode(), dot_key=dot_key)\n\n    def get_encrypted_key(self, dot_key, default=None):\n        encrypted = self.fm.get_key(dot_key=dot_key, default=default)\n        if encrypted:\n            return self.cipher.decrypt(encrypted.encode()).decode()\n        return default\n</code></pre> <p>If you're still experiencing issues, please check the GitHub Issues or create a new issue with detailed information about your problem.</p>"},{"location":"troubleshooting/memory_resource_issues/","title":"Memory and Resource Issues","text":""},{"location":"troubleshooting/memory_resource_issues/#memory-leaks","title":"Memory Leaks","text":"<p>Problem: Memory usage keeps increasing.</p> <p>Solutions: <pre><code># 1. Use context managers\nwith YAPFileManager(\"config.json\") as fm:\n    # Use file manager\n    pass\n# Automatically cleaned up\n\n# 2. Explicitly unload\nfm.unload()  # Free memory\n\n# 3. Use weak references\nimport weakref\n\nclass MemoryEfficientManager:\n    def __init__(self, path):\n        self.fm = YAPFileManager(path)\n        self._cache = weakref.WeakValueDictionary()\n\n    def get_data(self):\n        if 'data' not in self._cache:\n            with self.fm:\n                self._cache['data'] = self.fm.data.copy()\n        return self._cache['data']\n</code></pre></p>"},{"location":"troubleshooting/memory_resource_issues/#resource-exhaustion","title":"Resource Exhaustion","text":"<p>Problem: Too many file handles or other resources.</p> <p>Solutions: <pre><code># 1. Use context managers\nwith YAPFileManager(\"config.json\") as fm:\n    # File is automatically closed\n    pass\n\n# 2. Limit concurrent operations\nimport threading\n\nclass ResourceLimitedManager:\n    def __init__(self, path, max_concurrent=5):\n        self.fm = YAPFileManager(path)\n        self.semaphore = threading.Semaphore(max_concurrent)\n\n    def operation(self):\n        with self.semaphore:\n            with self.fm:\n                # Perform operation\n                pass\n</code></pre></p>"},{"location":"troubleshooting/performance_issues/","title":"Performance Issues","text":""},{"location":"troubleshooting/performance_issues/#slow-file-operations","title":"Slow File Operations","text":"<p>Problem: File operations are taking too long.</p> <p>Solutions: <pre><code># 1. Use lazy loading\nfm = YAPFileManager(\"config.json\")\n# File is only loaded when first accessed\ndata = fm.data  # Loads here\n\n# 2. Use batch operations\nwith fm.lazy_save():\n    fm.set_key(\"value1\", dot_key=\"key1\")\n    fm.set_key(\"value2\", dot_key=\"key2\")\n    fm.set_key(\"value3\", dot_key=\"key3\")\n    # Single save at the end\n\n# 3. Use caching\nfrom yapfm import FileManagerProxy\nimport time\n\nclass CachedFileManager:\n    def __init__(self, path, cache_ttl=300):\n        self.fm = YAPFileManager(path)\n        self.cache = {}\n        self.cache_ttl = cache_ttl\n        self.last_load = 0\n\n    def get_data(self):\n        if time.time() - self.last_load &gt; self.cache_ttl:\n            with self.fm:\n                self.cache = self.fm.data.copy()\n                self.last_load = time.time()\n        return self.cache\n</code></pre></p>"},{"location":"troubleshooting/performance_issues/#memory-usage-issues","title":"Memory Usage Issues","text":"<p>Problem: High memory usage with large files.</p> <p>Solutions: <pre><code># 1. Use streaming for large files\ndef process_large_file(fm):\n    with fm:\n        data = fm.data\n        # Process data in chunks\n        for key, value in data.items():\n            # Process each item\n            process_item(key, value)\n\n# 2. Unload when not needed\nfm.unload()  # Free memory\n\n# 3. Use context managers\nwith YAPFileManager(\"config.json\") as fm:\n    # Use file manager\n    pass\n# Automatically unloaded when exiting context\n</code></pre></p>"},{"location":"troubleshooting/performance_issues/#thread-safety-issues","title":"Thread Safety Issues","text":"<p>Problem: Race conditions in multi-threaded environments.</p> <p>Solutions: <pre><code>import threading\n\n# 1. Use locks\nlock = threading.Lock()\n\ndef thread_safe_operation():\n    with lock:\n        fm.set_key(\"value\", dot_key=\"key\")\n\n# 2. Use thread-safe file manager\nclass ThreadSafeFileManager:\n    def __init__(self, path):\n        self.fm = YAPFileManager(path)\n        self.lock = threading.RLock()\n\n    def set_key(self, value, dot_key):\n        with self.lock:\n            self.fm.set_key(value, dot_key=dot_key)\n\n    def get_key(self, dot_key, default=None):\n        with self.lock:\n            return self.fm.get_key(dot_key=dot_key, default=default)\n</code></pre></p>"},{"location":"usage_examples/","title":"Examples and Usage Patterns","text":"<p>This guide provides comprehensive examples and real-world usage patterns for YAPFM, covering everything from basic operations to advanced scenarios.</p>"},{"location":"usage_examples/#table-of-contents","title":"\ud83d\udcda Table of Contents","text":"<ol> <li>Caching &amp; Streaming Examples - Examples of intelligent caching, lazy loading, and streaming</li> <li>Basic Examples - Simple configuration files and format handling</li> <li>Configuration Management - Application configuration managers and dynamic updates</li> <li>Multi-Environment Setup - Environment-specific configurations and inheritance</li> <li>Advanced Patterns - Validation, caching, and hot reloading</li> <li>Logging and Monitoring - Configuration monitoring with proxy and metrics</li> <li>Error Handling Patterns - Robust configuration loading and fallback strategies</li> <li>Performance Optimization - Batch operations and performance improvements</li> <li>Integration Examples - Flask, Django, and other framework integrations</li> </ol>"},{"location":"usage_examples/#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Need caching and streaming examples? Check Caching &amp; Streaming Examples</li> <li>Getting started? Check Basic Examples</li> <li>Need configuration management? See Configuration Management</li> <li>Working with multiple environments? Read Multi-Environment Setup</li> <li>Want advanced features? Go to Advanced Patterns</li> <li>Need monitoring? Browse Logging and Monitoring</li> <li>Handling errors? See Error Handling Patterns</li> <li>Performance is critical? Check Performance Optimization</li> <li>Integrating with frameworks? Explore Integration Examples</li> </ul>"},{"location":"usage_examples/#additional-resources","title":"Additional Resources","text":"<ul> <li>User Guide - Basic usage and common patterns</li> <li>Advanced Features - Advanced patterns and optimization</li> <li>API Reference - Complete API documentation</li> <li>Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"usage_examples/advanced_patterns/","title":"Advanced Patterns","text":""},{"location":"usage_examples/advanced_patterns/#configuration-validation-and-schema","title":"Configuration Validation and Schema","text":"<pre><code>from yapfm import YAPFileManager\nfrom typing import Dict, Any, List, Optional, Union\nimport re\n\nclass ConfigValidator:\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.fm = YAPFileManager(config_file, auto_create=True)\n        self.errors: List[str] = []\n        self.warnings: List[str] = []\n\n    def validate(self) -&gt; bool:\n        \"\"\"Validate configuration against schema.\"\"\"\n        self.errors.clear()\n        self.warnings.clear()\n\n        with self.fm:\n            # Validate required keys\n            self._validate_required_keys()\n\n            # Validate data types\n            self._validate_data_types()\n\n            # Validate value ranges\n            self._validate_value_ranges()\n\n            # Validate string formats\n            self._validate_string_formats()\n\n        return len(self.errors) == 0\n\n    def _validate_required_keys(self) -&gt; None:\n        \"\"\"Validate that all required keys are present.\"\"\"\n        required_keys = [\n            \"app.name\",\n            \"app.version\",\n            \"database.host\",\n            \"database.port\",\n            \"api.timeout\"\n        ]\n\n        for key in required_keys:\n            if not self.fm.has_key(dot_key=key):\n                self.errors.append(f\"Missing required key: {key}\")\n\n    def _validate_data_types(self) -&gt; None:\n        \"\"\"Validate data types of configuration values.\"\"\"\n        type_validations = {\n            \"app.name\": str,\n            \"app.version\": str,\n            \"database.port\": int,\n            \"api.timeout\": int,\n            \"api.retries\": int,\n            \"debug\": bool\n        }\n\n        for key, expected_type in type_validations.items():\n            if self.fm.has_key(dot_key=key):\n                value = self.fm.get_key(dot_key=key)\n                if not isinstance(value, expected_type):\n                    self.errors.append(f\"Key '{key}' should be {expected_type.__name__}, got {type(value).__name__}\")\n\n    def _validate_value_ranges(self) -&gt; None:\n        \"\"\"Validate value ranges for numeric configuration.\"\"\"\n        range_validations = {\n            \"database.port\": (1, 65535),\n            \"api.timeout\": (1, 300),\n            \"api.retries\": (0, 10)\n        }\n\n        for key, (min_val, max_val) in range_validations.items():\n            if self.fm.has_key(dot_key=key):\n                value = self.fm.get_key(dot_key=key)\n                if isinstance(value, (int, float)):\n                    if not (min_val &lt;= value &lt;= max_val):\n                        self.errors.append(f\"Key '{key}' value {value} is out of range [{min_val}, {max_val}]\")\n\n    def _validate_string_formats(self) -&gt; None:\n        \"\"\"Validate string formats for configuration values.\"\"\"\n        format_validations = {\n            \"app.version\": r\"^\\d+\\.\\d+\\.\\d+$\",  # Semantic versioning\n            \"database.host\": r\"^[a-zA-Z0-9.-]+$\",  # Hostname format\n            \"api.version\": r\"^v\\d+$\"  # API version format\n        }\n\n        for key, pattern in format_validations.items():\n            if self.fm.has_key(dot_key=key):\n                value = self.fm.get_key(dot_key=key)\n                if isinstance(value, str):\n                    if not re.match(pattern, value):\n                        self.errors.append(f\"Key '{key}' value '{value}' does not match expected format\")\n\n    def get_errors(self) -&gt; List[str]:\n        \"\"\"Get validation errors.\"\"\"\n        return self.errors\n\n    def get_warnings(self) -&gt; List[str]:\n        \"\"\"Get validation warnings.\"\"\"\n        return self.warnings\n\n    def fix_common_issues(self) -&gt; bool:\n        \"\"\"Attempt to fix common configuration issues.\"\"\"\n        fixed = False\n\n        with self.fm:\n            # Fix missing required keys with defaults\n            defaults = {\n                \"app.name\": \"My Application\",\n                \"app.version\": \"1.0.0\",\n                \"database.host\": \"localhost\",\n                \"database.port\": 5432,\n                \"api.timeout\": 30\n            }\n\n            for key, default_value in defaults.items():\n                if not self.fm.has_key(dot_key=key):\n                    self.fm.set_key(default_value, dot_key=key)\n                    fixed = True\n\n        return fixed\n\n# Usage example\ndef main():\n    validator = ConfigValidator(\"app_config.json\")\n\n    # Try to fix common issues\n    if validator.fix_common_issues():\n        print(\"Fixed some common configuration issues\")\n\n    # Validate configuration\n    if validator.validate():\n        print(\"Configuration is valid!\")\n    else:\n        print(\"Configuration validation failed:\")\n        for error in validator.get_errors():\n            print(f\"  - {error}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"usage_examples/advanced_patterns/#configuration-caching-and-hot-reloading","title":"Configuration Caching and Hot Reloading","text":"<pre><code>from yapfm import YAPFileManager\nimport time\nimport threading\nfrom typing import Dict, Any, Callable, Optional\n\nclass ConfigCache:\n    def __init__(self, config_file: str, reload_interval: int = 30):\n        self.config_file = config_file\n        self.reload_interval = reload_interval\n        self.fm = YAPFileManager(config_file, auto_create=True)\n        self.cache: Dict[str, Any] = {}\n        self.last_reload = 0\n        self.callbacks: List[Callable[[Dict[str, Any]], None]] = []\n        self._stop_reload = False\n        self._reload_thread: Optional[threading.Thread] = None\n\n    def start_auto_reload(self) -&gt; None:\n        \"\"\"Start automatic configuration reloading.\"\"\"\n        if self._reload_thread is None or not self._reload_thread.is_alive():\n            self._stop_reload = False\n            self._reload_thread = threading.Thread(target=self._auto_reload_loop)\n            self._reload_thread.daemon = True\n            self._reload_thread.start()\n\n    def stop_auto_reload(self) -&gt; None:\n        \"\"\"Stop automatic configuration reloading.\"\"\"\n        self._stop_reload = True\n        if self._reload_thread and self._reload_thread.is_alive():\n            self._reload_thread.join()\n\n    def _auto_reload_loop(self) -&gt; None:\n        \"\"\"Background thread for automatic reloading.\"\"\"\n        while not self._stop_reload:\n            time.sleep(self.reload_interval)\n            if self._should_reload():\n                self.reload()\n\n    def _should_reload(self) -&gt; bool:\n        \"\"\"Check if configuration should be reloaded.\"\"\"\n        if not self.fm.exists():\n            return False\n\n        try:\n            stat = self.fm.path.stat()\n            return stat.st_mtime &gt; self.last_reload\n        except OSError:\n            return False\n\n    def load(self) -&gt; Dict[str, Any]:\n        \"\"\"Load configuration into cache.\"\"\"\n        with self.fm:\n            self.cache = self.fm.data.copy()\n            self.last_reload = time.time()\n            return self.cache\n\n    def reload(self) -&gt; Dict[str, Any]:\n        \"\"\"Reload configuration from file.\"\"\"\n        old_cache = self.cache.copy()\n        new_cache = self.load()\n\n        # Notify callbacks if configuration changed\n        if old_cache != new_cache:\n            for callback in self.callbacks:\n                try:\n                    callback(new_cache)\n                except Exception as e:\n                    print(f\"Error in configuration callback: {e}\")\n\n        return new_cache\n\n    def get(self, key: str, default: Any = None) -&gt; Any:\n        \"\"\"Get a configuration value from cache.\"\"\"\n        if not self.cache:\n            self.load()\n\n        # Navigate through nested keys\n        keys = key.split('.')\n        value = self.cache\n\n        for k in keys:\n            if isinstance(value, dict) and k in value:\n                value = value[k]\n            else:\n                return default\n\n        return value\n\n    def add_callback(self, callback: Callable[[Dict[str, Any]], None]) -&gt; None:\n        \"\"\"Add a callback for configuration changes.\"\"\"\n        self.callbacks.append(callback)\n\n    def remove_callback(self, callback: Callable[[Dict[str, Any]], None]) -&gt; None:\n        \"\"\"Remove a configuration change callback.\"\"\"\n        if callback in self.callbacks:\n            self.callbacks.remove(callback)\n\n# Usage example\ndef config_change_handler(new_config: Dict[str, Any]) -&gt; None:\n    \"\"\"Handle configuration changes.\"\"\"\n    print(\"Configuration updated!\")\n    print(f\"New app name: {new_config.get('app', {}).get('name')}\")\n\ndef main():\n    cache = ConfigCache(\"app_config.json\", reload_interval=10)\n\n    # Add change handler\n    cache.add_callback(config_change_handler)\n\n    # Load initial configuration\n    cache.load()\n\n    # Start auto-reload\n    cache.start_auto_reload()\n\n    try:\n        # Use configuration\n        for i in range(5):\n            app_name = cache.get(\"app.name\", \"Unknown\")\n            print(f\"App name: {app_name}\")\n            time.sleep(5)\n    finally:\n        # Stop auto-reload\n        cache.stop_auto_reload()\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"usage_examples/basic_examples/","title":"Basic Examples","text":""},{"location":"usage_examples/basic_examples/#simple-configuration-file","title":"Simple Configuration File","text":"<pre><code>from yapfm import YAPFileManager\n\n# Create a basic configuration file\ndef create_app_config():\n    with YAPFileManager(\"app_config.json\", auto_create=True) as fm:\n        # Application settings\n        fm.set_key(\"My Application\", dot_key=\"app.name\")\n        fm.set_key(\"1.0.0\", dot_key=\"app.version\")\n        fm.set_key(\"production\", dot_key=\"app.environment\")\n\n        # Database configuration\n        fm.set_key(\"localhost\", dot_key=\"database.host\")\n        fm.set_key(5432, dot_key=\"database.port\")\n        fm.set_key(\"myapp\", dot_key=\"database.name\")\n        fm.set_key(True, dot_key=\"database.ssl\")\n\n        # API settings\n        fm.set_key(\"v1\", dot_key=\"api.version\")\n        fm.set_key(30, dot_key=\"api.timeout\")\n        fm.set_key(3, dot_key=\"api.retries\")\n\n        print(\"Configuration created successfully!\")\n\n# Read configuration\ndef read_app_config():\n    with YAPFileManager(\"app_config.json\") as fm:\n        app_name = fm.get_key(dot_key=\"app.name\")\n        db_host = fm.get_key(dot_key=\"database.host\")\n        api_timeout = fm.get_key(dot_key=\"api.timeout\")\n\n        print(f\"App: {app_name}\")\n        print(f\"Database: {db_host}\")\n        print(f\"API Timeout: {api_timeout}s\")\n\n# Run the examples\ncreate_app_config()\nread_app_config()\n</code></pre>"},{"location":"usage_examples/basic_examples/#working-with-different-file-formats","title":"Working with Different File Formats","text":""},{"location":"usage_examples/basic_examples/#using-yapfilemanager-directly","title":"Using YAPFileManager Directly","text":"<pre><code>from yapfm import YAPFileManager\n\n# JSON configuration\ndef json_example():\n    with YAPFileManager(\"config.json\", auto_create=True) as fm:\n        fm.set_key(\"JSON Config\", dot_key=\"format\")\n        fm.set_key({\"key1\": \"value1\", \"key2\": \"value2\"}, dot_key=\"data\")\n        print(\"JSON configuration created\")\n\n# TOML configuration\ndef toml_example():\n    with YAPFileManager(\"config.toml\", auto_create=True) as fm:\n        fm.set_key(\"TOML Config\", dot_key=\"format\")\n        fm.set_key(\"localhost\", dot_key=\"server.host\")\n        fm.set_key(8000, dot_key=\"server.port\")\n        print(\"TOML configuration created\")\n\n# YAML configuration\ndef yaml_example():\n    with YAPFileManager(\"config.yaml\", auto_create=True) as fm:\n        fm.set_key(\"YAML Config\", dot_key=\"format\")\n        fm.set_key([\"item1\", \"item2\", \"item3\"], dot_key=\"items\")\n        print(\"YAML configuration created\")\n\n# Run all examples\njson_example()\ntoml_example()\nyaml_example()\n</code></pre>"},{"location":"usage_examples/basic_examples/#using-the-open_file-helper","title":"Using the open_file Helper","text":"<pre><code>from yapfm.helpers import open_file\n\n# Open files with automatic format detection\ndef open_file_examples():\n    # JSON file\n    json_fm = open_file(\"config.json\", auto_create=True)\n    with json_fm:\n        json_fm.set_key(\"JSON Config\", dot_key=\"format\")\n        json_fm.set_key({\"key1\": \"value1\", \"key2\": \"value2\"}, dot_key=\"data\")\n\n    # TOML file\n    toml_fm = open_file(\"config.toml\", auto_create=True)\n    with toml_fm:\n        toml_fm.set_key(\"TOML Config\", dot_key=\"format\")\n        toml_fm.set_key(\"localhost\", dot_key=\"server.host\")\n        toml_fm.set_key(8000, dot_key=\"server.port\")\n\n    # YAML file\n    yaml_fm = open_file(\"config.yaml\", auto_create=True)\n    with yaml_fm:\n        yaml_fm.set_key(\"YAML Config\", dot_key=\"format\")\n        yaml_fm.set_key([\"item1\", \"item2\", \"item3\"], dot_key=\"items\")\n\n    print(\"All configurations created using open_file helper\")\n\n# Format override examples\ndef format_override_examples():\n    # Force JSON format regardless of file extension\n    json_fm = open_file(\"config.txt\", format=\"json\", auto_create=True)\n    with json_fm:\n        json_fm.set_key(\"Forced JSON\", dot_key=\"format\")\n\n    # Force TOML format\n    toml_fm = open_file(\"settings.dat\", format=\"toml\", auto_create=True)\n    with toml_fm:\n        toml_fm.set_key(\"Forced TOML\", dot_key=\"format\")\n\n    # Force YAML format\n    yaml_fm = open_file(\"data.log\", format=\"yaml\", auto_create=True)\n    with yaml_fm:\n        yaml_fm.set_key(\"Forced YAML\", dot_key=\"format\")\n\n    print(\"Format override examples completed\")\n\n# Run examples\nopen_file_examples()\nformat_override_examples()\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/","title":"Caching &amp; Streaming Examples","text":"<p>This document provides practical examples of using YAPFM's caching and performance features: intelligent caching, lazy loading, and streaming capabilities.</p>"},{"location":"usage_examples/caching_streaming_examples/#quick-start-with-caching-performance-features","title":"\ud83d\ude80 Quick Start with Caching &amp; Performance Features","text":""},{"location":"usage_examples/caching_streaming_examples/#basic-setup","title":"Basic Setup","text":"<pre><code>from yapfm import YAPFileManager\nfrom yapfm.strategies import JSONFileStrategy\n\n# Create a file manager with all caching and performance features enabled\nfm = YAPFileManager(\n    \"config.json\",\n    strategy=JSONFileStrategy(),\n    auto_create=True,\n    enable_cache=True,           # Enable intelligent caching\n    cache_size=1000,            # Maximum 1000 cached entries\n    cache_ttl=3600,             # 1 hour TTL\n    enable_lazy_loading=True,   # Enable lazy loading for sections\n    enable_streaming=True       # Enable streaming for large files\n)\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#intelligent-caching-examples","title":"\ud83e\udde0 Intelligent Caching Examples","text":""},{"location":"usage_examples/caching_streaming_examples/#basic-caching","title":"Basic Caching","text":"<pre><code># First access loads from file and caches\nhost = fm.get_value(\"database.host\")\nprint(f\"Database host: {host}\")\n\n# Subsequent accesses return from cache (much faster)\nhost_cached = fm.get_value(\"database.host\")  # Returns from cache\nprint(f\"Cached host: {host_cached}\")\n\n# Access with default value\nport = fm.get_value(\"database.port\", default=5432)\nprint(f\"Database port: {port}\")\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#cache-management","title":"Cache Management","text":"<pre><code># Get cache statistics\nstats = fm.get_cache_stats()\nprint(f\"Cache hits: {stats['unified_cache']['hits']}\")\nprint(f\"Cache misses: {stats['unified_cache']['misses']}\")\nprint(f\"Hit rate: {stats['unified_cache']['hit_rate']:.2%}\")\nprint(f\"Cache size: {stats['unified_cache']['size']}\")\n\n# Invalidate specific patterns\nfm.invalidate_cache(\"key:database.*\")  # Invalidate all database keys\nfm.invalidate_cache(\"key:api.*\")       # Invalidate all API keys\n\n# Clear all cache\nfm.clear_cache()\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code>import time\n\n# Measure cache performance\nstart_time = time.time()\nfor i in range(1000):\n    value = fm.get_value(\"database.host\")\ncached_time = time.time() - start_time\n\n# Clear cache and measure without caching\nfm.clear_cache()\nstart_time = time.time()\nfor i in range(1000):\n    value = fm.get_value(\"database.host\")\nuncached_time = time.time() - start_time\n\nprint(f\"Cached access time: {cached_time:.4f}s\")\nprint(f\"Uncached access time: {uncached_time:.4f}s\")\nprint(f\"Speed improvement: {uncached_time/cached_time:.2f}x\")\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#lazy-loading-examples","title":"\ud83c\udfaf Lazy Loading Examples","text":""},{"location":"usage_examples/caching_streaming_examples/#basic-lazy-loading","title":"Basic Lazy Loading","text":"<pre><code># Section is not loaded until accessed\ndb_section = fm.get_section(\"database\")\nprint(f\"Database host: {db_section['host']}\")\nprint(f\"Database port: {db_section['port']}\")\n\n# Subsequent accesses return from lazy cache\ndb_section_again = fm.get_section(\"database\")  # Returns from cache\nprint(f\"Database name: {db_section_again['name']}\")\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#lazy-loading-with-statistics","title":"Lazy Loading with Statistics","text":"<pre><code># Get lazy loading statistics\nstats = fm.get_lazy_stats()\nprint(f\"Total sections: {stats['total_sections']}\")\nprint(f\"Loaded sections: {stats['loaded_sections']}\")\nprint(f\"Loading efficiency: {stats['loaded_sections']/stats['total_sections']:.2%}\")\n\n# Force immediate loading (bypass lazy loading)\ndb_section = fm.get_section(\"database\", lazy=False)\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#lazy-loading-with-cache-invalidation","title":"Lazy Loading with Cache Invalidation","text":"<pre><code># Update section with cache invalidation\nfm.set_section({\n    \"host\": \"newhost.example.com\",\n    \"port\": 3306,\n    \"name\": \"new_database\"\n}, dot_key=\"database\", update_lazy_cache=True)\n\n# The lazy cache is automatically invalidated\ndb_section = fm.get_section(\"database\")  # Loads fresh data\nprint(f\"New database host: {db_section['host']}\")\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#streaming-examples","title":"\ud83c\udf0a Streaming Examples","text":""},{"location":"usage_examples/caching_streaming_examples/#basic-file-streaming","title":"Basic File Streaming","text":"<pre><code># Stream file in chunks\nfor chunk in fm.stream_file(chunk_size=1024*1024):  # 1MB chunks\n    print(f\"Processing chunk of {len(chunk)} bytes\")\n    process_chunk(chunk)\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#line-by-line-processing","title":"Line-by-Line Processing","text":"<pre><code># Stream file line by line\nerror_count = 0\nfor line in fm.stream_lines():\n    if \"ERROR\" in line:\n        error_count += 1\n        print(f\"Error found: {line.strip()}\")\n\nprint(f\"Total errors found: {error_count}\")\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#section-extraction","title":"Section Extraction","text":"<pre><code># Extract sections from large configuration files\nfor section in fm.stream_sections(\"[\", \"]\"):\n    print(f\"Section: {section['name']}\")\n    print(f\"Content: {section['content']}\")\n    print(\"---\")\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#custom-processing-with-progress","title":"Custom Processing with Progress","text":"<pre><code>def count_words(chunk):\n    return len(chunk.split())\n\ndef progress_callback(progress):\n    print(f\"Processing progress: {progress:.1%}\")\n\n# Process large file with custom function\nresults = list(fm.process_large_file(count_words, progress_callback))\ntotal_words = sum(results)\nprint(f\"Total words in file: {total_words}\")\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#search-in-large-files","title":"Search in Large Files","text":"<pre><code># Search for patterns in large files\nfor match in fm.search_in_file(\"error\", case_sensitive=False, context_lines=3):\n    print(f\"Found at line {match['line_number']}: {match['match']}\")\n    print(f\"Context: {match['context']}\")\n    print(\"---\")\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#real-world-examples","title":"\ud83d\udd27 Real-World Examples","text":""},{"location":"usage_examples/caching_streaming_examples/#configuration-management-system","title":"Configuration Management System","text":"<pre><code>class ConfigManager:\n    def __init__(self, config_file):\n        self.fm = YAPFileManager(\n            config_file,\n            enable_cache=True,\n            cache_size=5000,\n            cache_ttl=1800,  # 30 minutes\n            enable_lazy_loading=True\n        )\n\n    def get_database_config(self):\n        \"\"\"Get database configuration with caching.\"\"\"\n        return self.fm.get_section(\"database\")\n\n    def get_api_config(self):\n        \"\"\"Get API configuration with caching.\"\"\"\n        return self.fm.get_section(\"api\")\n\n    def update_database_config(self, new_config):\n        \"\"\"Update database configuration with cache invalidation.\"\"\"\n        self.fm.set_section(new_config, dot_key=\"database\", update_lazy_cache=True)\n\n    def get_cache_stats(self):\n        \"\"\"Get comprehensive cache statistics.\"\"\"\n        return self.fm.get_cache_stats()\n\n# Usage\nconfig = ConfigManager(\"app_config.json\")\ndb_config = config.get_database_config()\napi_config = config.get_api_config()\n\n# Monitor performance\nstats = config.get_cache_stats()\nprint(f\"Cache hit rate: {stats['unified_cache']['hit_rate']:.2%}\")\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#large-log-file-analyzer","title":"Large Log File Analyzer","text":"<pre><code>class LogAnalyzer:\n    def __init__(self, log_file):\n        self.fm = YAPFileManager(log_file, enable_streaming=True)\n\n    def analyze_errors(self):\n        \"\"\"Analyze error patterns in log file.\"\"\"\n        error_patterns = {}\n\n        for match in self.fm.search_in_file(\"ERROR\", case_sensitive=False):\n            error_type = self.extract_error_type(match['match'])\n            error_patterns[error_type] = error_patterns.get(error_type, 0) + 1\n\n        return error_patterns\n\n    def extract_error_type(self, error_line):\n        \"\"\"Extract error type from error line.\"\"\"\n        # Simple error type extraction\n        if \"connection\" in error_line.lower():\n            return \"connection_error\"\n        elif \"timeout\" in error_line.lower():\n            return \"timeout_error\"\n        else:\n            return \"unknown_error\"\n\n    def get_file_stats(self):\n        \"\"\"Get file statistics.\"\"\"\n        return {\n            \"size\": self.fm.get_file_size(),\n            \"progress\": self.fm.get_file_progress()\n        }\n\n# Usage\nanalyzer = LogAnalyzer(\"application.log\")\nerror_patterns = analyzer.analyzer_errors()\nprint(\"Error patterns found:\")\nfor error_type, count in error_patterns.items():\n    print(f\"  {error_type}: {count}\")\n\nfile_stats = analyzer.get_file_stats()\nprint(f\"File size: {file_stats['size']} bytes\")\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#memory-efficient-data-processor","title":"Memory-Efficient Data Processor","text":"<pre><code>class DataProcessor:\n    def __init__(self, data_file):\n        self.fm = YAPFileManager(\n            data_file,\n            enable_lazy_loading=True,\n            enable_cache=True,\n            cache_size=1000\n        )\n\n    def process_user_data(self, user_id):\n        \"\"\"Process user data with lazy loading.\"\"\"\n        user_section = self.fm.get_section(f\"users.{user_id}\")\n        if user_section:\n            return self.process_user_section(user_section)\n        return None\n\n    def process_user_section(self, user_data):\n        \"\"\"Process individual user data.\"\"\"\n        # Process user data without loading entire file\n        return {\n            \"id\": user_data.get(\"id\"),\n            \"name\": user_data.get(\"name\"),\n            \"email\": user_data.get(\"email\"),\n            \"processed_at\": time.time()\n        }\n\n    def get_processing_stats(self):\n        \"\"\"Get processing statistics.\"\"\"\n        cache_stats = self.fm.get_cache_stats()\n        lazy_stats = self.fm.get_lazy_stats()\n\n        return {\n            \"cache_hit_rate\": cache_stats['unified_cache']['hit_rate'],\n            \"loaded_sections\": lazy_stats['loaded_sections'],\n            \"total_sections\": lazy_stats['total_sections']\n        }\n\n# Usage\nprocessor = DataProcessor(\"users.json\")\n\n# Process individual users (only loads their sections)\nuser_1 = processor.process_user_data(\"user_1\")\nuser_2 = processor.process_user_data(\"user_2\")\n\n# Get processing statistics\nstats = processor.get_processing_stats()\nprint(f\"Cache hit rate: {stats['cache_hit_rate']:.2%}\")\nprint(f\"Loaded sections: {stats['loaded_sections']}/{stats['total_sections']}\")\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#performance-optimization-examples","title":"\ud83c\udfaf Performance Optimization Examples","text":""},{"location":"usage_examples/caching_streaming_examples/#cache-size-optimization","title":"Cache Size Optimization","text":"<pre><code>import time\nimport psutil\n\ndef optimize_cache_size(fm, test_keys, max_memory_mb=100):\n    \"\"\"Find optimal cache size based on memory usage.\"\"\"\n    best_size = 100\n    best_hit_rate = 0\n\n    for cache_size in [100, 500, 1000, 2000, 5000]:\n        fm.clear_cache()\n        fm.unified_cache.max_size = cache_size\n\n        # Test with sample keys\n        start_time = time.time()\n        for key in test_keys:\n            fm.get_value(key)\n        test_time = time.time() - start_time\n\n        # Get statistics\n        stats = fm.get_cache_stats()\n        hit_rate = stats['unified_cache']['hit_rate']\n        memory_usage = stats['unified_cache']['memory_usage_mb']\n\n        print(f\"Cache size: {cache_size}, Hit rate: {hit_rate:.2%}, Memory: {memory_usage:.2f}MB\")\n\n        if hit_rate &gt; best_hit_rate and memory_usage &lt; max_memory_mb:\n            best_size = cache_size\n            best_hit_rate = hit_rate\n\n    return best_size\n\n# Usage\ntest_keys = [\"database.host\", \"database.port\", \"api.key\", \"api.url\", \"app.name\"]\noptimal_size = optimize_cache_size(fm, test_keys)\nprint(f\"Optimal cache size: {optimal_size}\")\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#lazy-loading-efficiency","title":"Lazy Loading Efficiency","text":"<pre><code>def analyze_lazy_loading_efficiency(fm):\n    \"\"\"Analyze lazy loading efficiency.\"\"\"\n    stats = fm.get_lazy_stats()\n\n    total_sections = stats['total_sections']\n    loaded_sections = stats['loaded_sections']\n    efficiency = loaded_sections / total_sections if total_sections &gt; 0 else 0\n\n    print(f\"Lazy Loading Analysis:\")\n    print(f\"  Total sections: {total_sections}\")\n    print(f\"  Loaded sections: {loaded_sections}\")\n    print(f\"  Efficiency: {efficiency:.2%}\")\n\n    if efficiency &gt; 0.5:\n        print(\"  Warning: High lazy loading ratio, consider disabling lazy loading\")\n    elif efficiency &lt; 0.1:\n        print(\"  Good: Low lazy loading ratio, lazy loading is working well\")\n    else:\n        print(\"  Good: Moderate lazy loading ratio\")\n\n# Usage\nanalyze_lazy_loading_efficiency(fm)\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#streaming-performance","title":"Streaming Performance","text":"<pre><code>def benchmark_streaming(fm, chunk_sizes=[1024, 10240, 102400, 1024000]):\n    \"\"\"Benchmark streaming performance with different chunk sizes.\"\"\"\n    results = {}\n\n    for chunk_size in chunk_sizes:\n        start_time = time.time()\n\n        # Stream file with specific chunk size\n        chunks = list(fm.stream_file(chunk_size=chunk_size))\n\n        end_time = time.time()\n        processing_time = end_time - start_time\n\n        results[chunk_size] = {\n            \"time\": processing_time,\n            \"chunks\": len(chunks),\n            \"avg_chunk_size\": sum(len(chunk) for chunk in chunks) / len(chunks) if chunks else 0\n        }\n\n        print(f\"Chunk size: {chunk_size}, Time: {processing_time:.4f}s, Chunks: {len(chunks)}\")\n\n    # Find optimal chunk size\n    best_chunk_size = min(results.keys(), key=lambda k: results[k][\"time\"])\n    print(f\"Optimal chunk size: {best_chunk_size}\")\n\n    return results\n\n# Usage\nstreaming_results = benchmark_streaming(fm)\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#debugging-and-monitoring","title":"\ud83d\udd0d Debugging and Monitoring","text":""},{"location":"usage_examples/caching_streaming_examples/#cache-debugging","title":"Cache Debugging","text":"<pre><code>def debug_cache_behavior(fm):\n    \"\"\"Debug cache behavior and performance.\"\"\"\n    print(\"Cache Debug Information:\")\n    print(\"=\" * 50)\n\n    # Get cache statistics\n    stats = fm.get_cache_stats()\n    cache_stats = stats['unified_cache']\n\n    print(f\"Cache size: {cache_stats['size']}/{cache_stats['max_size']}\")\n    print(f\"Memory usage: {cache_stats['memory_usage_mb']:.2f}MB\")\n    print(f\"Hit rate: {cache_stats['hit_rate']:.2%}\")\n    print(f\"Hits: {cache_stats['hits']}\")\n    print(f\"Misses: {cache_stats['misses']}\")\n    print(f\"Evictions: {cache_stats['evictions']}\")\n\n    # Check for performance issues\n    if cache_stats['hit_rate'] &lt; 0.5:\n        print(\"\u26a0\ufe0f  Warning: Low hit rate, consider increasing cache size\")\n\n    if cache_stats['memory_usage_mb'] &gt; 50:\n        print(\"\u26a0\ufe0f  Warning: High memory usage, consider reducing cache size\")\n\n    if cache_stats['evictions'] &gt; cache_stats['hits']:\n        print(\"\u26a0\ufe0f  Warning: High eviction rate, cache size may be too small\")\n\n# Usage\ndebug_cache_behavior(fm)\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#lazy-loading-monitoring","title":"Lazy Loading Monitoring","text":"<pre><code>def monitor_lazy_loading(fm):\n    \"\"\"Monitor lazy loading performance.\"\"\"\n    print(\"Lazy Loading Monitor:\")\n    print(\"=\" * 50)\n\n    stats = fm.get_lazy_stats()\n\n    print(f\"Total sections: {stats['total_sections']}\")\n    print(f\"Loaded sections: {stats['loaded_sections']}\")\n    print(f\"Loading efficiency: {stats['loaded_sections']/stats['total_sections']:.2%}\")\n\n    # Monitor memory usage\n    import psutil\n    process = psutil.Process()\n    memory_usage = process.memory_info().rss / 1024 / 1024  # MB\n\n    print(f\"Process memory usage: {memory_usage:.2f}MB\")\n\n    if memory_usage &gt; 100:  # More than 100MB\n        print(\"\u26a0\ufe0f  Warning: High memory usage, consider clearing lazy cache\")\n        fm.clear_lazy_cache()\n\n# Usage\nmonitor_lazy_loading(fm)\n</code></pre>"},{"location":"usage_examples/caching_streaming_examples/#best-practices-summary","title":"\ud83c\udfaf Best Practices Summary","text":""},{"location":"usage_examples/caching_streaming_examples/#caching-best-practices","title":"Caching Best Practices","text":"<ol> <li>Start with reasonable defaults: 1000 cache size, 1 hour TTL</li> <li>Monitor hit rates: Aim for 80%+ hit rate</li> <li>Use pattern invalidation: Invalidate related entries together</li> <li>Clear cache when needed: Clear cache when data changes significantly</li> <li>Balance memory and performance: Adjust cache size based on available memory</li> </ol>"},{"location":"usage_examples/caching_streaming_examples/#lazy-loading-best-practices","title":"Lazy Loading Best Practices","text":"<ol> <li>Use for large sections: Only use lazy loading for sections that are large</li> <li>Monitor memory usage: Keep track of loaded sections</li> <li>Invalidate when needed: Update lazy cache when sections change</li> <li>Consider access patterns: Disable lazy loading if sections are accessed frequently</li> </ol>"},{"location":"usage_examples/caching_streaming_examples/#streaming-best-practices","title":"Streaming Best Practices","text":"<ol> <li>Choose appropriate chunk size: Balance memory usage with I/O efficiency</li> <li>Use progress callbacks: Monitor long-running operations</li> <li>Handle errors gracefully: Streaming operations can fail on large files</li> <li>Test with different chunk sizes: Find the optimal chunk size for your use case</li> </ol> <p>For more examples and advanced usage patterns, see the API Reference and New Features Guide.</p>"},{"location":"usage_examples/configuration_management/","title":"Configuration Management","text":""},{"location":"usage_examples/configuration_management/#application-configuration-manager","title":"Application Configuration Manager","text":"<pre><code>from yapfm import YAPFileManager\nfrom typing import Dict, Any, Optional\nimport os\n\nclass AppConfig:\n    def __init__(self, config_file: str = \"app_config.json\"):\n        self.config_file = config_file\n        self.fm = YAPFileManager(config_file, auto_create=True)\n\n    def load(self) -&gt; None:\n        \"\"\"Load configuration with defaults.\"\"\"\n        with self.fm:\n            # Set application defaults\n            defaults = {\n                \"app.name\": \"My Application\",\n                \"app.version\": \"1.0.0\",\n                \"app.environment\": \"development\",\n                \"app.debug\": False,\n                \"database.host\": \"localhost\",\n                \"database.port\": 5432,\n                \"database.name\": \"myapp\",\n                \"database.ssl\": False,\n                \"api.version\": \"v1\",\n                \"api.timeout\": 30,\n                \"api.retries\": 3,\n                \"logging.level\": \"INFO\",\n                \"logging.file\": \"app.log\"\n            }\n\n            # Set defaults for missing keys\n            for key, value in defaults.items():\n                if not self.fm.has_key(dot_key=key):\n                    self.fm.set_key(value, dot_key=key)\n\n    def get(self, key: str, default: Any = None) -&gt; Any:\n        \"\"\"Get a configuration value.\"\"\"\n        return self.fm.get_key(dot_key=key, default=default)\n\n    def set(self, key: str, value: Any) -&gt; None:\n        \"\"\"Set a configuration value.\"\"\"\n        self.fm.set_key(value, dot_key=key)\n        self.fm.save()\n\n    def get_section(self, section: str) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Get an entire configuration section.\"\"\"\n        return self.fm.get_section(dot_key=section)\n\n    def set_section(self, section: str, data: Dict[str, Any]) -&gt; None:\n        \"\"\"Set an entire configuration section.\"\"\"\n        self.fm.set_section(data, dot_key=section)\n        self.fm.save()\n\n    def validate(self) -&gt; bool:\n        \"\"\"Validate required configuration keys.\"\"\"\n        required_keys = [\n            \"app.name\",\n            \"app.version\",\n            \"database.host\",\n            \"database.port\"\n        ]\n\n        for key in required_keys:\n            if not self.fm.has_key(dot_key=key):\n                print(f\"Missing required configuration key: {key}\")\n                return False\n\n        return True\n\n# Usage example\ndef main():\n    config = AppConfig(\"my_app_config.json\")\n    config.load()\n\n    if config.validate():\n        print(\"Configuration is valid\")\n        print(f\"App: {config.get('app.name')}\")\n        print(f\"Database: {config.get('database.host')}:{config.get('database.port')}\")\n    else:\n        print(\"Configuration validation failed\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"usage_examples/configuration_management/#dynamic-configuration-updates","title":"Dynamic Configuration Updates","text":"<pre><code>from yapfm import YAPFileManager\nimport time\nfrom typing import Dict, Any\n\nclass DynamicConfig:\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.fm = YAPFileManager(config_file, auto_create=True)\n        self.last_modified = 0\n\n    def load(self) -&gt; Dict[str, Any]:\n        \"\"\"Load configuration and track modifications.\"\"\"\n        with self.fm:\n            self.last_modified = time.time()\n            return self.fm.data\n\n    def update_feature_flag(self, feature: str, enabled: bool) -&gt; None:\n        \"\"\"Update a feature flag.\"\"\"\n        with self.fm:\n            self.fm.set_key(enabled, dot_key=f\"features.{feature}\")\n            self.fm.set_key(time.time(), dot_key=\"last_updated\")\n\n    def update_limits(self, limits: Dict[str, int]) -&gt; None:\n        \"\"\"Update application limits.\"\"\"\n        with self.fm:\n            for key, value in limits.items():\n                self.fm.set_key(value, dot_key=f\"limits.{key}\")\n            self.fm.set_key(time.time(), dot_key=\"last_updated\")\n\n    def get_feature_flags(self) -&gt; Dict[str, bool]:\n        \"\"\"Get all feature flags.\"\"\"\n        return self.fm.get_section(dot_key=\"features\") or {}\n\n    def get_limits(self) -&gt; Dict[str, int]:\n        \"\"\"Get all limits.\"\"\"\n        return self.fm.get_section(dot_key=\"limits\") or {}\n\n# Usage example\ndef main():\n    config = DynamicConfig(\"dynamic_config.json\")\n\n    # Load initial configuration\n    config.load()\n\n    # Update feature flags\n    config.update_feature_flag(\"new_ui\", True)\n    config.update_feature_flag(\"beta_features\", False)\n\n    # Update limits\n    config.update_limits({\n        \"max_users\": 1000,\n        \"max_requests_per_hour\": 10000,\n        \"max_file_size_mb\": 10\n    })\n\n    # Check current settings\n    features = config.get_feature_flags()\n    limits = config.get_limits()\n\n    print(\"Feature Flags:\", features)\n    print(\"Limits:\", limits)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"usage_examples/error_handling_patterns/","title":"Error Handling Patterns","text":""},{"location":"usage_examples/error_handling_patterns/#robust-configuration-loading","title":"Robust Configuration Loading","text":"<pre><code>from yapfm import YAPFileManager\nfrom yapfm.exceptions import LoadFileError, FileWriteError, StrategyError\nimport logging\nfrom typing import Dict, Any, Optional\n\nclass RobustConfig:\n    def __init__(self, config_file: str, fallback_config: Optional[Dict[str, Any]] = None):\n        self.config_file = config_file\n        self.fallback_config = fallback_config or {}\n        self.logger = logging.getLogger(\"robust_config\")\n\n    def load_with_fallback(self) -&gt; Dict[str, Any]:\n        \"\"\"Load configuration with fallback to defaults.\"\"\"\n        try:\n            # Try to load from file\n            fm = YAPFileManager(self.config_file)\n            with fm:\n                return fm.data\n        except LoadFileError as e:\n            self.logger.warning(f\"Failed to load config file: {e}\")\n            return self._create_fallback_config()\n        except StrategyError as e:\n            self.logger.error(f\"Unsupported file format: {e}\")\n            return self._create_fallback_config()\n        except Exception as e:\n            self.logger.error(f\"Unexpected error loading config: {e}\")\n            return self._create_fallback_config()\n\n    def _create_fallback_config(self) -&gt; Dict[str, Any]:\n        \"\"\"Create fallback configuration.\"\"\"\n        self.logger.info(\"Creating fallback configuration\")\n\n        fallback = {\n            \"app\": {\n                \"name\": \"Fallback App\",\n                \"version\": \"1.0.0\",\n                \"environment\": \"fallback\"\n            },\n            \"database\": {\n                \"host\": \"localhost\",\n                \"port\": 5432,\n                \"name\": \"fallback_db\"\n            },\n            \"api\": {\n                \"timeout\": 30,\n                \"retries\": 3\n            }\n        }\n\n        # Merge with provided fallback\n        fallback.update(self.fallback_config)\n\n        # Save fallback config\n        try:\n            fm = YAPFileManager(self.config_file, auto_create=True)\n            with fm:\n                fm.data = fallback\n        except Exception as e:\n            self.logger.error(f\"Failed to save fallback config: {e}\")\n\n        return fallback\n\n    def safe_save(self, data: Dict[str, Any]) -&gt; bool:\n        \"\"\"Safely save configuration with backup.\"\"\"\n        try:\n            # Create backup\n            backup_file = f\"{self.config_file}.backup\"\n            if self.fm.exists():\n                import shutil\n                shutil.copy2(self.config_file, backup_file)\n\n            # Save new configuration\n            fm = YAPFileManager(self.config_file)\n            with fm:\n                fm.data = data\n\n            self.logger.info(\"Configuration saved successfully\")\n            return True\n\n        except FileWriteError as e:\n            self.logger.error(f\"Failed to save configuration: {e}\")\n\n            # Try to restore from backup\n            try:\n                if backup_file and os.path.exists(backup_file):\n                    import shutil\n                    shutil.copy2(backup_file, self.config_file)\n                    self.logger.info(\"Restored configuration from backup\")\n            except Exception as restore_error:\n                self.logger.error(f\"Failed to restore from backup: {restore_error}\")\n\n            return False\n        except Exception as e:\n            self.logger.error(f\"Unexpected error saving configuration: {e}\")\n            return False\n\n# Usage example\ndef main():\n    # Set up logging\n    logging.basicConfig(level=logging.INFO)\n\n    # Create robust config with fallback\n    fallback_config = {\n        \"app\": {\"name\": \"My App\", \"version\": \"1.0.0\"},\n        \"database\": {\"host\": \"localhost\", \"port\": 5432}\n    }\n\n    config = RobustConfig(\"app_config.json\", fallback_config)\n\n    # Load configuration (will use fallback if file doesn't exist)\n    data = config.load_with_fallback()\n    print(\"Loaded configuration:\", data)\n\n    # Safely save configuration\n    data[\"app\"][\"version\"] = \"1.1.0\"\n    if config.safe_save(data):\n        print(\"Configuration saved successfully\")\n    else:\n        print(\"Failed to save configuration\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"usage_examples/integration_examples/","title":"Integration Examples","text":""},{"location":"usage_examples/integration_examples/#flask-application-integration","title":"Flask Application Integration","text":"<pre><code>from flask import Flask, request, jsonify\nfrom yapfm import YAPFileManager, FileManagerProxy\nimport logging\n\napp = Flask(__name__)\n\n# Set up configuration\nconfig_fm = YAPFileManager(\"flask_config.json\", auto_create=True)\nconfig_proxy = FileManagerProxy(\n    config_fm,\n    enable_logging=True,\n    enable_metrics=True,\n    logger=logging.getLogger(\"flask_config\")\n)\n\n@app.route('/config', methods=['GET'])\ndef get_config():\n    \"\"\"Get application configuration.\"\"\"\n    try:\n        with config_proxy:\n            return jsonify(config_proxy.data)\n    except Exception as e:\n        return jsonify({\"error\": str(e)}), 500\n\n@app.route('/config/&lt;path:key&gt;', methods=['GET'])\ndef get_config_key(key):\n    \"\"\"Get a specific configuration key.\"\"\"\n    try:\n        with config_proxy:\n            value = config_proxy.get_key(dot_key=key)\n            if value is None:\n                return jsonify({\"error\": \"Key not found\"}), 404\n            return jsonify({\"key\": key, \"value\": value})\n    except Exception as e:\n        return jsonify({\"error\": str(e)}), 500\n\n@app.route('/config/&lt;path:key&gt;', methods=['POST'])\ndef set_config_key(key):\n    \"\"\"Set a specific configuration key.\"\"\"\n    try:\n        data = request.get_json()\n        if not data or 'value' not in data:\n            return jsonify({\"error\": \"Value required\"}), 400\n\n        with config_proxy:\n            config_proxy.set_key(data['value'], dot_key=key)\n            return jsonify({\"key\": key, \"value\": data['value']})\n    except Exception as e:\n        return jsonify({\"error\": str(e)}), 500\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"usage_examples/integration_examples/#django-settings-integration","title":"Django Settings Integration","text":"<pre><code># settings.py\nfrom yapfm import YAPFileManager\nimport os\n\n# Load configuration from file\nconfig_fm = YAPFileManager(\"django_config.json\", auto_create=True)\n\nwith config_fm:\n    # Database configuration\n    DATABASES = {\n        'default': {\n            'ENGINE': config_fm.get_key(dot_key=\"database.engine\", default=\"django.db.backends.postgresql\"),\n            'NAME': config_fm.get_key(dot_key=\"database.name\", default=\"myapp\"),\n            'USER': config_fm.get_key(dot_key=\"database.user\", default=\"postgres\"),\n            'PASSWORD': config_fm.get_key(dot_key=\"database.password\", default=\"\"),\n            'HOST': config_fm.get_key(dot_key=\"database.host\", default=\"localhost\"),\n            'PORT': config_fm.get_key(dot_key=\"database.port\", default=\"5432\"),\n        }\n    }\n\n    # Debug setting\n    DEBUG = config_fm.get_key(dot_key=\"debug\", default=False)\n\n    # Secret key\n    SECRET_KEY = config_fm.get_key(dot_key=\"secret_key\", default=\"your-secret-key-here\")\n\n    # Allowed hosts\n    ALLOWED_HOSTS = config_fm.get_key(dot_key=\"allowed_hosts\", default=[\"localhost\"])\n\n    # Logging configuration\n    LOGGING = {\n        'version': 1,\n        'disable_existing_loggers': False,\n        'handlers': {\n            'file': {\n                'level': config_fm.get_key(dot_key=\"logging.level\", default=\"INFO\"),\n                'class': 'logging.FileHandler',\n                'filename': config_fm.get_key(dot_key=\"logging.file\", default=\"django.log\"),\n            },\n        },\n        'root': {\n            'handlers': ['file'],\n        },\n    }\n</code></pre>"},{"location":"usage_examples/logging_monitoring/","title":"Logging and Monitoring","text":""},{"location":"usage_examples/logging_monitoring/#configuration-with-proxy-and-logging","title":"Configuration with Proxy and Logging","text":"<pre><code>from yapfm import YAPFileManager, FileManagerProxy\nimport logging\nimport time\nfrom typing import Dict, Any\n\nclass MonitoredConfig:\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.fm = YAPFileManager(config_file, auto_create=True)\n\n        # Set up logging\n        self.logger = logging.getLogger(\"config_monitor\")\n        self.logger.setLevel(logging.INFO)\n\n        # Create file handler\n        handler = logging.FileHandler(\"config_operations.log\")\n        formatter = logging.Formatter(\n            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n        )\n        handler.setFormatter(formatter)\n        self.logger.addHandler(handler)\n\n        # Create proxy with monitoring\n        self.proxy = FileManagerProxy(\n            self.fm,\n            enable_logging=True,\n            enable_metrics=True,\n            enable_audit=True,\n            logger=self.logger,\n            audit_hook=self._audit_hook\n        )\n\n        # Metrics storage\n        self.metrics: Dict[str, Any] = {\n            \"operations\": 0,\n            \"loads\": 0,\n            \"saves\": 0,\n            \"errors\": 0\n        }\n\n    def _audit_hook(self, method: str, args: tuple, kwargs: dict, result: Any) -&gt; None:\n        \"\"\"Custom audit hook for tracking operations.\"\"\"\n        self.metrics[\"operations\"] += 1\n\n        if method == \"load\":\n            self.metrics[\"loads\"] += 1\n        elif method == \"save\":\n            self.metrics[\"saves\"] += 1\n\n        # Log significant operations\n        if method in [\"set_key\", \"set_section\", \"delete_key\"]:\n            self.logger.info(f\"Configuration modified: {method} with args {args}\")\n\n    def load(self) -&gt; Dict[str, Any]:\n        \"\"\"Load configuration with monitoring.\"\"\"\n        try:\n            with self.proxy:\n                return self.proxy.data\n        except Exception as e:\n            self.metrics[\"errors\"] += 1\n            self.logger.error(f\"Failed to load configuration: {e}\")\n            raise\n\n    def set_key(self, key: str, value: Any) -&gt; None:\n        \"\"\"Set configuration key with monitoring.\"\"\"\n        try:\n            with self.proxy:\n                self.proxy.set_key(value, dot_key=key)\n        except Exception as e:\n            self.metrics[\"errors\"] += 1\n            self.logger.error(f\"Failed to set key {key}: {e}\")\n            raise\n\n    def get_metrics(self) -&gt; Dict[str, Any]:\n        \"\"\"Get operation metrics.\"\"\"\n        return self.metrics.copy()\n\n    def reset_metrics(self) -&gt; None:\n        \"\"\"Reset operation metrics.\"\"\"\n        self.metrics = {\n            \"operations\": 0,\n            \"loads\": 0,\n            \"saves\": 0,\n            \"errors\": 0\n        }\n\n# Usage example\ndef main():\n    config = MonitoredConfig(\"monitored_config.json\")\n\n    # Load configuration\n    config.load()\n\n    # Make some changes\n    config.set_key(\"app.name\", \"Monitored App\")\n    config.set_key(\"app.version\", \"2.0.0\")\n    config.set_key(\"database.host\", \"monitored-db.example.com\")\n\n    # Check metrics\n    metrics = config.get_metrics()\n    print(\"Configuration Metrics:\")\n    for key, value in metrics.items():\n        print(f\"  {key}: {value}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"usage_examples/multi_environment_setup/","title":"Multi-Environment Setup","text":""},{"location":"usage_examples/multi_environment_setup/#environment-specific-configuration","title":"Environment-Specific Configuration","text":"<pre><code>from yapfm import YAPFileManager\nimport os\nfrom typing import Dict, Any\n\nclass EnvironmentConfig:\n    def __init__(self, base_config: str = \"config.json\"):\n        self.environment = os.getenv(\"ENVIRONMENT\", \"development\")\n        self.config_file = f\"config_{self.environment}.json\"\n        self.fm = YAPFileManager(self.config_file, auto_create=True)\n\n    def load(self) -&gt; Dict[str, Any]:\n        \"\"\"Load environment-specific configuration.\"\"\"\n        with self.fm:\n            # Set environment\n            self.fm.set_key(self.environment, dot_key=\"environment\")\n\n            # Set environment-specific defaults\n            if self.environment == \"development\":\n                self._set_development_defaults()\n            elif self.environment == \"staging\":\n                self._set_staging_defaults()\n            elif self.environment == \"production\":\n                self._set_production_defaults()\n\n            return self.fm.data\n\n    def _set_development_defaults(self) -&gt; None:\n        \"\"\"Set development environment defaults.\"\"\"\n        defaults = {\n            \"debug\": True,\n            \"database.host\": \"localhost\",\n            \"database.port\": 5432,\n            \"database.ssl\": False,\n            \"api.timeout\": 60,\n            \"api.debug\": True,\n            \"logging.level\": \"DEBUG\",\n            \"logging.console\": True,\n            \"cors.origins\": [\"http://localhost:3000\", \"http://localhost:8080\"]\n        }\n\n        for key, value in defaults.items():\n            if not self.fm.has_key(dot_key=key):\n                self.fm.set_key(value, dot_key=key)\n\n    def _set_staging_defaults(self) -&gt; None:\n        \"\"\"Set staging environment defaults.\"\"\"\n        defaults = {\n            \"debug\": False,\n            \"database.host\": \"staging-db.example.com\",\n            \"database.port\": 5432,\n            \"database.ssl\": True,\n            \"api.timeout\": 30,\n            \"api.debug\": False,\n            \"logging.level\": \"INFO\",\n            \"logging.console\": False,\n            \"cors.origins\": [\"https://staging.demo.example.com\"]\n        }\n\n        for key, value in defaults.items():\n            if not self.fm.has_key(dot_key=key):\n                self.fm.set_key(value, dot_key=key)\n\n    def _set_production_defaults(self) -&gt; None:\n        \"\"\"Set production environment defaults.\"\"\"\n        defaults = {\n            \"debug\": False,\n            \"database.host\": \"prod-db.example.com\",\n            \"database.port\": 3306,\n            \"database.ssl\": True,\n            \"api.timeout\": 15,\n            \"api.debug\": False,\n            \"logging.level\": \"WARNING\",\n            \"logging.console\": False,\n            \"cors.origins\": [\"https://demo.example.com\"]\n        }\n\n        for key, value in defaults.items():\n            if not self.fm.has_key(dot_key=key):\n                self.fm.set_key(value, dot_key=key)\n\n    def get_database_url(self) -&gt; str:\n        \"\"\"Get database URL for current environment.\"\"\"\n        host = self.fm.get_key(dot_key=\"database.host\")\n        port = self.fm.get_key(dot_key=\"database.port\")\n        name = self.fm.get_key(dot_key=\"database.name\", default=\"myapp\")\n        ssl = self.fm.get_key(dot_key=\"database.ssl\", default=False)\n\n        protocol = \"postgresql+ssl\" if ssl else \"postgresql\"\n        return f\"{protocol}://{host}:{port}/{name}\"\n\n    def get_api_config(self) -&gt; Dict[str, Any]:\n        \"\"\"Get API configuration for current environment.\"\"\"\n        return {\n            \"version\": self.fm.get_key(dot_key=\"api.version\", default=\"v1\"),\n            \"timeout\": self.fm.get_key(dot_key=\"api.timeout\", default=30),\n            \"debug\": self.fm.get_key(dot_key=\"api.debug\", default=False),\n            \"cors\": {\n                \"origins\": self.fm.get_key(dot_key=\"cors.origins\", default=[])\n            }\n        }\n\n# Usage example\ndef main():\n    # Set environment (usually done via environment variable)\n    os.environ[\"ENVIRONMENT\"] = \"development\"\n\n    config = EnvironmentConfig()\n    config.load()\n\n    print(f\"Environment: {config.environment}\")\n    print(f\"Database URL: {config.get_database_url()}\")\n    print(f\"API Config: {config.get_api_config()}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"usage_examples/multi_environment_setup/#configuration-inheritance","title":"Configuration Inheritance","text":"<pre><code>from yapfm import YAPFileManager\nfrom typing import Dict, Any, Optional\n\nclass ConfigInheritance:\n    def __init__(self, base_config: str = \"base_config.json\"):\n        self.base_config = base_config\n        self.environment = os.getenv(\"ENVIRONMENT\", \"development\")\n        self.env_config = f\"config_{self.environment}.json\"\n\n    def load_merged_config(self) -&gt; Dict[str, Any]:\n        \"\"\"Load and merge base and environment-specific configuration.\"\"\"\n        # Load base configuration\n        base_fm = YAPFileManager(self.base_config, auto_create=True)\n        with base_fm:\n            base_data = base_fm.data.copy()\n\n        # Load environment-specific configuration\n        env_fm = YAPFileManager(self.env_config, auto_create=True)\n        with env_fm:\n            env_data = env_fm.data\n\n        # Merge configurations (environment overrides base)\n        merged_config = self._deep_merge(base_data, env_data)\n\n        # Save merged configuration\n        merged_fm = YAPFileManager(\"merged_config.json\", auto_create=True)\n        with merged_fm:\n            merged_fm.data = merged_config\n\n        return merged_config\n\n    def _deep_merge(self, base: Dict[str, Any], override: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Deep merge two dictionaries.\"\"\"\n        result = base.copy()\n\n        for key, value in override.items():\n            if key in result and isinstance(result[key], dict) and isinstance(value, dict):\n                result[key] = self._deep_merge(result[key], value)\n            else:\n                result[key] = value\n\n        return result\n\n# Usage example\ndef main():\n    config_manager = ConfigInheritance()\n    merged_config = config_manager.load_merged_config()\n\n    print(\"Merged Configuration:\")\n    print(f\"Environment: {merged_config.get('environment')}\")\n    print(f\"Database: {merged_config.get('database', {}).get('host')}\")\n    print(f\"API: {merged_config.get('api', {}).get('timeout')}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"usage_examples/performance_optimization/","title":"Performance Optimization","text":""},{"location":"usage_examples/performance_optimization/#batch-operations","title":"Batch Operations","text":"<pre><code>from yapfm import YAPFileManager\nfrom typing import Dict, Any, List\nimport time\n\nclass BatchConfig:\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.fm = YAPFileManager(config_file, auto_create=True)\n        self.pending_changes: Dict[str, Any] = {}\n\n    def batch_set(self, changes: Dict[str, Any]) -&gt; None:\n        \"\"\"Set multiple configuration values in a single operation.\"\"\"\n        with self.fm:\n            with self.fm.lazy_save():\n                for key, value in changes.items():\n                    self.fm.set_key(value, dot_key=key)\n\n    def batch_set_sections(self, sections: Dict[str, Dict[str, Any]]) -&gt; None:\n        \"\"\"Set multiple sections in a single operation.\"\"\"\n        with self.fm:\n            with self.fm.lazy_save():\n                for section_key, section_data in sections.items():\n                    self.fm.set_section(section_data, dot_key=section_key)\n\n    def batch_update(self, updates: Dict[str, Any]) -&gt; None:\n        \"\"\"Update multiple configuration values efficiently.\"\"\"\n        with self.fm:\n            # Get current data\n            current_data = self.fm.data.copy()\n\n            # Apply updates\n            for key, value in updates.items():\n                keys = key.split('.')\n                target = current_data\n\n                # Navigate to the target location\n                for k in keys[:-1]:\n                    if k not in target:\n                        target[k] = {}\n                    target = target[k]\n\n                # Set the value\n                target[keys[-1]] = value\n\n            # Save updated data\n            self.fm.data = current_data\n\n# Performance comparison example\ndef performance_comparison():\n    config_file = \"performance_test.json\"\n\n    # Individual operations\n    start_time = time.time()\n    fm = YAPFileManager(config_file, auto_create=True)\n\n    with fm:\n        for i in range(100):\n            fm.set_key(f\"value_{i}\", dot_key=f\"key_{i}\")\n\n    individual_time = time.time() - start_time\n    print(f\"Individual operations: {individual_time:.4f} seconds\")\n\n    # Batch operations\n    start_time = time.time()\n    batch_config = BatchConfig(\"performance_test_batch.json\")\n\n    changes = {f\"key_{i}\": f\"value_{i}\" for i in range(100)}\n    batch_config.batch_set(changes)\n\n    batch_time = time.time() - start_time\n    print(f\"Batch operations: {batch_time:.4f} seconds\")\n\n    print(f\"Speedup: {individual_time / batch_time:.2f}x\")\n\nif __name__ == \"__main__\":\n    performance_comparison()\n</code></pre>"},{"location":"usage_examples/unified_api_examples/","title":"Unified API Examples","text":"<p>This document provides comprehensive examples of YAPFM's unified API and advanced features.</p>"},{"location":"usage_examples/unified_api_examples/#basic-unified-api-usage","title":"Basic Unified API Usage","text":""},{"location":"usage_examples/unified_api_examples/#simple-file-operations","title":"Simple File Operations","text":"<pre><code>from yapfm import YAPFileManager\n\n# Create a file manager\nfm = YAPFileManager(\"config.json\", auto_create=True)\n\n# Unified API - simple and intuitive\nfm.set(\"database.host\", \"localhost\")\nfm.set(\"database.port\", 5432)\nfm.set(\"api.version\", \"v2\")\n\n# Dictionary-like syntax\nfm[\"logging.level\"] = \"INFO\"\nfm[\"logging.file\"] = \"app.log\"\n\n# Retrieve values\nhost = fm.get(\"database.host\")\nport = fm.get(\"database.port\", 5432)  # with default\nlevel = fm[\"logging.level\"]\n\n# Check existence\nif fm.has(\"database.host\"):\n    print(\"Database host is configured\")\n\n# Delete keys\nfm.delete(\"temp.key\")\ndel fm[\"old.key\"]\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#context-management","title":"Context Management","text":"<pre><code># Automatic loading and saving\nwith YAPFileManager(\"config.json\") as fm:\n    fm.set(\"database.host\", \"localhost\")\n    fm.set(\"api.timeout\", 30)\n    # File is automatically saved when exiting context\n\n# Lazy saving for multiple operations\nwith fm.lazy_save():\n    fm.set(\"key1\", \"value1\")\n    fm.set(\"key2\", \"value2\")\n    fm.set(\"key3\", \"value3\")\n    # All changes saved at once when exiting lazy_save context\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#batch-operations","title":"Batch Operations","text":""},{"location":"usage_examples/unified_api_examples/#efficient-multi-key-operations","title":"Efficient Multi-Key Operations","text":"<pre><code># Set multiple values at once\nfm.set_multiple({\n    \"database.host\": \"localhost\",\n    \"database.port\": 5432,\n    \"database.ssl\": True,\n    \"api.version\": \"v2\",\n    \"api.timeout\": 30,\n    \"logging.level\": \"INFO\",\n    \"logging.file\": \"app.log\"\n})\n\n# Get multiple values\nvalues = fm.get_multiple([\n    \"database.host\",\n    \"database.port\",\n    \"api.timeout\"\n])\n\n# Get multiple values with specific defaults\nvalues = fm.get_multiple([\n    \"database.host\",\n    \"database.port\",\n    \"api.timeout\",\n    \"missing.key\"\n], defaults={\n    \"database.host\": \"localhost\",\n    \"database.port\": 5432,\n    \"api.timeout\": 30,\n    \"missing.key\": \"default_value\"\n})\n\n# Check existence of multiple keys\nexists = fm.has_multiple([\n    \"database.host\",\n    \"database.port\",\n    \"api.timeout\",\n    \"missing.key\"\n])\n# Returns: {\"database.host\": True, \"database.port\": True, \"api.timeout\": True, \"missing.key\": False}\n\n# Delete multiple keys\ndeleted_count = fm.delete_multiple([\n    \"temp.key1\",\n    \"temp.key2\",\n    \"temp.key3\"\n])\nprint(f\"Deleted {deleted_count} keys\")\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#performance-comparison","title":"Performance Comparison","text":"<pre><code>import time\n\n# Individual operations (slower)\nstart = time.time()\nfor i in range(1000):\n    fm.set(f\"key{i}\", f\"value{i}\")\nindividual_time = time.time() - start\n\n# Batch operations (faster)\nstart = time.time()\nbatch_data = {f\"batch_key{i}\": f\"value{i}\" for i in range(1000)}\nfm.set_multiple(batch_data)\nbatch_time = time.time() - start\n\nprint(f\"Individual operations: {individual_time:.3f}s\")\nprint(f\"Batch operations: {batch_time:.3f}s\")\nprint(f\"Speedup: {individual_time/batch_time:.1f}x\")\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#multi-file-operations","title":"Multi-File Operations","text":""},{"location":"usage_examples/unified_api_examples/#basic-multi-file-loading","title":"Basic Multi-File Loading","text":"<pre><code># Load multiple files with deep merge\ndata = fm.load_multiple_files([\n    \"base.json\",\n    \"environment.json\",\n    \"user.json\"\n], strategy=\"deep\")\n\n# Load with namespace strategy\ndata = fm.load_multiple_files([\n    \"database.json\",\n    \"api.json\",\n    \"cache.json\"\n], strategy=\"namespace\", namespace_prefix=\"services\")\n\n# Load with priority strategy\ndata = fm.load_multiple_files([\n    \"base.json\",\n    \"override.json\"\n], strategy=\"priority\", priorities={\"override.json\": 2, \"base.json\": 1})\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#advanced-merge-strategies","title":"Advanced Merge Strategies","text":"<pre><code># Deep merge with conflict resolution\ndef resolve_conflicts(key, value1, value2):\n    \"\"\"Custom conflict resolution function.\"\"\"\n    if key == \"database.host\":\n        return value2  # Always use the newer value\n    elif key == \"logging.level\":\n        # Use the more verbose level\n        levels = {\"DEBUG\": 0, \"INFO\": 1, \"WARNING\": 2, \"ERROR\": 3}\n        return value1 if levels.get(value1, 0) &gt; levels.get(value2, 0) else value2\n    else:\n        return value2  # Default: newer value wins\n\ndata = fm.load_multiple_files(\n    [\"base.json\", \"override.json\"],\n    strategy=\"deep\",\n    conflict_resolver=resolve_conflicts\n)\n\n# Conditional loading based on environment\ndef load_environment_config(environment):\n    \"\"\"Load configuration based on environment.\"\"\"\n    def condition(file_path, data):\n        # Load base files always\n        if \"base\" in str(file_path):\n            return True\n\n        # Load environment-specific files\n        if environment in str(file_path):\n            return True\n\n        # Load files that match current environment\n        if data.get(\"environment\") == environment:\n            return True\n\n        return False\n\n    return fm.load_multiple_files(\n        [\"base.json\", \"dev.json\", \"prod.json\", \"staging.json\"],\n        strategy=\"conditional\",\n        condition_func=condition\n    )\n\n# Load production configuration\nprod_config = load_environment_config(\"production\")\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#file-group-management","title":"File Group Management","text":"<pre><code># Define file groups\nfile_groups = {\n    \"core_services\": {\n        \"files\": [\"database.json\", \"cache.json\", \"queue.json\"],\n        \"strategy\": \"namespace\",\n        \"namespace_prefix\": \"core\"\n    },\n    \"api_services\": {\n        \"files\": [\"rest.json\", \"graphql.json\", \"websocket.json\"],\n        \"strategy\": \"namespace\", \n        \"namespace_prefix\": \"api\"\n    },\n    \"environment_config\": {\n        \"files\": [\"base.json\", \"dev.json\", \"prod.json\"],\n        \"strategy\": \"priority\",\n        \"priorities\": {\"prod.json\": 100, \"dev.json\": 50, \"base.json\": 10}\n    }\n}\n\n# Load specific groups\ncore_config = fm.load_file_group(\"core_services\", file_groups)\napi_config = fm.load_file_group(\"api_services\", file_groups)\n\n# Load all groups\nall_config = {}\nfor group_name in file_groups:\n    group_config = fm.load_file_group(group_name, file_groups)\n    all_config.update(group_config)\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#advanced-caching","title":"Advanced Caching","text":""},{"location":"usage_examples/unified_api_examples/#cache-configuration","title":"Cache Configuration","text":"<pre><code># Enable advanced caching\nfm = YAPFileManager(\n    \"config.json\",\n    enable_cache=True,\n    cache_size=2000,\n    cache_ttl=7200  # 2 hours\n)\n\n# Cache-aware operations\nfm.set(\"database.host\", \"localhost\")  # Automatically cached\nhost = fm.get(\"database.host\")        # Retrieved from cache\n\n# Batch operations with cache optimization\nfm.set_multiple({\n    \"key1\": \"value1\",\n    \"key2\": \"value2\",\n    \"key3\": \"value3\"\n})  # All keys cached efficiently\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#cache-statistics-and-management","title":"Cache Statistics and Management","text":"<pre><code># Get comprehensive cache statistics\nstats = fm.get_cache_stats()\nprint(f\"Cache hit rate: {stats['unified_cache']['hit_rate']:.2%}\")\nprint(f\"Cache size: {stats['unified_cache']['size']}\")\nprint(f\"Memory usage: {stats['unified_cache']['memory_usage']} bytes\")\nprint(f\"Lazy sections: {stats['lazy_sections']['total_sections']}\")\n\n# Cache invalidation\nfm.invalidate_cache(\"database.*\")  # Invalidate all database keys\nfm.clear_cache()  # Clear all cache\nfm.clear_key_cache()  # Clear key generation cache\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#data-analysis-and-transformation","title":"Data Analysis and Transformation","text":""},{"location":"usage_examples/unified_api_examples/#data-analysis","title":"Data Analysis","text":"<pre><code># Get comprehensive statistics\nstats = fm.get_stats()\nprint(f\"Total keys: {stats['total_keys']}\")\nprint(f\"Max depth: {stats['max_depth']}\")\nprint(f\"File size: {stats['file_size']} bytes\")\nprint(f\"Type distribution: {stats['type_counts']}\")\n\n# Find duplicates\nduplicates = fm.find_duplicates()\nfor value, keys in duplicates.items():\n    if len(keys) &gt; 1:\n        print(f\"Value '{value}' found in: {keys}\")\n\n# Get type distribution\ntypes = fm.get_type_distribution()\nprint(f\"String values: {types.get('str', 0)}\")\nprint(f\"Integer values: {types.get('int', 0)}\")\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#data-transformation","title":"Data Transformation","text":"<pre><code># Flatten nested structure\nflat_data = fm.flatten()\nprint(flat_data)  # {'database.host': 'localhost', 'database.port': 5432}\n\n# Transform all string values to uppercase\nfm.transform_values(lambda x: x.upper() if isinstance(x, str) else x)\n\n# Transform all keys to lowercase\nfm.transform_keys(str.lower)\n\n# Convert snake_case to camelCase\ndef snake_to_camel(snake_str):\n    components = snake_str.split('_')\n    return components[0] + ''.join(x.title() for x in components[1:])\n\nfm.transform_keys(snake_to_camel)\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#data-cleanup","title":"Data Cleanup","text":"<pre><code># Remove null values\nnulls_removed = fm.remove_nulls()\nprint(f\"Removed {nulls_removed} null values\")\n\n# Remove empty sections\nempty_sections_removed = fm.clean_empty_sections()\nprint(f\"Removed {empty_sections_removed} empty sections\")\n\n# Compact data (remove nulls and empty sections)\nresult = fm.compact()\nprint(f\"Total operations: {result['total_operations']}\")\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#security-features","title":"Security Features","text":""},{"location":"usage_examples/unified_api_examples/#sensitive-data-handling","title":"Sensitive Data Handling","text":"<pre><code># Mask sensitive data\nmasked_data = fm.mask_sensitive()\nprint(masked_data)  # Sensitive values replaced with \"***\"\n\n# Mask specific keys\nmasked_data = fm.mask_sensitive([\"password\", \"secret\"], \"HIDDEN\")\n\n# Get public configuration (sensitive data removed)\npublic_config = fm.get_public_config()\n\n# Freeze file for read-only access\nfm.freeze()\n# fm.set(\"new.key\", \"value\")  # This would raise PermissionError\n\n# Unfreeze to allow modifications\nfm.unfreeze()\nfm.set(\"new.key\", \"value\")  # Now works\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#export-and-format-conversion","title":"Export and Format Conversion","text":""},{"location":"usage_examples/unified_api_examples/#export-to-different-formats","title":"Export to Different Formats","text":"<pre><code># Export to different formats\njson_str = fm.to_json(pretty=True)\nyaml_str = fm.to_yaml()\ntoml_str = fm.to_toml()\n\n# Export specific sections\ndb_config = fm.export_section(\"database\", \"json\")\napi_config = fm.export_section(\"api\", \"yaml\", \"api_config.yaml\")\n\n# Export entire data to file\nfm.export_to_file(\"backup.json\")\nfm.export_to_file(\"config.yaml\", \"yaml\")\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#error-handling-and-validation","title":"Error Handling and Validation","text":""},{"location":"usage_examples/unified_api_examples/#robust-error-handling","title":"Robust Error Handling","text":"<pre><code>def safe_operations(fm, operations):\n    \"\"\"Safely perform operations with error handling.\"\"\"\n    results = {\n        \"successful\": [],\n        \"failed\": [],\n        \"skipped\": []\n    }\n\n    for operation_type, data in operations.items():\n        try:\n            if operation_type == \"set\":\n                fm.set_multiple(data)\n                results[\"successful\"].extend(data.keys())\n            elif operation_type == \"delete\":\n                deleted = fm.delete_multiple(data)\n                results[\"successful\"].extend(data[:deleted])\n                results[\"skipped\"].extend(data[deleted:])\n            elif operation_type == \"get\":\n                values = fm.get_multiple(data)\n                results[\"successful\"].extend(values.keys())\n        except Exception as e:\n            results[\"failed\"].append({\n                \"operation\": operation_type,\n                \"data\": data,\n                \"error\": str(e)\n            })\n\n    return results\n\n# Usage\noperations = {\n    \"set\": {\"key1\": \"value1\", \"key2\": \"value2\"},\n    \"delete\": [\"old_key1\", \"old_key2\"],\n    \"get\": [\"key1\", \"key2\", \"key3\"]\n}\n\nresults = safe_operations(fm, operations)\nprint(f\"Successful: {len(results['successful'])}\")\nprint(f\"Failed: {len(results['failed'])}\")\nprint(f\"Skipped: {len(results['skipped'])}\")\n</code></pre>"},{"location":"usage_examples/unified_api_examples/#complete-example-application-configuration-management","title":"Complete Example: Application Configuration Management","text":"<pre><code>from yapfm import YAPFileManager\nfrom pathlib import Path\n\nclass AppConfigManager:\n    \"\"\"Complete application configuration management example.\"\"\"\n\n    def __init__(self, config_dir=\"config\"):\n        self.config_dir = Path(config_dir)\n        self.config_dir.mkdir(exist_ok=True)\n\n        # Main configuration file\n        self.main_config = YAPFileManager(\n            self.config_dir / \"main.json\",\n            auto_create=True,\n            enable_cache=True,\n            cache_size=1000\n        )\n\n        # Environment-specific files\n        self.env_files = {\n            \"dev\": self.config_dir / \"dev.json\",\n            \"prod\": self.config_dir / \"prod.json\",\n            \"test\": self.config_dir / \"test.json\"\n        }\n\n    def load_environment_config(self, environment):\n        \"\"\"Load configuration for specific environment.\"\"\"\n        files = [self.config_dir / \"base.json\"]\n\n        if environment in self.env_files:\n            files.append(self.env_files[environment])\n\n        return self.main_config.load_multiple_files(\n            files,\n            strategy=\"deep\"\n        )\n\n    def setup_database_config(self, environment):\n        \"\"\"Setup database configuration.\"\"\"\n        db_config = {\n            \"database.host\": \"localhost\",\n            \"database.port\": 5432,\n            \"database.ssl\": False\n        }\n\n        if environment == \"prod\":\n            db_config.update({\n                \"database.host\": \"prod-db-server\",\n                \"database.ssl\": True,\n                \"database.pool_size\": 20\n            })\n\n        self.main_config.set_multiple(db_config)\n\n    def setup_api_config(self):\n        \"\"\"Setup API configuration.\"\"\"\n        api_config = {\n            \"api.version\": \"v2\",\n            \"api.timeout\": 30,\n            \"api.rate_limit\": 1000,\n            \"api.cors_origins\": [\"http://localhost:3000\"]\n        }\n\n        self.main_config.set_multiple(api_config)\n\n    def setup_logging_config(self, level=\"INFO\"):\n        \"\"\"Setup logging configuration.\"\"\"\n        logging_config = {\n            \"logging.level\": level,\n            \"logging.file\": \"app.log\",\n            \"logging.max_size\": \"10MB\",\n            \"logging.backup_count\": 5\n        }\n\n        self.main_config.set_multiple(logging_config)\n\n    def get_public_config(self):\n        \"\"\"Get public configuration (sensitive data masked).\"\"\"\n        return self.main_config.get_public_config()\n\n    def backup_config(self, backup_path):\n        \"\"\"Backup current configuration.\"\"\"\n        self.main_config.export_to_file(backup_path)\n\n    def restore_config(self, backup_path):\n        \"\"\"Restore configuration from backup.\"\"\"\n        backup_fm = YAPFileManager(backup_path)\n        self.main_config.data = backup_fm.data\n        self.main_config.save()\n\n    def validate_config(self):\n        \"\"\"Validate configuration.\"\"\"\n        # Check required keys\n        required_keys = [\n            \"database.host\",\n            \"database.port\",\n            \"api.version\",\n            \"logging.level\"\n        ]\n\n        missing_keys = []\n        for key in required_keys:\n            if not self.main_config.has(key):\n                missing_keys.append(key)\n\n        if missing_keys:\n            raise ValueError(f\"Missing required configuration keys: {missing_keys}\")\n\n        # Validate database port\n        port = self.main_config.get(\"database.port\")\n        if not isinstance(port, int) or not (1 &lt;= port &lt;= 65535):\n            raise ValueError(\"Invalid database port\")\n\n        return True\n\n# Usage example\nconfig_manager = AppConfigManager(\"my_app_config\")\n\n# Setup configuration for development\nconfig_manager.setup_database_config(\"dev\")\nconfig_manager.setup_api_config()\nconfig_manager.setup_logging_config(\"DEBUG\")\n\n# Validate configuration\ntry:\n    config_manager.validate_config()\n    print(\"Configuration is valid\")\nexcept ValueError as e:\n    print(f\"Configuration error: {e}\")\n\n# Get public configuration for client\npublic_config = config_manager.get_public_config()\n\n# Backup configuration\nconfig_manager.backup_config(\"config_backup.json\")\n</code></pre> <p>This comprehensive example demonstrates how to use YAPFM's unified API and advanced features for real-world application configuration management.</p>"},{"location":"user_guide/","title":"User Guide","text":"<p>This comprehensive guide covers all aspects of using YAPFM in your projects, from basic operations to advanced patterns and best practices.</p>"},{"location":"user_guide/#table-of-contents","title":"\ud83d\udcd6 Table of Contents","text":"<ol> <li>Getting Started - Basic setup and first steps</li> <li>Core Concepts - Understanding YAPFM architecture</li> <li>File Operations - Loading, saving, and managing files</li> <li>Data Access Patterns - Working with keys and sections</li> <li>Context Management - Using context managers effectively</li> <li>Error Handling - Handling exceptions and validation</li> <li>Performance Considerations - Optimizing for performance</li> <li>Best Practices - Recommended patterns and approaches</li> <li>Common Patterns - Real-world usage examples</li> </ol>"},{"location":"user_guide/#quick-navigation","title":"Quick Navigation","text":"<ul> <li>New to YAPFM? Start with Getting Started</li> <li>Need to understand the basics? Check Core Concepts</li> <li>Working with files? See File Operations</li> <li>Managing data? Read Data Access Patterns</li> <li>Want best practices? Go to Best Practices</li> <li>Looking for examples? Browse Common Patterns</li> </ul>"},{"location":"user_guide/#additional-resources","title":"Additional Resources","text":"<ul> <li>Advanced Features Guide - Proxy patterns, custom strategies, and performance optimization</li> <li>API Reference - Complete API documentation</li> <li>Examples - More code examples and use cases</li> </ul>"},{"location":"user_guide/best_practices/","title":"Best Practices","text":""},{"location":"user_guide/best_practices/#1-use-context-managers","title":"1. Use Context Managers","text":"<pre><code># \u2705 Good: Automatic cleanup\nwith YAPFileManager(\"config.json\", auto_create=True) as fm:\n    fm.set_key(\"value\", dot_key=\"key\")\n\n# \u274c Avoid: Manual cleanup\nfm = YAPFileManager(\"config.json\")\nfm.load()\nfm.set_key(\"value\", dot_key=\"key\")\nfm.save()\n</code></pre>"},{"location":"user_guide/best_practices/#2-set-defaults","title":"2. Set Defaults","text":"<pre><code># \u2705 Good: Always provide defaults\nhost = fm.get_key(dot_key=\"database.host\", default=\"localhost\")\n\n# \u274c Avoid: No defaults\nhost = fm.get_key(dot_key=\"database.host\")  # Could be None\n</code></pre>"},{"location":"user_guide/best_practices/#3-validate-configuration","title":"3. Validate Configuration","text":"<pre><code># \u2705 Good: Validate before use\ndef load_config():\n    with YAPFileManager(\"config.json\", auto_create=True) as fm:\n        # Set required defaults\n        if not fm.has_key(dot_key=\"database.host\"):\n            fm.set_key(\"localhost\", dot_key=\"database.host\")\n\n        return fm.data\n\n# \u274c Avoid: No validation\ndef load_config():\n    with YAPFileManager(\"config.json\") as fm:\n        return fm.data  # Could be missing required keys\n</code></pre>"},{"location":"user_guide/best_practices/#4-handle-errors-gracefully","title":"4. Handle Errors Gracefully","text":"<pre><code># \u2705 Good: Comprehensive error handling\ntry:\n    with YAPFileManager(\"config.json\") as fm:\n        fm.set_key(\"value\", dot_key=\"key\")\nexcept LoadFileError as e:\n    logger.error(f\"Failed to load config: {e}\")\n    # Fallback to default config\nexcept FileWriteError as e:\n    logger.error(f\"Failed to save config: {e}\")\n    # Handle save failure\nexcept Exception as e:\n    logger.error(f\"Unexpected error: {e}\")\n    # Handle unexpected errors\n\n# \u274c Avoid: No error handling\nwith YAPFileManager(\"config.json\") as fm:\n    fm.set_key(\"value\", dot_key=\"key\")  # Could fail silently\n</code></pre>"},{"location":"user_guide/best_practices/#5-use-meaningful-key-names","title":"5. Use Meaningful Key Names","text":"<pre><code># \u2705 Good: Clear, descriptive keys\nfm.set_key(\"localhost\", dot_key=\"database.host\")\nfm.set_key(5432, dot_key=\"database.port\")\nfm.set_key(\"myapp\", dot_key=\"database.name\")\n\n# \u274c Avoid: Unclear keys\nfm.set_key(\"localhost\", dot_key=\"db.h\")\nfm.set_key(5432, dot_key=\"db.p\")\nfm.set_key(\"myapp\", dot_key=\"db.n\")\n</code></pre>"},{"location":"user_guide/common_patterns/","title":"Common Patterns","text":""},{"location":"user_guide/common_patterns/#1-configuration-management","title":"1. Configuration Management","text":"<pre><code>class AppConfig:\n    def __init__(self, config_file=\"config.json\"):\n        self.fm = YAPFileManager(config_file, auto_create=True)\n\n    def load(self):\n        \"\"\"Load configuration with defaults.\"\"\"\n        with self.fm:\n            # Set defaults if not present\n            defaults = {\n                \"app.name\": \"My App\",\n                \"app.version\": \"1.0.0\",\n                \"database.host\": \"localhost\",\n                \"database.port\": 5432,\n                \"debug\": False\n            }\n\n            for key, value in defaults.items():\n                if not self.fm.has_key(dot_key=key):\n                    self.fm.set_key(value, dot_key=key)\n\n    def get(self, key, default=None):\n        \"\"\"Get configuration value.\"\"\"\n        return self.fm.get_key(dot_key=key, default=default)\n\n    def set(self, key, value):\n        \"\"\"Set configuration value.\"\"\"\n        self.fm.set_key(value, dot_key=key)\n        self.fm.save()\n\n# Use the configuration manager\nconfig = AppConfig(\"my_app_config.json\")\nconfig.load()\napp_name = config.get(\"app.name\")\nconfig.set(\"debug\", True)\n</code></pre>"},{"location":"user_guide/common_patterns/#2-environment-specific-configuration","title":"2. Environment-Specific Configuration","text":"<pre><code>import os\nfrom yapfm import YAPFileManager\n\nclass EnvironmentConfig:\n    def __init__(self, base_config=\"config.json\"):\n        self.env = os.getenv(\"ENVIRONMENT\", \"development\")\n        self.config_file = f\"config_{self.env}.json\"\n        self.fm = YAPFileManager(self.config_file, auto_create=True)\n\n    def load(self):\n        \"\"\"Load environment-specific configuration.\"\"\"\n        with self.fm:\n            # Set environment\n            self.fm.set_key(self.env, dot_key=\"environment\")\n\n            # Set environment-specific defaults\n            if self.env == \"development\":\n                self.fm.set_key(True, dot_key=\"debug\")\n                self.fm.set_key(\"localhost\", dot_key=\"database.host\")\n            elif self.env == \"production\":\n                self.fm.set_key(False, dot_key=\"debug\")\n                self.fm.set_key(\"prod-db.example.com\", dot_key=\"database.host\")\n\n    def get_database_url(self):\n        \"\"\"Get database URL for current environment.\"\"\"\n        host = self.fm.get_key(dot_key=\"database.host\")\n        port = self.fm.get_key(dot_key=\"database.port\")\n        name = self.fm.get_key(dot_key=\"database.name\")\n        return f\"postgresql://{host}:{port}/{name}\"\n\n# Use environment-specific configuration\nconfig = EnvironmentConfig()\nconfig.load()\ndb_url = config.get_database_url()\n</code></pre>"},{"location":"user_guide/common_patterns/#3-configuration-validation","title":"3. Configuration Validation","text":"<pre><code>from yapfm import YAPFileManager\n\nclass ConfigValidator:\n    def __init__(self, config_file):\n        self.fm = YAPFileManager(config_file)\n\n    def validate(self):\n        \"\"\"Validate configuration file.\"\"\"\n        errors = []\n\n        # Required keys\n        required_keys = [\n            \"app.name\",\n            \"app.version\",\n            \"database.host\",\n            \"database.port\"\n        ]\n\n        for key in required_keys:\n            if not self.fm.has_key(dot_key=key):\n                errors.append(f\"Missing required key: {key}\")\n\n        # Validate specific values\n        if self.fm.has_key(dot_key=\"database.port\"):\n            port = self.fm.get_key(dot_key=\"database.port\")\n            if not isinstance(port, int) or port &lt; 1 or port &gt; 65535:\n                errors.append(\"Invalid database port\")\n\n        if self.fm.has_key(dot_key=\"debug\"):\n            debug = self.fm.get_key(dot_key=\"debug\")\n            if not isinstance(debug, bool):\n                errors.append(\"Debug flag must be boolean\")\n\n        return errors\n\n    def is_valid(self):\n        \"\"\"Check if configuration is valid.\"\"\"\n        return len(self.validate()) == 0\n\n# Use configuration validator\nvalidator = ConfigValidator(\"config.json\")\nif validator.is_valid():\n    print(\"Configuration is valid\")\nelse:\n    errors = validator.validate()\n    print(f\"Configuration errors: {errors}\")\n</code></pre> <p>Ready to explore more advanced features? Check out the Advanced Features Guide for proxy patterns, custom strategies, and performance optimization.</p>"},{"location":"user_guide/context_management/","title":"Context Management","text":""},{"location":"user_guide/context_management/#basic-context-manager","title":"Basic Context Manager","text":"<pre><code>from yapfm import YAPFileManager\n\n# Automatic loading and saving\nwith YAPFileManager(\"config.json\", auto_create=True) as fm:\n    fm.set_key(\"value\", dot_key=\"key\")\n    # File is automatically saved when exiting the context\n</code></pre>"},{"location":"user_guide/context_management/#lazy-save-context","title":"Lazy Save Context","text":"<pre><code># Save only when exiting the lazy_save context\nwith YAPFileManager(\"config.json\") as fm:\n    with fm.lazy_save():\n        fm.set_key(\"value1\", dot_key=\"key1\")\n        fm.set_key(\"value2\", dot_key=\"key2\")\n        fm.set_key(\"value3\", dot_key=\"key3\")\n        # Save happens here when exiting lazy_save context\n</code></pre>"},{"location":"user_guide/context_management/#auto-save-context","title":"Auto Save Context","text":"<pre><code># Auto-save context (similar to lazy_save)\nwith YAPFileManager(\"config.json\") as fm:\n    with fm.auto_save():\n        fm.set_key(\"value\", dot_key=\"key\")\n        # Save happens here when exiting auto_save context\n</code></pre>"},{"location":"user_guide/context_management/#context-manager-with-error-handling","title":"Context Manager with Error Handling","text":"<pre><code>try:\n    with YAPFileManager(\"config.json\", auto_create=True) as fm:\n        fm.set_key(\"value\", dot_key=\"key\")\n        # Some operation that might fail\n        risky_operation()\nexcept Exception as e:\n    print(f\"Error occurred: {e}\")\n    # File is still saved if no exception occurred\n</code></pre>"},{"location":"user_guide/core_concepts/","title":"Core Concepts","text":""},{"location":"user_guide/core_concepts/#file-manager","title":"File Manager","text":"<p>The <code>YAPFileManager</code> is the main class that combines all functionality through mixins:</p> <ul> <li>FileOperationsMixin: Basic file operations (load, save, exists)</li> <li>KeyOperationsMixin: Key-based data access with dot notation</li> <li>SectionOperationsMixin: Section-based data management</li> <li>ContextMixin: Context manager support</li> </ul>"},{"location":"user_guide/core_concepts/#strategies","title":"Strategies","text":"<p>YAPFM uses the Strategy pattern to handle different file formats:</p> <ul> <li>JsonStrategy: Handles JSON files</li> <li>TomlStrategy: Handles TOML files with comment preservation</li> <li>YamlStrategy: Handles YAML files with safe loading</li> </ul>"},{"location":"user_guide/core_concepts/#dot-notation","title":"Dot Notation","text":"<p>YAPFM uses dot notation to access nested data:</p> <pre><code># Instead of: data[\"section\"][\"subsection\"][\"key\"]\nfm.get_key(dot_key=\"section.subsection.key\")\n\n# Instead of: data[\"section\"][\"subsection\"][\"key\"] = \"value\"\nfm.set_key(\"value\", dot_key=\"section.subsection.key\")\n</code></pre>"},{"location":"user_guide/data_access_patterns/","title":"Data Access Patterns","text":""},{"location":"user_guide/data_access_patterns/#key-operations","title":"Key Operations","text":""},{"location":"user_guide/data_access_patterns/#setting-values","title":"Setting Values","text":"<pre><code># Set single values\nfm.set_key(\"localhost\", dot_key=\"database.host\")\nfm.set_key(5432, dot_key=\"database.port\")\nfm.set_key(True, dot_key=\"database.ssl\")\n\n# Set with path and key name\nfm.set_key(\"localhost\", path=[\"database\"], key_name=\"host\")\n\n# Set with overwrite control\nfm.set_key(\"new_value\", dot_key=\"key\", overwrite=True)   # Default\nfm.set_key(\"new_value\", dot_key=\"key\", overwrite=False)  # Only if key doesn't exist\n</code></pre>"},{"location":"user_guide/data_access_patterns/#getting-values","title":"Getting Values","text":"<pre><code># Get values with defaults\nhost = fm.get_key(dot_key=\"database.host\", default=\"localhost\")\nport = fm.get_key(dot_key=\"database.port\", default=5432)\n\n# Get with path and key name\nhost = fm.get_key(path=[\"database\"], key_name=\"host\", default=\"localhost\")\n\n# Get without default (returns None if not found)\nhost = fm.get_key(dot_key=\"database.host\")\n</code></pre>"},{"location":"user_guide/data_access_patterns/#checking-existence","title":"Checking Existence","text":"<pre><code># Check if key exists\nif fm.has_key(dot_key=\"database.host\"):\n    print(\"Database host is configured\")\n\n# Check with path and key name\nif fm.has_key(path=[\"database\"], key_name=\"host\"):\n    print(\"Database host is configured\")\n</code></pre>"},{"location":"user_guide/data_access_patterns/#deleting-keys","title":"Deleting Keys","text":"<pre><code># Delete single keys\ndeleted = fm.delete_key(dot_key=\"database.host\")\nif deleted:\n    print(\"Database host removed\")\n\n# Delete with path and key name\ndeleted = fm.delete_key(path=[\"database\"], key_name=\"host\")\n</code></pre>"},{"location":"user_guide/data_access_patterns/#section-operations","title":"Section Operations","text":""},{"location":"user_guide/data_access_patterns/#setting-sections","title":"Setting Sections","text":"<pre><code># Set entire sections\ndatabase_config = {\n    \"host\": \"localhost\",\n    \"port\": 5432,\n    \"name\": \"myapp\",\n    \"ssl\": True\n}\nfm.set_section(database_config, dot_key=\"database\")\n\n# Set nested sections\napi_config = {\n    \"version\": \"v1\",\n    \"timeout\": 30,\n    \"cors\": {\n        \"enabled\": True,\n        \"origins\": [\"http://localhost:3000\"]\n    }\n}\nfm.set_section(api_config, dot_key=\"api\")\n</code></pre>"},{"location":"user_guide/data_access_patterns/#getting-sections","title":"Getting Sections","text":"<pre><code># Get entire sections\ndatabase_config = fm.get_section(dot_key=\"database\")\nif database_config:\n    print(f\"Database: {database_config['host']}:{database_config['port']}\")\n\n# Get nested sections\ncors_config = fm.get_section(dot_key=\"api.cors\")\nif cors_config:\n    print(f\"CORS origins: {cors_config['origins']}\")\n</code></pre>"},{"location":"user_guide/data_access_patterns/#checking-section-existence","title":"Checking Section Existence","text":"<pre><code># Check if section exists\nif fm.has_section(dot_key=\"database\"):\n    print(\"Database configuration exists\")\n\n# Check nested sections\nif fm.has_section(dot_key=\"api.cors\"):\n    print(\"CORS configuration exists\")\n</code></pre>"},{"location":"user_guide/data_access_patterns/#direct-data-access","title":"Direct Data Access","text":"<pre><code># Access data directly (auto-loads if not loaded)\ndata = fm.data\nprint(f\"All data: {data}\")\n\n# Set data directly\nfm.data = {\n    \"app\": {\"name\": \"My App\", \"version\": \"1.0.0\"},\n    \"database\": {\"host\": \"localhost\", \"port\": 5432}\n}\n\n# Modify data directly\nfm.data[\"app\"][\"version\"] = \"1.1.0\"\nfm.mark_as_dirty()  # Remember to mark as dirty\n</code></pre>"},{"location":"user_guide/error_handling/","title":"Error Handling","text":""},{"location":"user_guide/error_handling/#common-exceptions","title":"Common Exceptions","text":"<pre><code>from yapfm.exceptions import LoadFileError, FileWriteError, StrategyError\n\ntry:\n    with YAPFileManager(\"config.json\") as fm:\n        fm.set_key(\"value\", dot_key=\"key\")\n        fm.save()\nexcept LoadFileError as e:\n    print(f\"Failed to load file: {e}\")\nexcept FileWriteError as e:\n    print(f\"Failed to save file: {e}\")\nexcept StrategyError as e:\n    print(f\"Strategy error: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"user_guide/error_handling/#graceful-error-handling","title":"Graceful Error Handling","text":"<pre><code>def safe_config_operation(config_file, key, value):\n    \"\"\"Safely set a configuration value with error handling.\"\"\"\n    try:\n        with YAPFileManager(config_file, auto_create=True) as fm:\n            fm.set_key(value, dot_key=key)\n            return True\n    except LoadFileError:\n        print(f\"Could not load configuration file: {config_file}\")\n        return False\n    except FileWriteError:\n        print(f\"Could not save configuration file: {config_file}\")\n        return False\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return False\n\n# Use the safe function\nsuccess = safe_config_operation(\"config.json\", \"database.host\", \"localhost\")\nif success:\n    print(\"Configuration updated successfully\")\n</code></pre>"},{"location":"user_guide/error_handling/#validation-and-error-prevention","title":"Validation and Error Prevention","text":"<pre><code>def validate_config_file(config_file):\n    \"\"\"Validate that a configuration file is usable.\"\"\"\n    try:\n        fm = YAPFileManager(config_file)\n\n        # Check if file exists\n        if not fm.exists():\n            print(f\"Configuration file does not exist: {config_file}\")\n            return False\n\n        # Try to load the file\n        fm.load()\n\n        # Check if file is valid\n        if not isinstance(fm.data, dict):\n            print(f\"Configuration file is not a valid dictionary: {config_file}\")\n            return False\n\n        return True\n\n    except Exception as e:\n        print(f\"Configuration file validation failed: {e}\")\n        return False\n\n# Use validation\nif validate_config_file(\"config.json\"):\n    print(\"Configuration file is valid\")\nelse:\n    print(\"Configuration file has issues\")\n</code></pre>"},{"location":"user_guide/file_operations/","title":"File Operations","text":""},{"location":"user_guide/file_operations/#loading-files","title":"Loading Files","text":"<pre><code>from yapfm import YAPFileManager\n\n# Basic loading\nfm = YAPFileManager(\"config.json\")\nfm.load()\n\n# Auto-create if file doesn't exist\nfm = YAPFileManager(\"config.json\", auto_create=True)\nfm.load()  # Creates empty file if it doesn't exist\n\n# Check if file exists before loading\nif fm.exists():\n    fm.load()\nelse:\n    print(\"File doesn't exist\")\n</code></pre>"},{"location":"user_guide/file_operations/#saving-files","title":"Saving Files","text":"<pre><code># Basic saving\nfm.save()\n\n# Save only if file has been modified\nfm.save_if_dirty()\n\n# Check if file needs saving\nif fm.is_dirty():\n    fm.save()\n</code></pre>"},{"location":"user_guide/file_operations/#file-status","title":"File Status","text":"<pre><code># Check various file states\nprint(f\"File exists: {fm.exists()}\")\nprint(f\"File loaded: {fm.is_loaded()}\")\nprint(f\"File dirty: {fm.is_dirty()}\")\n\n# Manual state management\nfm.mark_as_dirty()    # Mark as modified\nfm.mark_as_clean()    # Mark as clean\nfm.mark_as_loaded()   # Mark as loaded\n</code></pre>"},{"location":"user_guide/file_operations/#file-lifecycle","title":"File Lifecycle","text":"<pre><code># Complete file lifecycle\nfm = YAPFileManager(\"config.json\")\n\n# 1. Load file\nfm.load()\n\n# 2. Make changes\nfm.set_key(\"value\", dot_key=\"key\")\n\n# 3. Save changes\nfm.save()\n\n# 4. Reload if needed (discards unsaved changes)\nfm.reload()\n\n# 5. Unload from memory\nfm.unload()\n</code></pre>"},{"location":"user_guide/getting_started/","title":"Getting Started","text":""},{"location":"user_guide/getting_started/#basic-setup","title":"Basic Setup","text":"<pre><code>from yapfm import YAPFileManager\n\n# Create a file manager\nfm = YAPFileManager(\"config.json\")\n\n# Load the file\nfm.load()\n\n# Your file is now ready to use!\n</code></pre>"},{"location":"user_guide/getting_started/#using-the-open_file-helper","title":"Using the open_file Helper","text":"<p>For a more convenient approach:</p> <pre><code>from yapfm.helpers import open_file\n\n# Open file with automatic format detection\nfm = open_file(\"config.json\")\n\n# Force a specific format\nfm = open_file(\"config.txt\", format=\"toml\")\n\n# Auto-create if file doesn't exist\nfm = open_file(\"new_config.json\", auto_create=True)\n\n# Use the file manager\nwith fm:\n    fm.set_key(\"value\", dot_key=\"key\")\n</code></pre>"},{"location":"user_guide/getting_started/#with-context-manager-recommended","title":"With Context Manager (Recommended)","text":"<pre><code>from yapfm import YAPFileManager\n\n# Automatic loading and saving\nwith YAPFileManager(\"config.json\", auto_create=True) as fm:\n    # Work with your configuration\n    fm.set_key(\"value\", dot_key=\"key\")\n    # File is automatically saved when exiting the context\n</code></pre>"},{"location":"user_guide/performance_considerations/","title":"Performance Considerations","text":""},{"location":"user_guide/performance_considerations/#lazy-loading","title":"Lazy Loading","text":"<pre><code># File is only loaded when first accessed\nfm = YAPFileManager(\"config.json\")\n# File is not loaded yet\n\n# Access data (triggers loading)\ndata = fm.data  # File is loaded here\n\n# Or explicitly load\nfm.load()  # File is loaded here\n</code></pre>"},{"location":"user_guide/performance_considerations/#memory-management","title":"Memory Management","text":"<pre><code># Unload file from memory when done\nfm = YAPFileManager(\"config.json\")\nfm.load()\n# ... use the file ...\nfm.unload()  # Free memory\n\n# Or use context manager for automatic cleanup\nwith YAPFileManager(\"config.json\") as fm:\n    # ... use the file ...\n    # File is automatically unloaded when exiting context\n</code></pre>"},{"location":"user_guide/performance_considerations/#batch-operations","title":"Batch Operations","text":"<pre><code># Batch multiple operations to reduce I/O\nwith YAPFileManager(\"config.json\") as fm:\n    with fm.lazy_save():\n        # Multiple operations, single save\n        fm.set_key(\"value1\", dot_key=\"key1\")\n        fm.set_key(\"value2\", dot_key=\"key2\")\n        fm.set_key(\"value3\", dot_key=\"key3\")\n        # Single save at the end\n</code></pre>"}]}